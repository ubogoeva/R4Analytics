{
  "hash": "498023f15ae3ddd123bd909d7a98c8a7",
  "result": {
    "markdown": "---\ntitle: \"Поправки на множественное тестирование\"\nauthor: \"Elena U\"\ndate: '29 Nov 2023'\nformat: html\neditor: visual\ntheme: yeti\ntoc: true\ntoc-expand: 2\ntoc-depth: 2\ncode-fold: true\n---\n\n\n\n\n::: {style=\"text-align: right\"}\n*Время чтения \\~10 минут*\n:::\n\nРазберем, что такое поправки на множественное тестирование, зачем они нужны, как работают основные методы, которые часто используются в науке и индустрии, а также на что опираться при выборе поправки в своем исследовании.\n\nНачнем разбор с классификации.\n\n## Классификация поправок на множественное тестирование\n\nСуществует 2 принципиально разных подхода к поправкам на множественное тестирование.\n\n-   Контроль групповой **вероятности** ошибки I рода (FWER, family-wise error rate)\n\n    -   Тесты, которые поправляют значимость у набора p-value (поправка Бонферрони, Холма, Шидака и тд.) вне зависимости, какой тест был применен до этого;\n\n    -   Тесты для попарных сравнений групп: пост-хоки (поправка Тьюки, поправка Даннета, тест Фишера LSD и тд).\n\n-   Контроль **доли** ложных открытий (FDR, false discovery rate): поправка Benjamini-Hochberg, поправка Benjamini-Yekutieli.\n\nНебольшое напоминание про типы ошибок:\n\n![https://t.me/stats_for_science/69](images/error_1_2_type.jpg)\n\nРазберем разные виды поправок подробнее.\n\n# FWER -- family-wise error rate\n\nFWER -- групповая вероятность ошибки I рода. Мне больше нравится определение, что это вероятность совершить **хоть одну** ошибку первого рода в нескольких тестах. Обычно рассчитывается для серии тестов (но можно посчитать FWER и для одного теста: вероятность будет равна $\\alpha$).\n\n$$\nFWER = 1 - (1-\\alpha)^k, где\n$$ {#eq-fwer}\n\n*k* - количество тестов, $\\alpha$ - уровень значимости.\n\n::: callout-important\nДля корректного применения формулы тесты должны быть [независимыми]{.underline}.\n:::\n\nЕсли это не так, то посчитать точный FWER можно с помощью симуляции, а по формуле вычисляется верхняя граница (то есть максимально возможное значение вероятности совершить ошибку I рода).\n\nПример ситуаций, когда тесты зависимы:\n\n-   Мы собрали две группы образцов и измерили у них 20 параметров. Тесты зависимы, поскольку пул образцов один и тот же для каждого измеренного параметра.\n\n-   У нас 3 группы, делаем попарное сравнение каждой группы с каждой. Тесты зависимы, поскольку одна и та же группа участвует в двух тестах.\n\nВо многих ситуациях тесты являются зависимыми, тем не менее, при множественном тестировании даже для зависимых тестов ошибка первого рода превышает пороговое 0.05.\n\n## Симуляция независимых тестов для подсчета FWER\n\nГенерируем заданное количество раз (5, 10, 50, 100) выборки размером 100 элементов из одной генеральной совокупности (стандартного нормального распределения) и сравниваем их t-тестом. Повторяем это 10000 раз, чтобы оценить долю случаев, где мы получили p-value \\< 0.05 (ложнопозитивный результат).\n\nТесты независимые, поскольку каждый раз извлекаем новую выборку, следовательно, мы ожидаем увидеть результат, близкий к рассчитанному по формуле выше.\n\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-2_123469fe484e339cc20b3b7004c1fbcc'}\n\n```{.r .cell-code}\npaste('Для 5 тестов: ', mean(replicate(10000, sum(replicate(5, t.test(rnorm(100), rnorm(100))$p.value) < 0.05) != 0)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Для 5 тестов:  0.2239\"\n```\n:::\n:::\n\n\n$FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05)^5 = 0.226$\n\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-3_dfefa8fb7990140744ee4a2ed34fd7fc'}\n\n```{.r .cell-code}\npaste('Для 10 тестов: ', mean(replicate(10000, sum(replicate(10, t.test(rnorm(100), rnorm(100))$p.value) < 0.05) != 0)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Для 10 тестов:  0.3976\"\n```\n:::\n:::\n\n\n$FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{10} = 0.401$\n\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-4_748d9fc9cc3a61f2164325443d2d9131'}\n\n```{.r .cell-code}\npaste('Для 50 тестов: ', mean(replicate(10000, sum(replicate(50, t.test(rnorm(100), rnorm(100))$p.value) < 0.05) != 0)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Для 50 тестов:  0.9211\"\n```\n:::\n:::\n\n\n$FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{50} = 0.923$\n\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-5_982deb2b6d97838d6737900e27145532'}\n\n```{.r .cell-code}\npaste('Для 100 тестов: ', mean(replicate(10000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) < 0.05) != 0)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Для 100 тестов:  0.9951\"\n```\n:::\n:::\n\n\n$FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{100} = 0.994$\n\nДействительно, при симуляции значения FWER сходятся с теоретически рассчитанными. Что можно сделать, чтобы избежать ошибок первого рода?\n\n## Поправка Бонферрони (Bonferroni)\n\nСамый простой способ контролировать вероятность ошибки первого рода -- это изменить критический уровень значимости $\\alpha$.\n\n$$ FWER = 1 - (1-\\frac{\\alpha}{k})^k, $$ {#eq-fwer_bonf}\n\nДелим $\\alpha$ на число тестов -\\> получаем новый p-уровень значимости, ниже которого результаты будут считаться статистически значимыми.\n\nИли умножаем каждое p-value на количество тестов, и если поправленное p-value \\< 0.05, то результат считается статистически значимым.\n\nПри таком подходе мы контролируем вероятность совершить *хоть одну* ошибку первого рода на уровне 0.05, однако сильно завышаем вероятность ошибки [второго рода]{.underline} (то есть не найти значимый эффект, где он на самом деле есть), следовательно, уменьшаем мощность теста.\n\nПроверим FWER после поправки.\n\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-6_761004d28192680ca5604e2b17aff08f'}\n\n```{.r .cell-code}\npaste('Для 5 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(5, t.test(rnorm(100), rnorm(100))$p.value) < 0.05/5) != 0)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Для 5 тестов FWER по Бонферрони:  0.051\"\n```\n:::\n:::\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-7_5eb703b7d05b1325cc72bdf2d9ee5049'}\n\n```{.r .cell-code}\npaste('Для 10 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(10, t.test(rnorm(100), rnorm(100))$p.value) < 0.05/10) != 0)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Для 10 тестов FWER по Бонферрони:  0.0435\"\n```\n:::\n:::\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-8_727dad3dd8e27fc8abcdc24d169b575d'}\n\n```{.r .cell-code}\npaste('Для 50 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(50, t.test(rnorm(100), rnorm(100))$p.value) < 0.05/50) != 0)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Для 50 тестов FWER по Бонферрони:  0.0479\"\n```\n:::\n:::\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-9_e0c6dd5ae37c6b81d449ea34dbc5f9fc'}\n\n```{.r .cell-code}\npaste('Для 100 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) < 0.05/100) != 0)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Для 100 тестов FWER по Бонферрони:  0.0452\"\n```\n:::\n:::\n\n\nДа, мы контролируем FWER на заданном уровне 0.05.\n\nПоправка Бонферрони используется редко, в основном в областях, где цена ошибок первого рода (ложнопозитивного результата) очень высока, например в исследованиях GWAS на человеке. В остальных случаях рекомендуют использовать менее консервативные поправки.\n\n## Поправка Холма (Holm)\n\nМенее консервативная поправка. Метод часто называют \"Бонферрони-Холма\", однако Карло Бонферрони не имел отношения к разработке этой формулы. Разберем на примере как работает.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\np_value <- c(0.004, 0.87, 0.003, 0.04, 0.18, 0.24)\n```\n:::\n\n\nСортируем и ранжируем p-value по возрастанию, далее по формуле умножаем каждое p-value на $(m+1-rank)$, где $m$ - количество тестов, $rank$ - ранг p-value.\n\n\n::: {.cell}\n::: {.cell-output-display}\n| pvalue| rank_pvalue|formula           | result|\n|------:|-----------:|:-----------------|------:|\n|  0.003|           1|0.003*(6 + 1 - 1) |  0.018|\n|  0.004|           2|0.004*(6 + 1 - 2) |  0.020|\n|  0.040|           3|0.04*(6 + 1 - 3)  |  0.160|\n|  0.180|           4|0.18*(6 + 1 - 4)  |  0.540|\n|  0.240|           5|0.24*(6 + 1 - 5)  |  0.480|\n|  0.870|           6|0.87*(6 + 1 - 6)  |  0.870|\n:::\n:::\n\n\nДалее нужно задать, что поправленные p-value могут только возрастать, и при этом p-value заменяется на бОльшее, поэтому процедура поправки Холма называется пошаговой нисходящей -- step-down.\n\n\n::: {.cell}\n::: {.cell-output-display}\n| pvalue| rank_pvalue|formula           | result| p_adjusted|\n|------:|-----------:|:-----------------|------:|----------:|\n|  0.003|           1|0.003*(6 + 1 - 1) |  0.018|      0.018|\n|  0.004|           2|0.004*(6 + 1 - 2) |  0.020|      0.020|\n|  0.040|           3|0.04*(6 + 1 - 3)  |  0.160|      0.160|\n|  0.180|           4|0.18*(6 + 1 - 4)  |  0.540|      0.540|\n|  0.240|           5|0.24*(6 + 1 - 5)  |  0.480|      0.540|\n|  0.870|           6|0.87*(6 + 1 - 6)  |  0.870|      0.870|\n:::\n:::\n\n\nМожем убедиться, что у нас подсчитано все верно:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\np.adjust(sort(p_value), method = 'holm')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.018 0.020 0.160 0.540 0.540 0.870\n```\n:::\n:::\n\n\nПоскольку для самого **минимального** **p-value** поправленное p-value **такое же** как и в Бонферрони, то поправка Холма контролирует FWER на **том же уровне 0.05**, что и поправка Бонферрони, при этом не так сильно снижает мощность тестов.\n\nПроверим на 100 тестах:\n\n\n::: {.cell hash='multiple_testing_cache/html/unnamed-chunk-14_1a82de8785ee223688e8d88398d7f72b'}\n\n```{.r .cell-code  code-fold=\"false\"}\nreplicate(1000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) %>% \n  p.adjust(method = 'holm') < 0.05) != 0) %>%\n  mean()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.054\n```\n:::\n:::\n\n\nТаким образом, мы все еще контролируем вероятность совершить хоть одну ошибку первого рода на уровне 0.05, и оставляем больше значимых результатов, по сравнению с поправкой Бонферрони. Поэтому во многих случаях рекомендуют использовать именно поправку Холма для множественных сравнений.\n\n::: callout-note\n## Ссылка на оригинальную статью:\n\nHolm, S. (1979). A simple sequentially rejective multiple test procedure. *Scandinavian Journal of Statistics*, **6**, 65--70. <https://www.jstor.org/stable/4615733>.\n:::\n\nТеперь перейдем к поправкам, которые используются в конкретных тестах.\n\n## Тест Фишера LSD (Least significant difference)\n\nИспользуется как постхок тест **только** после значимой ANOVA для сравнения средних групп между собой (напоминаю, что ANOVA, дисперсионный анализ дает ответ на вопрос, есть ли хоть какое-то различие между группами, но не говорит между какими). Также тест можно применять **только** для сравнения [трех групп]{.underline}.\n\nФормула вычисления критерия:\n\n$$\nt = \\frac{\\overline{X_1}-\\overline{X2}}{\\sqrt{MSE(\\frac{1}{n_1}+\\frac{1}{n_2})}}, где\n$$\n\n$\\overline{X_1}$, $\\overline{X_2}$ -- средние групп 1 и 2, $n_1$, $n_2$ -- размер групп 1 и 2, $MSE$ -- mean square error из таблицы ANOVA, то есть общая дисперсия между всеми группами.\n\nДля трех групп имеет большую мощность чем Тьюки. Но если групп больше чем 3, то контролирует FWER на уровне больше 0.05 и следовательно к использованию не рекомендуется.\n\nПодробнее, почему это так, можно посмотреть [здесь](https://www.youtube.com/watch?v=cAltDstP6ik&list=PLLTSM0eKjC2dvba2A0VCUogEGDch6cXFN&index=5).\n\n## Поправка Тьюки (Tukey, TukeyHSD)\n\nИспользуется как постхок тест вне зависимости от значимости ANOVA (подробнее ниже) для сравнения средних групп между собой, чтобы узнать *какие именно* группы различаются. Также нет ограничения на количество групп, участвующих в сравнении.\n\nВ этом тесте сравнивается каждая группа с каждой, поэтому у него будет минимальная мощность, так как тестов больше всего. Если нам не нужно сравнивать каждую группу с каждой, то лучше использовать тест Даннета, который сравнивает одну группу с остальными и имеет более высокую мощность.\n\nФормула расчета тестовой статистики:\n\n$$ q_s = \\frac{M_1 - M_2}{\\sqrt{\\frac{SS_w}{2}(\\frac{1}{n_A}+\\frac{1}{n_B})}},  $$\n\nгде M~1~ \\> M~2~ (средние в группе), *nA*, *nB* - размер 1 и 2 выборки, $SS_W$ - внутригрупповая сумма квадратов в ANOVA.\n\nДля проверки гипотезы используется studentized range distribution, студентизированное распределение (не путать с t-распределением).\n\nУ теста Тьюки есть допущения к использованию:\n\n-   Независимость наблюдений\n\n-   Примерное равенство дисперсий\n\n-   Примерно нормальное распределение данных в группах\n\nЕсли допущения про нормальность распределения и равенство дисперсий не выполняются, то можно использовать непараметрические аналоги теста.\n\n::: callout-tip\n## Про значимую ANOVA\n\nТест Тьюки вовсе необязательно использовать *только* после значимой ановы, как нередко пишут в учебниках, просто в тесте при расчете используется внутригрупповая сумма квадратов и количество степеней свободы из таблицы ANOVA. Поэтому в докомпьютерное время расчет критерия Тьюки был [проще]{.underline} после дисперсионного анализа, и при незначимой анове сравнивать группы между собой уже не имело смысла. Сейчас в R в функции `TukeyHSD()` для расчета критерия Тьюки в качестве инпута используется результат ановы, но никто не запрещает применять тест и если анова оказалась незначимой.\n\nТакже может быть и ситуация, когда по результатам ANOVA получилось, что средние групп различаются между собой, но при этом по Тьюки нет, можно почитать [здесь](https://stats.stackexchange.com/questions/16665/how-can-i-get-a-significant-overall-anova-but-no-significant-pairwise-difference), почему так бывает.\n:::\n\n## Тест Данна (Dunn)\n\nЯвляется непараметрическим постхок тестом, аналогом теста Тьюки, для ситуаций, когда его допущения не выполняются.\n\nПо сути сравнивает средний ранг групп, вычисленных после теста Краскелла-Уоллиса (Kruskal-Wallis), таким образом как бы учитывая общую дисперсию между группами (чего не будет происходить в попарных тестах Манна-Уитни). Далее полученные p-value должны быть поправлены любым методом, например Бонферрони, Холм, FDR.\n\nЛично мне это в свое время сломало мозг, что это поправка в поправке, вроде используем постхок тест, но при этом его результат тоже нужно поправить тестом на выбор (в функции `dunn_test()` из пакета `rstatix` поправка Холма происходит автоматически).\n\nКак альтернатива, в качестве непараметрического аналога Тьюки можно использовать попарные тесты Манна-Уитни с поправками, однако ранги будут рассчитаны отдельно для каждого теста.\n\nОригинальная статья про метод:\n\nDunn, O. J. (1964) Multiple comparisons using rank sums Technometrics, 6(3):241-252.\n\n## Тест Даннета (Dunnet)\n\nС помощью этого теста сравнивают одну группу с остальными группами, например, когда задача сравнить контрольную группу и несколько воздействий, и не нужно сравнение каждой группы с каждой\n\nНапример, у нас 4 группы, из которой одна группа контрольная, с которой мы проводим сравнения. У нас будет всего 3 сравнения: control - A, control - B, control - C, что увеличивает мощность теста.\n\nДля теста Даннета должны соблюдаться такие же допущения, как и для теста Тьюки: независимость наблюдений, примерно равная дисперсия в группах и нормальное распределение.\n\nПосмотреть детально можно [здесь](https://www.youtube.com/watch?v=5pPd2rLS1GU&list=PLLTSM0eKjC2dvba2A0VCUogEGDch6cXFN&index=8).\n\nТеперь перейдем к принципиально другому подходу поправок -- контроле доли ложных открытий (FDR).\n\n# FDR - false discovery rate\n\n## Определение FDR\n\nFDR, false discovery rate -- доля ложнопозитивных результатов.\n\nВ скрининговых экспериментах, таких как анализ RNA-seq данных важнее контролировать долю ложнопозитивных результатов (FDR), чем вероятность совершить хоть одно ложное открытие.\n\n|                   | H~0~ верна (различий нет) | H~0~ неверна (различие есть) |\n|-------------------|---------------------------|------------------------------|\n| Не отклонить H~0~ | True Negative (TN)        | False Negative (FN)          |\n| Отклонить H~0~    | False Positive (FP)       | True Positive (TP)           |\n\n$$ FDR = \\frac{FP}{FP + TP} $$\n\nПодробнее в этом [видео](https://www.youtube.com/watch?v=-oIkIdhSNeU).\n\n## Расчет FDR\n\nРасмотрим контроль FDR по методу Бенджамини-Хохберга (Benjamini-Hochberg), так как он используется чаще всего. Также FDR можно посчитать с помощью метода Benjamini-Yekutieli, но он имеет меньшую мощность и используется реже.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\np_values <- c(0.361, 0.387, 0.005, 0.009, 0.022, 0.051, 0.101, 0.019)\n```\n:::\n\n\n-   Сортируем и ранжируем p-value по возрастанию;\n-   Каждое p-value умножаем на $\\frac{m}{rank}$, где $m$ -- количество тестов, $rank$ -- ранг p-value.\n\n\n::: {.cell}\n::: {.cell-output-display}\n| pvalue| rank_pvalue|formula     |    result|\n|------:|-----------:|:-----------|---------:|\n|  0.005|           1|0.005*(8/1) | 0.0400000|\n|  0.009|           2|0.009*(8/2) | 0.0360000|\n|  0.019|           3|0.019*(8/3) | 0.0506667|\n|  0.022|           4|0.022*(8/4) | 0.0440000|\n|  0.051|           5|0.051*(8/5) | 0.0816000|\n|  0.101|           6|0.101*(8/6) | 0.1346667|\n|  0.361|           7|0.361*(8/7) | 0.4125714|\n|  0.387|           8|0.387*(8/8) | 0.3870000|\n:::\n:::\n\n\nИтоговое FDR вычисляется так, чтобы p-value не убывали, но при этом приводится в меньшую сторону (в отличие от поправки Холма), поэтому процедура называется пошаговой восходящей -- step-up.\n\n\n::: {.cell}\n::: {.cell-output-display}\n| pvalue| rank_pvalue|formula     |    result| p_adjusted|reject_H0 |\n|------:|-----------:|:-----------|---------:|----------:|:---------|\n|  0.005|           1|0.005*(8/1) | 0.0400000|  0.0360000|yes       |\n|  0.009|           2|0.009*(8/2) | 0.0360000|  0.0360000|yes       |\n|  0.019|           3|0.019*(8/3) | 0.0506667|  0.0440000|yes       |\n|  0.022|           4|0.022*(8/4) | 0.0440000|  0.0440000|yes       |\n|  0.051|           5|0.051*(8/5) | 0.0816000|  0.0816000|no        |\n|  0.101|           6|0.101*(8/6) | 0.1346667|  0.1346667|no        |\n|  0.361|           7|0.361*(8/7) | 0.4125714|  0.3870000|no        |\n|  0.387|           8|0.387*(8/8) | 0.3870000|  0.3870000|no        |\n:::\n:::\n\n\nFDR в основном используется в скрининговых экспериментах, где ключевые результаты могут быть проверены уже более прицельным экспериментом (например некоторые дифференциально экспрессирующиеся гены по результатам RNA-seq проверяют количественной ПЦР).\n\n# Как выбрать поправку?\n\nВсе зависит от задачи. Лично я стараюсь ответить на вопрос, что в конкретном случае важнее контролировать - FWER или FDR. Разумно использовать FDR в массовых экспериментах, где количество тестов исчисляется десятками тысяч, при этом найти ложнопозитивный результат не так страшно. FWER же контролируют в более fine-scale экспериментах, где нам не хотелось бы совершить ошибку первого рода или где ее цена очень высока (исследования на человеке).\n\nЕсли у нас есть конкретный тест, например Тьюки для сравнения групп между собой, то обычно его и используют, если же ситуация более нестандартная, допустим после бутстреп теста нужно сделать поправку на множественное тестирование, то здесь я бы использовала поправку Холма.\n\nВ любом случае нужно опираться на особенности и ограничения тестов, которые я постаралась расписать, надеюсь это поможет выбрать тест ~~мудро~~ правильно.\n\nПосмотреть подробнее про все поправки на множественное тестирование можно в [этой серии](https://www.youtube.com/playlist?list=PLLTSM0eKjC2dvba2A0VCUogEGDch6cXFN) видео от замечательного канала по статистике \\@[TileStats](https://www.youtube.com/@tilestats)\n\nА также подписывайтесь на [телеграм-канал](https://t.me/stats_for_science), делитесь постом, пишите комментарии!\n\n![](figures/logo.jpg)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}