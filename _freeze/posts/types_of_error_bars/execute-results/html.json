{
  "hash": "bbab29be33d8dbb9a09d77078e43d1ca",
  "result": {
    "markdown": "---\ntitle: \"Types of error bars and it's differences\"\nauthor: \"Elena U\"\ndate: \"2022-11-15\"\noutput: \n  html_document:\n        toc: true\n        code_folding: hide\n---\n\n::: {.cell}\n<style type=\"text/css\">\n.spoiler {\n  visibility: hidden;\n}\n\n.spoiler::before {\n  background-color: #d6d6d6;\n  visibility: visible;\n  content: \"Spoiler alert!\"\n}\n\n.spoiler:hover {\n  visibility: visible;\n}\n\n.spoiler:hover::before {\n  display: none;\n}\n</style>\n:::\n\n\nСегодня поговорим о различных видах пределов погрешностей или усов, как пишут в русскоязычной литературе (error bars).\n\n*Предупреждаю сразу: по ходу повествования я буду использовать все варианты написания этого термина, даже слово эррор бар.*\n\nВажно отметить, что существует два принципиально разных вида отображения пределов погрешностей на графике:\n\n-   отражение описательных статистик (descriptive statistics);\n-   отражение статистик вывода (inferential statistics).\n\nОни выглядят на графике одинаково, но по факту фундаментально различны. Давайте разбираться, в чем разница.\n\n## Descriptive error bars (Описательные пределы погрешностей)\n\nК описательным эррор барам относятся:\n\n-   Размах (range): разница между максимальным и минимальным значением в выборке (X~max~ - X~min~).\n-   Межквартильный размах (interquartile range, IQR): разница между третьм квартилем (Q~3~) и первым квартилем (Q~1~.).\n-   Стандартное отклонение (standard deviation, sd): квадратный корень из дисперсии.\n\n**Размах** самая простая для понимания метрика, при этом редко использующаяся, поскольку сама по себе разница между максимальным и минимальным значением довольно-таки малоинформативна.\n\n**Межквартильный размах (IQR)**, точнее 1.5\\*IQR чаще всего используется на боксплотах (boxplot), я редко встречала 1\\*IQR или 1.5\\*IQR как усы к обычным барплотам.\n\n*Барплот (barplot) - столбчатая диаграмма для категориальных данных, их будет много чуть дальше.*\n\n![*Самое простое описание составляющих боксплота*](boxplot.png)\n\nЕсли расставить числа в ряд по возрастанию, то середина этого ряда - медиана (median) или второй квартиль (Q~2~). Первый квартиль (Q~1~) - значение, меньше которого 25% процентов данных, третий квартиль (Q~3~) - значение, меньше которого 75% данных.\n\nДумаю, что на рисунке понять проще:\n\n![*про межквартильный размах (IQR)*](figures/IQR.png){width=\"75%\"}\n\nМежквартильный размах намного чаще используется для визуализации, так как предоставляет больше информации о данных.\n\n**Стандартное отклонение (standard deviation)** по-моему наиболее часто встречается в публикациях и на конференциях (по крайней мере в биологии), да и я обычно использую именно sd в качестве предела погрешностей.\n\nФормула стандартного отклонения (для генеральной совокупности): $$\\Large sd = \\sqrt{var} = \\sqrt{\\frac{\\sum_{i=1}^{N}(x_{i} - \\mu)^2}{N}}$$ Где $\\mu$ - среднее значение в генеральной совокупности, $N$ - размер генеральной совокупности, var (variance) - дисперсия. Но мы обычно работаем с выборками, а не генеральной совокупностью, и в формуле вычисления sd в Excel и R используют *несмещенную (unbiased)* оценку дисперсии и стандартного отклонения (потому что для выборки): $$\\Large sd = \\sqrt{var} = \\sqrt{\\frac{\\sum_{i=1}^{N}(x_{i} - \\overline{x})^2}{N-1}}$$ Почему именно $N-1$ в знаменателе выходит за рамки нашего обсуждения, поэтому ограничусь ссылками: [1](https://www.quora.com/Why-do-we-use-n-1-instead-of-n-for-a-samples-variance), [2](https://stats.stackexchange.com/questions/198452/why-sample-variance-has-has-n-1-in-the-denominator), [видео с таймкодом](https://youtu.be/SzZ6GpcfoQY?t=435).\n\nЕще не сделала схему с детальным вычислением стандартного отклонения на реальных данных, поэтому пока можно посмотреть на [статквесте](https://www.youtube.com/watch?v=SzZ6GpcfoQY).\n\nВажный момент! Все вышеописанные метрики отражают разброс значений в нашей **выборке**, без каких-либо предположений о происходящем в генеральной совокупности. В этом отличие от второго типа error bar.\n\n## Inferential error bars\n\nК эррор барам, отражающим статистики вывода относятся:\n\n-   Стандартная ошибка среднего (standard error of mean, sem или просто SE)\n-   Доверительный интервал (confidence interval, CI)\n\nПринципиальное отличие от описательных пределов погрешности в том, что грубо говоря, стандартная ошибка среднего/доверительный интервал пытаются отразить степень уверенности в поиске к примеру *истинного среднего* генеральной совокупности. В то время как описательные отражают, что происходит конкретно в *нашей выборке*.\n\nТут немного инфы для продвинутых (не открывайте, если не уверены, что хотите это знать!):\n\n[Небольшое уточнение: с помощью бутстрепов можно оценивать не только доверительный интервал и стандартную ошибку для среднего, но и для медианы и даже для стандартного отклонения, но про это сейчас не будем]{.spoiler}\n\n### Стандартная ошибка среднего\n\nТеперь еще немного вымученных формулировок, которые попробую сформулировать понятнее.\n\nВымученная формулировка: *The standard error (SE) of a statistic is the standard deviation of its sampling distribution or an estimate of that standard deviation.* (цитата прямо из [википедии](https://en.wikipedia.org/wiki/Standard_error))\n\nФормула вычисления стандартной ошибки среднего очень простая - стандартное отклонение, деленное на квадратный корень из размера выборки. Но что на самом деле это значит, какой физический смысл стоит за результатом этого вычисления? Попробуйте сами ответить на этот вопрос, опираясь только на определение из википедии и формулу)\n\nТеперь попробуем представить, что мы провели некий эксперимент, например измеряли вес 20 мышей после какого-либо воздействия и усредняли полученные значения. При этом мы решили 10 раз повторить свой эксперимент, в результате чего получили 10 средних значений. После этого мы можем посчитать среднее средних (!) и **стандартное отклонение средних**. Вот это стандартное отклонение выборочных средних и есть стандартная ошибка среднего. Ура? Пойду воспроизводить эксперимент по 10 раз?\n\nНо мы не всегда (обычно никогда) можем себе позволить повторять эксперимент по 10 раз, и хитрость в том, что мы можем вычислить стандартную ошибку среднего без многократного повторения эксперимента, просто поделив стандартное отклонение на квадратный корень из размера выборки.\n\nВот [тут](https://pozdniakov.github.io/tidy_stats/310-infer_stats.html#sec-sample_dist) хорошо расписано, как моделировать стандартную ошибку средних и что она действительно соответствует стандартному отклонению, деленному на квадратный корень из числа наблюдений.\n\n$$\\huge SE = \\frac{sd}{\\sqrt{N}}$$ *Формула SE (стандартной ошибки), где sd - это стандартное отклонение, N - количество наблюдений*\n\nВот еще можно посмотреть про:\n\n-   отличия стандартного отклонения от стандартной ошибки <https://www.youtube.com/watch?v=SzZ6GpcfoQY>\n-   объяснение стандартной ошибки с бутстреп-примером <https://www.youtube.com/watch?v=XNgt7F6FqDU&t=341s>\n\nВ [статье](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2064100/), на которую я опиралась при написании этого материала, было указано, что для представления сравнения групп лучше использовать стандартную ошибку/доверительный интервал как error bar, а не стандартное отклонение и другие описательные статистики.\n\nНо у меня есть неприятное подозрение, что для публикаций и представлений своей работы на конференциях некоторые недобросовестные ученые используют se, чтобы на графиках были усы поменьше. Однако, я не хочу обидеть тех, кто использует стандартную ошибку и понимает физический смысл. Интересно будет собрать примеры работ, где использование se оправданно и разумно, и где это не так, поэтому если есть примеры, то пишите в комментарии.\n\nВ целом, плюс именно se в том, что при отрисовке сравнений двух или нескольких групп, перекрываемость усов позволяет судить об отсутствии статистической значимости различий (при этом наоборот не работает, про это будет еще чуть дальше), в то время как sd и остальные описательные пределы погрешностей - нет. Однако sd показывает данные почти как они есть, то есть реальный разброс в наших данных, без предположений о генеральной совокупности, поэтому лично я предпочитаю sd для отрисовки. Это тоже интересная тема для дискуссии, буду рада обсудить в комментариях.\n\nИ наконец...\n\n### Доверительный интервал\n\nЕсли простыми словами, то доверительный интервал оценивает диапазон, в котором с заданной уверенностью (например 95%), можно ожидать истинное значение параметра, например среднего генеральной совокупности.\n\nПрикрепляю формулу (кстати все формулы записаны прямо силами Rmarkdown):\n\n$$\\huge CI = \\overline{x} ± z\\frac{s}{\\sqrt{n}}$$\n\nФормула доверительного интервала (CI), $\\overline{x}$ - среднее значение выборки, z - значение уровня достоверности, например для 95% уровня достоверности, $z = 1.96$, $\\frac{s}{\\sqrt{n}}$ - формула уже знакомой стандартной ошибки.\n\nВообще я не люблю эту тему, но к счастью уже существует немало источников, которые объяснили доверительный интервал разными способами:\n\n-   В [книге](https://pozdniakov.github.io/tidy_stats/310-infer_stats.html#sec-ci_build) у Ивана объяснение доверительных интервалов классическим образом через формулу стандартной ошибки;\n\n-   Классное объяснение доверительных интервалов с помощью бутстрепа на [статквесте](https://www.youtube.com/watch?v=TqOeMYtOc1w&t=325s) (канал супер, всем рекомендую);\n\n-   Бонусом для тех, кому это все слишком просто: я нашла совершенно дикую статью про доверительные интервалы, доверительные полосы и доверительные эллипсы (sic!), поэтому кто желает преисполниться - велком (вот [ссылка](https://r-analytics.blogspot.com/2018/04/blog-post_28.html?m=1)). Краткого пересказа не будет, это надо прочитать самостоятельно.\n\nНебольшой вывод. Отрисовка доверительных интервалов сейчас считается модной, якобы их проще интерпретировать. Но на самом деле доверительный интервал как и p-value - это один из тех концептов, которые провоцируют просто огромное количество мисинтерпретаций, это кстати одна из причин, по которой я это не люблю рассказывать. Важно сейчас отметить вот что:\n\n![*Интерпретация перекрывания inferential error bars. Ссылка на [статью](https://www.graphpad.com/support/faq/spanwhat-you-can-conclude-when-two-error-bars-overlap-or-dontspan/), откуда картинка*](figures/se_overlap.png)\n\nТаким образом, **перекрывание** стандартных ошибок говорит об **отсутствии** значимости в различии, при этом обратное не верно, а с доверительными интервалами наоборот - **отсутствие перекрывания** доверительных интервалов говорит о **значимости** различий, в то время обратное не верно.\n\nВ этом смысле мне нравится концепция стандартного отклонения, потому что их перекрывание или не перекрывание не говорит нам вообще ничего, а значит - нельзя запутаться!). Чуть дальше разберем, как выглядят разные пределы погрешностей!\n\n**В любом случае, вне зависимости какой тип пределов погрешностей вы выбрали для отображения на графике, всегда нужно подписывать какой, потому что интерпретации совершенно разные.**\n\n## А что если вообще не рисовать пределы погрешностей?\n\nЕсли число значений в выборке невелико (например меньше 10), то лучше нарисовать все числа как они есть, например с помощью диаграммы рассеяния (scatter plot) без редуцирования информации в боксплоты или барплоты с пределами погрешностей. Если значений больше, то возможно множество вариантов отрисовывания, часто исследователи используют просто барплоты с пределами погрешностей или боксплоты, однако здесь я предлагаю два возможных варианта более репрезентативного отображения данных.\n\nПервый - это отрисовать violin plot (скрипичная диаграмма), но не просто, а с небольшим боксплотом внутри. Я эту идею подчерпнула на курсе бластима по R, мне показалось очень забавно, прикрепляю небольшой пример как это выглядит на примере данных `iris`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nviolin_box <- iris %>% \n  ggplot(aes(x = Species, y = Sepal.Width))+\n  geom_violin(aes(fill = Species))+\n  geom_boxplot(width = 0.15, alpha = 0.8)+\n  theme_bw()\nviolin_box\n```\n\n::: {.cell-output-display}\n![](types_of_error_bars_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nВторой вариант больше подойдет для относительно небольшого количества наблюдений, когда счет идет на десятки, но не тысячи точек. Это комбинация боксплота и отображения точек как они есть с помощью `geom_jitter` в библиотеке ggplot2.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbox_point <- iris %>% \n  ggplot(aes(Species, Sepal.Width))+\n  geom_boxplot()+\n  geom_jitter(aes(colour = Species), \n              position = position_jitter(width = 0.3, height = 0),\n              alpha = 0.6, size = 1.5)+\n  theme_bw()\nbox_point\n```\n\n::: {.cell-output-display}\n![](types_of_error_bars_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nПо моему прикольно получилось! Эти варианты визуализации содержат гораздо больше информации, сравните например с обычными боксплотами и барплотами (здесь как предел погрешности использовала стандартное отклонение).\n\n------------------------------------------------------------------------\n\n📝 UPD: в комментариях посоветовали напомнить, что перекрывание или не-перекрывание усов в боксплотах и вайлин плотах не имеет отношения к статистике вывода, то есть не позволяет делать выводы о значимости различий\n\n------------------------------------------------------------------------\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbox <- iris %>% \n  ggplot(aes(Species, Sepal.Width, fill = Species))+\n  geom_boxplot()+\n  theme_bw()\nbar <- iris %>% \n  group_by(Species) %>% \n  summarise(mean_PW = mean(Sepal.Width), sd_PW = sd(Sepal.Width)) %>% \n  ggplot(aes(Species, mean_PW, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean_PW - sd_PW, ymax = mean_PW + sd_PW), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are standard deviation')+\n  theme_bw()\nbox\n```\n\n::: {.cell-output-display}\n![](types_of_error_bars_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbar\n```\n\n::: {.cell-output-display}\n![](types_of_error_bars_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\nА теперь все вместе на одном графике (обратите внимание на библиотеку `patchwork` для красивого объединения плотов на одном рисунке):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\np <- (violin_box + box_point) / (box + bar)\np + plot_annotation(tag_levels = 'A')\n```\n\n::: {.cell-output-display}\n![](types_of_error_bars_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nГолосуйте, какой плот больше нравится и является более информативным. Мне лично здесь нравится вариант B - box+точки, кажется наиболее информативным и красивым. Возможно, если наблюдений будет больше, то лучше окажется первый вариант с вайлином плотом и боксом.\n\n------------------------------------------------------------------------\n\n📝 В violin plot-е (скрипичная диаграмма) форма отражает плотность распределения значений. Грубо говоря, чем больше значений в диапазоне, тем толще соответствующий диапазон на графике. В случае `geom_jitter` по оси X важна только принадлежность точек к группе, внутри одной группы точки по оси X распределяются так, чтобы не перекрывать друг друга.\n\n------------------------------------------------------------------------\n\nА теперь визуализация трех основных пределов погрешностей: стандартного отклонения, стандартной ошибки и доверительных интервалов на данных `iris`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nbar_se <- iris %>% \n  group_by(Species) %>% \n  summarise(mean_PW = mean(Sepal.Width), se_PW = sd(Sepal.Width)/sqrt(length(Sepal.Width))) %>% \n  ggplot(aes(Species, mean_PW, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean_PW - se_PW, ymax = mean_PW + se_PW), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are standard error')+\n  theme_bw()\n# bar_se\n\nbar_CI <- iris %>% \n  group_by(Species) %>%\n  summarise(n=n(), mean=mean(Sepal.Length), sd=sd(Sepal.Length)) %>%\n  mutate(se = sd/sqrt(n))  %>%\n  mutate(ic = se * qt((1-0.05)/2 + .5, n-1)) %>% \n  ggplot(aes(Species, mean, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean - ic, ymax = mean + ic), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are confidence intervals')+\n  theme_bw()\n# bar_CI\nbar + bar_se + bar_CI+  plot_layout(ncol = 2)\n```\n\n::: {.cell-output-display}\n![](types_of_error_bars_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nТеперь я сделаю одну плохую вещь, а именно **просто** сравню тестом Стьюдента Sepal.Width для разных видов ириса. Как думаете, почему это плохо?\n\n[Я в этом примере не делаю поправку на множественное тестирование]{.spoiler}\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris %>% \n  setDT() \ncat('versicolor vs setosa: \\np-value of the test', t.test(iris[Species == 'setosa', Sepal.Width], iris[Species == 'versicolor', Sepal.Width])$p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nversicolor vs setosa: \np-value of the test 2.484228e-15\n```\n:::\n\n```{.r .cell-code}\ncat('setosa vs virginica: \\np-value of the test', t.test(iris[Species == 'setosa', Sepal.Width], iris[Species == 'virginica', Sepal.Width])$p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsetosa vs virginica: \np-value of the test 4.570771e-09\n```\n:::\n\n```{.r .cell-code}\ncat('virginica vs versicolor: \\np-value of the test', t.test(iris[Species == 'virginica', Sepal.Width], iris[Species == 'versicolor', Sepal.Width])$p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nvirginica vs versicolor: \np-value of the test 0.001819483\n```\n:::\n:::\n\n\nНо один раз в жизни можно, только для демонстрации того, что все выборки значимо отличаются друг от друга (без поправки), и на графиках можно увидеть что доверительные интервалы не перекрываются.\n\nУра! Я дописала, а вы дочитали, с чем я всех и поздравляю) Теперь перейдем к выводам.\n\n## Выводы\n\n1.  Существует два типа отображения пределов погрешностей на графике: описательные, которые *описывают* значения в конкретно нашей выборке и inferential (так и не придумала как переводить), которые пытаются отразить что-то о генеральной совокупности с заданной долей уверенности.\n2.  Для отображения сравнений между группами рекомендуют использовать вторые, поскольку они позволяют делать выводы из перекрывания или не-перекрывания усов.\n3.  Однако, есть способы рисовать распределение наших значений без использования мисинтерпретируемых пределов погрешностей, например violin+boxplot и boxplot+точки\n\nПодписывайтесь на телеграм канал: <https://t.me/stats_for_science>, будет много интересного\n\n![](figures/logo.jpg)\n",
    "supporting": [
      "types_of_error_bars_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}