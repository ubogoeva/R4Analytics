---
title: "Тест Стьюдента и тест Велча"
author: "Elena U"
date: "2024-10-06"
format: html
editor: visual
categories: statistics
draft: true
---

## Проблема дорожных карт по статистике

Наверняка каждый при проведении статистических тестов сталкивался с проблемой выбора подходящего теста. В научном сообществе есть определенная популярность у "дорожных карт" по выбору статистического метода, пример ниже:

[![Можно кликнуть на картинку и перейти на изображение в лучшем качестве](https://onishlab.colostate.edu/wp-content/uploads/2019/07/which_test_flowchart.png)](https://onishlab.colostate.edu/wp-content/uploads/2019/07/which_test_flowchart.png)

Я выбрала первую попавшуюся схему по запросу `how to choose statistical test flow chart`, в этой схеме есть сразу несколько ошибок, например миф про 30 наблюдений (тут вообще странное, по мнению автора схемы, при размере выборки больше 30 наблюдений можно использовать z-test).

Обычно этот миф звучит так: для небольших выборок меньше 30 наблюдений для применения t-теста нужно, чтобы было нормальное распределение данных, а если наблюдений больше 30, то можно использовать t-тест и так, в силу центральной предельной теоремы. Почему это миф, написано в статье "[История одного обмана или требования к распределению в t-тесте](https://koch-kir.medium.com/история-одного-обмана-или-требования-к-распределению-в-статистических-тестах-55139a5558d)".\
Статья подвергалась определенной критике профильных статистиков, но ключевой момент отражен верно — для t-теста не нужно нормальное распределение *данных*, нужно нормальное распределение *тестовой статистики* — то есть выборочных средних. Про это подробно собирается написать статистик **Матвей Славенко**, я обязательно сделаю репост, когда статья выйдет, очень нужен для сообщества такой материал.

Но вернемся к тесту.

## Тест Велча

Часто также можно встретить требование к равенству дисперсий для теста Стьюдента и это правильное требование, если использовать классический тест Стьюдента. Однако в большинстве статистических пакетов, в том числе в R, реализован тест Стьюдента с поправкой Велча (Welch) или просто тест Велча, для которого нет требования по соблюдению равенства дисперсий.

Формула теста Стьюдента:

$$
t = \frac{\overline{X_1}-\overline{X_2}}{s_x\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}},
s_x = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}
$$

Чтобы запустить именно тест Стьюдента в R, можно использовать аргумент `var.equal = TRUE`.

```{r}
#t.test(iris$ ~ wc3_units_armor$armor_type, 
 #      var.equal = TRUE)
```

Однако это делать не рекомендуется, поскольку при равных дисперсиях тест Стьюдента не будет сильно отличаться от теста Велча, а при разных тест Велча точнее.

Формула теста Велча:

$$
t = \frac{\overline{X}_1 - \overline{X}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

Количество степеней свободы:

$$
df = \frac{(s_1^2/n_1 + s_2^2 / n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}
$$

Для обучения я обычно рассказываю тест Стьюдента без поправки Велча, потому что на нем проще посчитать вручную тестовую статистику и степени свободы, однако потом обязательно уточняю, что для теста Велча требование равенства дисперсий необязательно. При этом в источниках часто можно встретить требование к равенству дисперсий, как и к нормальности распределения исходных данных.

Однако наиболее критичным требованием для проведения теста Стьюдента является независимость наблюдений, п~~отому что от этого нарушаются математика теста и результаты получаются ненадежные.~~

## Проверим на симуляциях

```{r}
#| message: false
library(tidyverse)
```

Разберем разные кейсы: проверим и ошибку первого рода и мощность теста.

Здесь и далее тестом Стьюдента будет называться тест Стьюдента без поправок, а тестом Велча - тест Стьюдента с поправкой Велча

## Отличий нет, проверка на ошибку первого рода

### Одинаковое среднее и дисперсия, равный размер выборок

Начнем с ситуации когда у нас обе выборки из генеральных совокупностей с одинаковым средним и дисперсией, например, здесь это нормальное распределение со средним 0.2 и стандартным отклонением 1.

::: callout-note
Здесь и в дальнейшем для симуляций будет создаваться генеральная совокупность (размером 100000) с заданными параметрами среднего и стандартного отклонения, а далее будут многократно извлекаться "выборки" заданного размера. Таким образом будет соблюдаться общая логика статистического вывода — наличие генеральной совокупности с заданными параметрами и создание выборки.
:::

Тест Велча

```{r}
#| cache: true
population <- rnorm(100000, mean = 0.2, sd = 1) # создание генеральной совокупности
p_values <- replicate(1000, t.test(population %>% 
                              sample(size = 10000, replace = FALSE), 
                            population %>% 
                              sample(size = 10000, replace = FALSE))$p.value)
hist(p_values)
mean(p_values < 0.05) # доля p-value, которые оказались меньше 0.05 (прокрасились) 
```

Тест Стьюдента

```{r}
#| cache: true
p_values <- replicate(1000, t.test(population %>% 
                              sample(size = 10000, replace = FALSE), 
                            population %>% 
                              sample(size = 10000, replace = FALSE), 
                            var.equal = TRUE)$p.value)
hist(p_values)
mean(p_values < 0.05) # доля p-value, которые оказались меньше 0.05 (прокрасились)
```

Здесь у нас вероятность ошибки первого рода для обоих тестов примерно 0.05, а также распределение p-value похоже на равномерное, что ожидаемо и корректно, так как выборки извлекались из одинаковой генеральной совокупности.

### Одинаковое среднее, разная дисперсия, равный размер выборок

Теперь рассмотрим случай с неравными дисперсиями. Для этого создадим две генеральные совокупности с одинаковым средним, но в одной стандартное отклонение 1, в другой 2. Извлекаем две выборки размером 10000 значений и сравниваем их тестом Стьюдента и тестом Велча.

Тест Велча

```{r}
#| cache: true
population1 <- rnorm(100000, mean = 0.2, sd = 1) # создание первой генеральной совокупности
population2 <- rnorm(100000, mean = 0.2, sd = 2) # создание второй генеральной совокупности
# проведение теста
p_values_welch <- replicate(10000, t.test(population1 %>% 
                                      sample(size = 10000, replace = FALSE), 
                                    population2 %>% 
                                      sample(size = 10000, replace = FALSE))$p.value)
hist(p_values_welch)

mean(p_values_welch < 0.05)

```

Тест Стьюдента

```{r}
#| cache: true
# проведение теста
p_values_st <- replicate(10000, t.test(population1 %>% 
                                      sample(size = 10000, replace = FALSE), 
                                    population2 %>% 
                                      sample(size = 10000, replace = FALSE), 
                                    var.equal = TRUE)$p.value)
hist(p_values_st)
mean(p_values_st < 0.05)
```

Вроде ничего страшного и не случилось, в ситуации с неравными дисперсиями оба теста хорошо работают. Тут важно указать, что размер выборок в данном примере одинаковый. Однако тест Стьюдента без поправки Велча становится неустойчивым с точки зрения ошибки первого рода, в случае, когда у нас выборки сильно отличаются по размеру.

### Одинаковое среднее, разная дисперсия, разный размер выборок

Например, в одной выборке 3000 наблюдений, в другой 7000.

```{r}
#| cache: true
mean(replicate(10000, t.test(population1 %>% 
                               sample(size = 7000, replace = FALSE), 
                             population2 %>% 
                               sample(size = 3000, replace = FALSE))$p.value) < 0.05)
mean(replicate(10000, t.test(population1 %>% 
                               sample(size = 7000, replace = FALSE), 
                             population2 %>% 
                               sample(size = 3000, replace = FALSE), 
                             var.equal = TRUE)$p.value) < 0.05)
```

Получилось, что тест Стьюдента в ситуации с неравными дисперсиями и разным размером выборки показал себя хуже и мы наблюдали ложные прокрасы в 12% случаев (вместо 5%, как должно было бы быть).

С увеличением дисбаланса в размере выборок, ситуация становится хуже, например, вот что произойдет, если выборки отличаются по размеру в 9 раз (это вполне может встретиться в ситуации, когда мы показываем 10% пользователей тестовую версию, а в контроле у нас 90% пользователей).

::: callout-tip
Это может быть нормально для A/B тестирования, когда мы показываем 10% пользователей тестовую версию, а в контроле у нас 90% пользователей
:::

```{r}
#| cache: true
mean(replicate(10000, t.test(population1 %>% 
                               sample(size = 9000, replace = FALSE), 
                             population2 %>% 
                               sample(size = 1000, replace = FALSE))$p.value) < 0.05) # тест Велча
mean(replicate(10000, t.test(population1 %>% 
                               sample(size = 9000, replace = FALSE), 
                             population2 %>% 
                               sample(size = 1000, replace = FALSE), 
                             var.equal = TRUE)$p.value) < 0.05) # тест Стьюдента
```

Тут для теста Стьюдента без поправки Велча получилось 24% ложноположительных результатов, что достаточно много.

При увеличении неравенства дисперсий наблюдается и ухудшение работы теста Стьюдента без поправки Велча (для выборок разного размера).

Давайте построим график зависимости ошибки первого рода от неравенства дисперсий в выборке, сохраняя пропорцию 1 к 9.

```{r}
#| cache: true
var_size <- seq(0, 5, 0.5)
calculate_mean_error_1st_type <- function(x, var.equal) {
  mean(replicate(1000, 
                 t.test(rnorm(9000, 0.2, 1), 
                        rnorm(1000, 0.2, 1+x), 
                        var.equal = var.equal)$p.value) < 0.05)
}
welch_error_1st_type <- map_dbl(var_size, ~calculate_mean_error_1st_type(., FALSE))
students_error_1st_type <- map_dbl(var_size, ~calculate_mean_error_1st_type(., TRUE))

data.frame(var_size, welch_error_1st_type, students_error_1st_type) %>% 
  pivot_longer(cols = c(welch_error_1st_type, students_error_1st_type), 
               names_to = 'type', values_to = 'error_1st_type') %>% 
  ggplot(aes(var_size, error_1st_type))+
  geom_point(aes(color = type))+
  geom_line(aes(color = type))+
  scale_x_continuous(name = 'Разница в стандартном отклонении между выборками')+
  ggtitle('Зависимость ошибки первого рода от стандартного отклонения', subtitle = 'для теста Стьюдента и теста Велча при дисбалансе выборок')+
  theme_bw()

```

При этом при равных размерах выборок, разница в дисперсиях не влияет на оба теста.

```{r}
#| cache: true
#| code-fold: show
var_size <- seq(0, 5, 0.5)
calculate_mean_error_1st_type <- function(x, var.equal) {
  mean(replicate(1000, t.test(rnorm(1000, 0.2, 1), rnorm(1000, 0.2, 1+x), var.equal = var.equal)$p.value) < 0.05)
}
welch_error_1st_type <- map_dbl(var_size, ~calculate_mean_error_1st_type(., FALSE))
students_error_1st_type <- map_dbl(var_size, ~calculate_mean_error_1st_type(., TRUE))

data.frame(var_size, welch_error_1st_type, students_error_1st_type) %>% 
  pivot_longer(cols = c(welch_error_1st_type, students_error_1st_type), 
               names_to = 'type', values_to = 'error_1st_type') %>% 
  ggplot(aes(var_size, error_1st_type))+
  geom_point(aes(color = type))+
  geom_line(aes(color = type))+
  scale_x_continuous(name = 'Разница в стандартном отклонении между выборками')+
  ggtitle('Зависимость ошибки первого рода от стандартного отклонения', 
          subtitle = 'для теста Стьюдента и теста Велча для равных выборок')+
  theme_bw()
```

Таким образом, при одинаковом размере выборок, тест Стьюдента также устойчив и к нарушению предположения о равенстве дисперсий.

::: callout-note
## Оффтоп

Кстати, и у теста Манна-Уитни не все хорошо в таком примере

```{r}
#| cache: true
mean(replicate(1000, wilcox.test(rnorm(9000, 0.2, 1), rnorm(1000, 0.2, 2))$p.value) < 0.05)
```
:::

Давайте немного усложним и используем логнормальное распределение для проверки ошибки первого рода в случае, когда генеральная совокупность распределена не нормально.

### Логнормальное распределение, равные дисперсии

Здесь добавить ген совокупность

```{r}
#| cache: true
population_log <- rlnorm(100000, 0, 1)
mean(replicate(10000, t.test(population_log %>% 
                               sample(10000, replace = FALSE), 
                             population_log %>% 
                               sample(10000, replace = FALSE))$p.value) < 0.05)
mean(replicate(10000, t.test(population_log %>% 
                               sample(10000, replace = FALSE), 
                             population_log %>% 
                               sample(10000, replace = FALSE), 
                             var.equal = TRUE)$p.value) < 0.05)
```

Даже для логнормального распределения, оба теста контролируют ошибку первого рода на уровне \< 0.05.

Теперь расммотрим симуляции, когда отличия действительно есть, как поведут себя тесты в этом случае.

## Отличия есть, проверка на мощность теста

### Разное среднее, одинаковая дисперсия, равный размер выборок

Начнем с ситуации, когда мы добавили небольшой аплифт для одной из генеральной совокупности.

График выборок

```{r}
#| cache: true
#| warning: false
pop1 <- rnorm(100000, 0.2, 1)
pop2 <- rnorm(100000, 0.3, 1)
data.frame(x = pop1 %>% sample(10000, replace = FALSE), 
           y = pop2 %>% sample(10000, replace = FALSE)) %>% 
  rownames_to_column(var = 'id') %>% 
  pivot_longer(cols = c(x, y)) %>% 
  ggplot(aes(value, fill = name))+
  geom_histogram(alpha = 0.5)+
  facet_wrap(~name, nrow = 2)+
  theme_bw()
```

Тест Велча

```{r}
#| cache: true
p_value <- replicate(10000, t.test(pop1 %>% 
                               sample(10000, replace = FALSE), 
                             pop2 %>% 
                               sample(10000, replace = FALSE))$p.value)
hist(p_value)
mean(p_value < 0.05)
```

Тест Стьюдента

```{r}
#| cache: true
p_value <- replicate(10000, t.test(pop1 %>% 
                               sample(10000, replace = FALSE), 
                             pop2 %>% 
                               sample(10000, replace = FALSE), 
                            var.equal = TRUE)$p.value)
hist(p_value)
mean(p_value < 0.05)
```

Оба теста нашли отличия там где они есть в 100% случаев, что достаточно хорошо.

Добавим неравенство дисперсий.

### Разное среднее, разная дисперсия, равный размер выборок

```{r}
#| cache: true
pop1 <- rnorm(100000, 0.2, 1)
pop2 <- rnorm(100000, 0.3, 3)
mean(replicate(10000, t.test(pop1 %>% 
                               sample(10000, replace = FALSE), 
                             pop2 %>% 
                               sample(10000, replace = FALSE))$p.value) < 0.05)
```

```{r}
#| cache: true
mean(replicate(10000, t.test(pop1 %>% 
                               sample(10000, replace = FALSE), 
                             pop2 %>% 
                               sample(10000, replace = FALSE),
                             var.equal = TRUE)$p.value) < 0.05)
```

При равных размерах выборок оба теста хорошо справляются с неравенством дисперсий

### Разное среднее, разная дисперсия, разный размер выборок

```{r}
#| cache: true
pop1 <- rnorm(100000, 0.2, 1)
pop2 <- rnorm(100000, 0.3, 3)
mean(replicate(10000, t.test(pop1 %>% 
                               sample(3000, replace = FALSE), 
                             pop2 %>% 
                               sample(7000, replace = FALSE))$p.value) < 0.05)
```

```{r}
#| cache: true
mean(replicate(10000, t.test(pop1 %>% 
                               sample(3000, replace = FALSE), 
                             pop2 %>% 
                               sample(7000, replace = FALSE),
                             var.equal = TRUE)$p.value) < 0.05)
```
