---
title: "Разбор курса 'Основы статистики'"
author: "Elena U"
format: html
editor: visual
date: "2025-02-01"
draft: true
---

По итогам многочисленных дискуссий в чатах по статистике и биоинформатике ([*BioStat \<- R \| Чат по статистике и R*](https://t.me/chat_biostat_R), [*BIOINF \| Education & Career*](https://t.me/bioinf_career)), я решила пересмотреть на удвоенной скорости курс ["Основы статистики"](https://stepik.org/course/76/syllabus) на платформе stepik самостоятельно. Давайте разберем его достоинства и недостатки, а также есть ли смысл его смотреть сейчас.

## Структура курса

Курс состоит из трех блоков:

1.  Введение, выборка и генеральная совокупность, типы переменных, описательная статистика, ЦПТ, p-value.
2.  Сравнение средних: t-test, однофакторная и многофакторная ANOVA, проблема множественных тестирований.
3.  Корреляция и регрессия.

Из достоинств данного курса стоит отметить, что он был создан в то время, когда было очень мало русскоязычных материалов по статистике такого формата. Да, были книги, но лекций на интерактивных платформах с возможностью проверять себя -- не было.

Я сама посмотрела курс примерно в 2018 году, после довольно слабого курса по статистике в университете и для меня курс "Основы статистики" был относительно полезен для старта, после чего продолжила изучать статистику преимущественно по книгам (а сейчас преподаю сама). В тот момент курс показался очень качественным, понравился простой язык изложения, не перегруженность формулами, формат заданий и их проверки (это преимущество в целом интерактивных платформ по типу stepik, coursera, не только конкретного курса).

Понравился расчет F-значений в дисперсионном анализе вручную.

С учетом начинающего уровня, на тот момент не увидела больших проблем в курсе, но со временем решила пересмотреть.

*Да, я не совсем поняла объяснение центральной предельной теоремы, но на тот момент это было не единственное, что осталось непонятным, поэтому не заподозрила авторов курса в неверном объяснении. Потом в чатах увидела, что очень многие критикуют курс, в том числе из-за некорректного объяснения центральной предельной теоремы (почитать можно [здесь](https://vk.com/@dmitry_penzar-stats-and-pulverization)) и наконец решила пересмотреть и расписать самостоятельно. Обнаружила, что лектор очень неаккуратно обращается с терминами, формулировками, неверно объясняет значение ЦПТ и интерпретацию доверительных интервалов.*

Разберем наиболее существенные неточности от самых серьезных к менее серьезным и в разбивке по блокам курса. Платформа степик к сожалению не позволяет делать ссылки с таймкодами, поэтому буду прикреплять ссылки на видео и подписывать время в тексте.

## Неверная интерпретация доверительных интервалов

Вот [тут](https://stepik.org/lesson/9249/step/8?unit=1829) было что-то совсем странное с интерпретацией доверительных интервалов (с 1.05).

::: {.callout-note appearance="simple"}
## Текст

"Потому что если у нас среднее номер 2 не попадает в доверительный интервал для среднего номер 1, и наоборот, среднее номер 1 не попадает в доверительный интервал для среднего номер 2, то такие различия у нас будут достигать уровня статистической значимости".
:::

[![Скриншот из видео](images/conf_interval.PNG)](https://stepik.org/lesson/9249/step/8?unit=1829)

Допустим, не будем придираться к формулировке, что различия будут достигать уровень статистической значимости (?), хотя на самом деле это сомнительная формулировка, но интерпретация доверительных интервалов совсем неверная.

Я [писала](https://ubogoeva.github.io/R4Analytics/posts/types_of_error_bars.html) про доверительные интервалы и пределы погрешностей. В двух словах: отсутствие перекрывания 95% доверительных интервалов говорит о статистически значимых различиях (p \< 0.05), но речь идет именно о перекрывании *усов*, а вовсе не о том, что доверительный интервал одной выборки не перекрывается со средним второй. Перекрывание со средним ничего не значит, а что на картинке выше доверительные интервалы перекрываются, не говорит о том, что различий нет, поскольку только *отсутствие* перекрывания говорит о статистически значимых различиях (вот [здесь](https://ubogoeva.github.io/R4Analytics/posts/types_of_error_bars.html#%D0%B4%D0%BE%D0%B2%D0%B5%D1%80%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9-%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%B2%D0%B0%D0%BB) подробнее писала). *Наличие* перекрывания *не* говорит о том, что различий нет.

Считаю это очень серьезной неточностью и даже ошибкой курса, учитывая, что в целом доверительный интервал как явление дает простор для мисинтерпретации, так еще и в курсе приведено заведомо неверное объяснение.

## Про центральную предельную теорему

Дмитрий Пензар достаточно подробно про это [расписал](https://vk.com/@dmitry_penzar-stats-and-pulverization), я здесь упомяну, что в формулировке Карпова ЦПТ становится практически бесполезной.

Основная суть ЦПТ в том, что **какой бы ни была форма распределения в генеральной совокупности, выборочное распределение средних будет стремиться к нормальному** (еще должно быть конечное среднее и дисперсия). для признака, которые обладает конечными средним и дисперсией, и даже распределен ненормально,

**согласно центральной предельной теореме *(ЦПТ, central limit theorem)*, какой бы ни была форма распределения в генеральной совокупности, выборочное распределение средних будет стремиться к нормальному.**

Основная магия ЦПТ состоит в том, что для признака, который даже распределен не-нормально и обладает конечными средним и дисперсией, то выборочные средние будут распределены нормально.

Проверим на примере лог-нормального распределения

```{r}
hist(rlnorm(1000), breaks = 30)
```

Извлечем тысячу раз выборки размером 100, посчитаем среднее и построим их распределение

```{r}
samp_means_log <- replicate(1000, mean(rlnorm(100))) 
hist(samp_means_log, breaks = 30)
```

Распределение средних из изначально ненормального распределения (логнормального) получилось очень похожим на нормальное распределение. Это получается благодаря центральной предельной теореме.

Вот тут можно посмотреть еще: [Шайни апп для центральной предельной теоремы](https://gallery.shinyapps.io/CLT_mean/), особенно впечатляет, что распределение выборочных средних даже из равномерного распределение также будет распределено нормально.

## Терминологические неточности

Сюда относятся многочисленные "принять альтернативную гипотезу", "статистически достоверно" вместо статистически значимо, соберем их в одном месте:

-   "[Принять альтернативную гипотезу](https://stepik.org/lesson/8078/step/6?unit=1358)" 0:38

-   В ответах к [заданию](https://stepik.org/lesson/8083/step/8?unit=1362) "принимаем нулевую гипотезу"

-   "[Считать наши значения статистически достоверными](https://stepik.org/lesson/8078/step/7?unit=1358)" 0.50

-   "[Принимаем различия статистически достоверными](https://stepik.org/lesson/8085/step/3?unit=1364)" 1.26 1.45 3.24 5.04. Заметьте, тут в рамках одного видео такая формулировка встречается 4 раза, что нельзя списать на то, что автор просто оговорился.

-   На этом степе в задании "[различия считаются статистически достоверными](https://stepik.org/lesson/8078/step/11?unit=1358)".

-   В формулировке [задания](https://stepik.org/lesson/9249/step/13?unit=1829) "статистически достоверными".

-   "различиям между группами признавались статистически достоверными" в тексте [задания](https://stepik.org/lesson/8085/step/10?unit=1364).

-   [принять или отклонить нулевую гипотезу](https://stepik.org/lesson/8086/step/11?unit=1365) 1.20

Неправильно говорить "достоверность" вместо статистической значимости, потому что в математике достоверное событие -- то, которое происходит со 100% вероятностью. Про термин "достоверность" почитать можно дискуссию в чате, начиная с этого [сообщения](https://t.me/chat_biostat_R/10315). В целом в чате поиском по слову достоверность можно найти достаточно аргументации, почему это нельзя использовать как замену статистической значимости.

::: callout-note
И еще [статья](https://cyberleninka.ru/article/n/dostovernost-ili-statisticheskaya-znachimost-12-let-spustya) на эту тему: *«Достоверность» или «Статистическая значимость» 12 лет спустя*, Зорин Никита Александрович
:::

Также в алгоритме статистического вывода, мы не принимаем нулевую или альтернативную гипотезу, а можешь лишь отклонить нулевую гипотезу или не отклонить ее.

*В общем, пока я собирала эту подборку и пересматривала заново, я чуть не сошла с ума, так что давайте перейдем от "достоверностей" к другому.*

Теперь разберем по разделам.

## Первая часть: введение

Общее впечатление: большая часть вещей объяснена нормально, но при этом проскальзывают неточности и неаккуратности с формулировками.

[Здесь](https://stepik.org/lesson/8073/step/6?unit=1353) немного странная история про перевод из количественной переменной в номинативную:

> "измерить рост наших испытуемых, это будет непрерывная количественная переменная, проранжировать наших испытуемых, то есть перевести их в ранговую переменную, а потом разделить на две группы: 1 выше среднего, 2 ниже среднего, то есть сделать номинативную переменную".

Все-таки последняя переменная не будет в чистом виде номинативной, потому что можно задать операцию сравнения. Хотя конечно сравнивать две группы уже имеет мало смысла.

В целом по всему разделу описательных статистик идет терминологическая непоследовательность в формуле дисперсии выборки и генеральной совокупности, то есть n-1 то появляется в формуле, то исчезает.

Карпов объясняет, что n-1 в знаменателе формулы связано со степенями свободы, но объяснение немного другое, вот [здесь](https://www.youtube.com/watch?v=sHRBg6BhKjI) или [тут](https://www.youtube.com/watch?v=pLH1QA4F9uE) можно посмотреть.

Вот [тут](https://stepik.org/lesson/9294/step/5?unit=1827) сказано, что между первым и третьим квартилем в боксплоте находится ровно 50% наблюдений. Но это не обязательно так, например, это будет неверно в случае, если в данных есть повторяющиеся значения.

```{r}
boxplot(c(1, 2, 2, 2, 2, 3, 3, 3))
```

Здесь в "ящике" бокса находится 7/8 значений, то есть 87.5%. В целом, можно придумать и совсем экстремальный случай, когда в ящике бокса находятся все наблюдения и "усов" нет совсем. Может быть это незначительная неточность, но в любом случае проявление неаккуратности формулировки.

## Вторая часть: сравнение средних

Общее впечатление: самая слабая часть курса, наибольшее количество ошибок сосредоточено именно здесь.

### Про тест Стьюдента

[Здесь](https://stepik.org/lesson/9249/step/2?unit=1829) некорректно назван t-тест почему-то парным t-тестом. Видимо имелся ввиду двухвыборочный t-тест. Напоминаю, что парный или *зависимый* t-тест применяется к *зависимым* выборкам и формула расчета его другая.

В целом, везде t-критерий Стьюдента называется `критерий t-Стьюдента`.

Странная [постановка нулевой и альтернативной гипотезы](https://stepik.org/lesson/9249/step/3?unit=1829) (0.20):

> нулевая гипотеза: в генеральной совокупности никакого различия между этими средними значениями нет, тогда как альтернативная гипотеза \<...\> будет говорить, что на самом деле эти средние в генеральной совокупности не равны.

**Раписать почему это ошибка**

*В комментариях предложили более правильную формулировку, но все равно это существенная неточность, да и много ли кто читает комментарии после просмотра видео.*

Далее, не было сказано ничего про тест Велча (или тест Стьюдента с поправкой Велча), зато [сказано](https://stepik.org/lesson/9249/step/9?unit=1829), что нужно обязательно равенство дисперсий при сравнении двух групп t-тестом. Для t-теста без поправки Велча это действительно так, но в целом более надежно с точки зрения ошибки первого рода использовать тест Стьюдента с поправкой Велча.

В большинстве случаев оба теста контролируют ошибку первого рода и мощность на заданном уровне. Однако у теста Стьюдента есть проблема с ошибкой первого рода (ложноположительные результаты) в ситуации с неравными дисперсиями и разным размером выборок.

Выдержка из [материала про тест Велча](https://ubogoeva.github.io/R4Analytics/posts/welch_test.html):

|                                                                                      | тест Велча | тест Стьюдента |
|-------------------------------------------|---------------|---------------|
| Отличий нет, равные дисперсии, равные выборки                                        | ✅         | ✅             |
| Отличий нет, разные дисперсии, равные выборки                                        | ✅         | ✅             |
| Отличий нет, разные дисперсии, разные выборки, меньшая выборка с большей дисперсией  | ✅         | ❌             |
| Отличий нет, разные дисперсии, разные выборки, бОльшая выборка с большей дисперсией  | ✅         | ✅             |
| Отличия есть, равные дисперсии, равные выборки                                       | ✅         | ✅             |
| Отличия есть, разные дисперсии, равные выборки                                       | ✅         | ✅             |
| Отличия есть, разные дисперсии, разные выборки, меньшая выборка с большей дисперсией | 🟡         | ✅             |
| Отличия есть, разные дисперсии, разные выборки, бОльшая выборка с большей дисперсией | ✅         | 🟡             |

: Здесь ✅ — тест показал себя хорошо, ❌ — тест показал себя плохо, 🟡 — тест показал себя не оптимально, но не слишком плохо

Потому что при равных дисперсиях результат теста Велча практически не будет отличаться от теста Стьюдента, а при разных дисперсиях тест Велча точнее. Писала про это здесь

К тому же по умолчанию в R считается именно тест с поправкой Велча (в функции `t.test()` параметр `var.equal = FALSE`, то есть предполагаем, что дисперсии не равны).

Также сказано про нормальность распределения как требование для t-теста, но причем только в случае, если значений в выборке меньше 30. Почитать, почему это не так, можно по [ссылке](https://koch-kir.medium.com/%D0%B8%D1%81%D1%82%D0%BE%D1%80%D0%B8%D1%8F-%D0%BE%D0%B4%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BE%D0%B1%D0%BC%D0%B0%D0%BD%D0%B0-%D0%B8%D0%BB%D0%B8-%D1%82%D1%80%D0%B5%D0%B1%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BA-%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8E-%D0%B2-%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85-%D1%82%D0%B5%D1%81%D1%82%D0%B0%D1%85-55139a5558d). В тексте статьи есть неточности, но общий посыл передан верно, ждем Матвея Славенко с подробным разбором этого статистического мифа.

Про формулу и одинаковый размер выборки для теста Стьюдента, формула верная только если размер выборки одинаковый.

Не то про [QQ](https://stepik.org/lesson/8082/step/4?unit=1361) - мало и возмозно неверено, но надо бы понять почему неверно

### Про тест Манна-Уитни

Очень мимоходом [сказано](https://stepik.org/lesson/8082/step/10?unit=1361) про тест Манна-Уитни, не сказано ничего про формулировку нулевой гипотезы, кажется что мы сравниваем средние, только в рангах, а это далеко не так. В случае Манна-Уитни мы сравниваем сдвиг распределений относительно друг друга.

Очень большая статья про МУ тест от Сергея Матросова.

### Про дисперсионный анализ

Здесь все достаточно неплохо

Про многофакторный поверхностно, но понятно что курс бесплатный.

Ограничение про 50 наблюдений. Проверять на нормальность и гомогенность дисперсий

В [части](https://stepik.org/lesson/8085/step/7?unit=1364) про поправки на множественное тестирование, все поправки собраны в одну кучу без расстановки акцентов на то, какой метод использовать в каких случаях.

Но общая идея изложена верно, что очень круто и за это респект. Для дальнейшего углубления в детали, какую поправку использовать лучше, можно ознакомиться с моим постом.

Лучше почитать мой [пост](https://ubogoeva.github.io/R4Analytics/posts/multiple_testing.html) про поправки.

## Про корреляции

Общее впечатление: часть недостаточно подробная, очень мало деталей и материалов для дальнейшего изучения.

Экстраполяция https://stepik.org/lesson/9996/step/2?unit=1926 0.20

Не сказано про угрозу экстраполяции, не акцентировано внимание, что регрессия работает только в диапазоне значений независимой переменной.

в принципе сказано про опасность экстраполяции, но мало

[Опечатка на слайде](https://stepik.org/lesson/8090/step/3?unit=1369) и в тексте видео (1.15): в требованиях к множественной линейной регрессии указана гетероскедастичность вместо гомоскедастичности.

https://stepik.org/lesson/9995/step/2?unit=1925 3.00 про показатели модели при мультиколлинеарности. Про то что при мультиколлинеарности коэффициент тянет в одну сторону, когда все другие зафиксированы и при сильной коллинеарности мы как бы не можем зафиксировать связанный предиктор.

Про регрессию в целом рассказано недостаточно подробно и нет ссылок на другие источники для дальнейшего развития. Например, ничего не сказано про VIF для оценки мультиколлинеарности, про информационные критерии AIC, BIC, и методы отбора лучшей модели.

На тему регрессии рекомендую [курс лекций](https://polydora.github.io/linmodr/lectures.html) Марины Варфоломеевой и Вадима Хайтова.

## Выводы

Как уже отмечала выше, можно было смотреть курс в то время, когда он только вышел и качественных материалов было немного. В настоящий момент смотреть курс "Основы статистики" настоятельно не рекомендую, лучше почитать и посмотреть в моей подборке [здесь](https://t.me/stats_for_science/73) (также в комментариях к посту приложено множество материалов).

Все вышенаписанное не относится к платным курсам Карпова, про платные я знаю немного.

## Благодарности
