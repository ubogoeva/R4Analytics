---
title: "Разбор курса 'Основы статистики'"
author: "Elena U"
date: "2025-02-14"
format: html
editor: visual
categories: statistics
---

По итогам многочисленных дискуссий в чатах по статистике и биоинформатике ([BioStat \<- R \| Чат по статистике и R](https://t.me/chat_biostat_R){target="_blank"}, [BIOINF \| Education & Career](https://t.me/bioinf_career){target="_blank"}), я решила написать обзор на курс ["Основы статистики"](https://stepik.org/course/76/syllabus){target="_blank"} на платформе stepik. Давайте разберем его достоинства и недостатки, а также есть ли смысл его смотреть сейчас.

## Общее описание курса

Немного контекста: курс был опубликован в начале 2015го года, и был одним из первых бесплатных русскоязычных курсов по статистике (а может и самый первый). Конечно, были и есть книги, но не было лекций в интерактивном формате.\
К тому же не все переводы книг по статистике хороши, например, перевод книги Гланца "[Медико-биологическая статистика]{.underline}" оставляет желать лучшего. Книга "[Статистика и котики]{.underline}", которая хороша для старта в статистике, была опубликована позже, в 2016. Это я к тому, что такого многообразия материалов по статистике, как появилось в последние \~5 лет еще не было, и на тот момент вводный курс по основам статистики был очень актуален для сообщества.

Я сама посмотрела курс "Основы статистики" в 2017 году, после довольно слабого курса по статистике в университете, и для меня курс был полезен для старта, после чего продолжила изучать статистику преимущественно по книгам (а сейчас преподаю сама). В тот момент курс показался достойным, мне понравился простой язык изложения, расчет формул на игрушечных примерах, а также удобный интерактивный формат заданий и их проверки на степике.

Курс состоит из трех блоков:

1.  Введение, выборка и генеральная совокупность, типы переменных, описательная статистика, ЦПТ, p-value.
2.  Сравнение средних: t-test, однофакторная и многофакторная ANOVA, проблема множественных тестирований.
3.  Корреляция и простая и множественная линейная регрессия, отбор моделей.

В общем такой джентльменский набор тем для старта.

Разберем подробно каждую часть, выделяя что понравилось, а также указывая на неточности и ошибки. Платформа степик не позволяет делать ссылки с таймкодами, поэтому буду прикреплять ссылки на видео и подписывать время в тексте.

## Первая часть: введение

Общее впечатление: большая часть вещей объяснена нормально, неплохой блок про статистический вывод, объяснено, чем p-value является и не является, но при этом проскальзывают неосторожные формулировки, а иногда и ошибки. Основные разобраны ниже, а также отдельно вынесены [терминологические неточности](#terms) (в основном что касается принять нулевую гипотезу и тп).

### Описательные статистики: смещенные и несмещенные оценки

По всему разделу описательных статистик перескакивает мысль с дисперсии генеральной совокупности на дисперсию выборки, в знаменателе формулы то $n$, то $n-1$, плюс не хватило объяснения, почему используются греческие или латинские буквы для обозначения дисперсии или среднего, это сбивает с толку слушателей.

Анатолий Карпов [объясняет](https://stepik.org/lesson/8076/step/5?unit=1356){target="_blank"} (на 3.30), что $n-1$ в знаменателе формулы дисперсии выборки связано со степенями свободы, но это не совсем так. Такое же [объяснение](https://stepik.org/lesson/8086/step/4?unit=1365){target="_blank"} приводится и для коэффициента корреляции, хотя в расчете коэффициента корреляции вообще степеней свободы $n-2$.\
Здесь важно прояснить две вещи. Первое: при делении на $n$ у нас систематически занижается дисперсия выборки относительно дисперсии генеральной совокупности, и деление на $n-1$ позволяет получить несмещенную оценку дисперсии ([здесь](https://www.youtube.com/watch?v=sHRBg6BhKjI){target="_blank"} или [здесь](https://www.youtube.com/watch?v=pLH1QA4F9uE){target="_blank"} можно посмотреть, как это происходит). Второе: при растущем объеме выборки обе формулы дают значение, которое приближается к дисперсии генеральной совокупности. То есть в курсе объяснение через степени свободы не совсем ошибка, но немного уводит в сторону.

::: callout-important
## Комментарий

[Почему именно n-1 в знаменателе](https://en.wikipedia.org/wiki/Bessel%27s_correction#Proof)
:::

::: callout-note
## Обсуждение в чате Биостата

Вот начиная с этого [сообщения](https://t.me/chat_biostat_R/22168) обсудили, что в принципе это объяснение тоже имеет смысл
:::

Кроме этого, стандартное отклонение называется в лекциях и стандартным, и среднеквадратичным отклонением. Понятно, что это одно и то же, но это не было проговорено явно, в результате слушатели курса в растерянности. Исторически в русскоязычной литературе использовался вариант "среднеквадратичное отклонение", но сейчас чаще встречается вариант "стандартное отклонение", мне кажется это более правильно, так как прямой перевод standard deviation.

Вот [тут](https://stepik.org/lesson/9294/step/5?unit=1827){target="_blank"} сказано, что между первым и третьим квартилем в боксплоте находится ровно 50% наблюдений. В принципе это часто так, но не обязательно, например, это будет неверно в случае, если в данных есть повторяющиеся значения.

```{r}
boxplot(c(1, 2, 2, 2, 2, 3, 3, 3))
```

Здесь в "ящике" бокса находится 7/8 значений, то есть 87.5%. Можно придумать и совсем экстремальный случай, когда в ящике бокса находятся все наблюдения и "усов" нет совсем. Конечно, это редко когда встречается, но в любом случае проявление неаккуратности формулировки, хотя и не слишком существенное.

А вот следующий пример будет гораздо хуже ⬇️

### Доверительные интервалы, которым нельзя доверять

Вот [тут](https://stepik.org/lesson/9249/step/8?unit=1829){target="_blank"} было что-то совсем странное с интерпретацией доверительных интервалов (с 1.05).

Дословно текст:

> Потому что если у нас среднее номер 2 не попадает в доверительный интервал для среднего номер 1, и наоборот, среднее номер 1 не попадает в доверительный интервал для среднего номер 2, то такие различия у нас будут достигать уровня статистической значимости.

![Скриншот из видео](images/conf_interval.PNG)

Такая интерпретация перекрывания доверительных интервалов совсем неверная.

Здесь я [писала](https://ubogoeva.github.io/R4Analytics/posts/types_of_error_bars.html){target="_blank"} про доверительные интервалы и пределы погрешностей. В двух словах: отсутствие перекрывания 95% доверительных интервалов говорит о статистически значимых различиях (p \< 0.05), но речь идет именно о перекрывании ***усов***, а вовсе не о том, что доверительный интервал одной выборки не перекрывается с ***выборочным*** ***средним*** второй.\
Перекрывание усов со средним не интерпретируется в терминах статистической значимости. На картинке выше доверительные интервалы перекрываются, и это не говорит о том, что различий нет, поскольку только *отсутствие* перекрывания говорит о статистически значимых различиях:

![Интерпретация перекрывания пределов погрешностей, доверительные интервалы — 95% CI. Ссылка на [источник](https://www.graphpad.com/support/faq/spanwhat-you-can-conclude-when-two-error-bars-overlap-or-dontspan/){target="_blank"} картинки](images/se_overlap.png)

*Наличие* перекрывания *не* говорит о том, что различий нет. Еще стоит отметить, что в принципе делать выводы о различиях средних на основании перекрывания/не перекрывания доверительных интервалов плохая практика.

Считаю это очень серьезной неточностью и даже ошибкой курса, учитывая, что в целом доверительный интервал как явление дает простор для мисинтерпретации, так еще и в курсе приведено заведомо неверное объяснение.

### Баг про центральную предельную теорему

Дмитрий Пензар достаточно подробно про это [расписал](https://vk.com/@dmitry_penzar-stats-and-pulverization){target="_blank"}, главное замечание в том, что в формулировке Карпова ЦПТ становится практически бесполезной (ссылка на [лекцию](https://stepik.org/lesson/8077/step/6?unit=1357){target="_blank"}).

> Предположим исследуемый нами признак имеет нормальное распределение в генеральной совокупности с некоторым средним и стандартным отклонением, и мы многократно извлекаем выборки равные n по объему, и в каждой выборке рассчитываем среднее значение, после чего строим распределение этих выборочных средних. Так вот, такое распределение будет являться нормальным со средним, совпадающим с этим показателем генеральной совокупности. И, что самое интересное, со стандартным отклонением, которое называется стандартная ошибка среднего, se равным sigma/корень(n).

Не хватило объяснения основной сути ЦПТ.

Основная суть ЦПТ в том, что **какой бы ни была форма распределения в генеральной совокупности, выборочное распределение средних будет стремиться к нормальному**. Это применимо для признака, который обладает конечными математическим ожиданием и дисперсией.

Иллюстрация на примере логнормального распределения:

```{r}
log_distr <- rlnorm(10000) # создаем "генеральную совокупность"
hist(log_distr, breaks = 30) # строим гистограмму
```

Извлекаем тысячу раз выборки размером 30, считаем среднее этих выборок, построим распределение.

```{r}
samp_means_log <- replicate(1000, mean(sample(log_distr, 30))) 
hist(samp_means_log, breaks = 30)
```

Распределение выборочных средних из логнормального распределения получилось очень похожим на нормальное распределение. Это происходит благодаря центральной предельной теореме.

Вот тут можно посмотреть еще: [Шайни апп для центральной предельной теоремы](https://gallery.shinyapps.io/CLT_mean/){target="_blank"}, особенно эффектно выглядит на примере равномерного распределения.

## Вторая часть: сравнение средних

Общее впечатление: самая слабая часть курса, наибольшее количество ошибок сосредоточено именно здесь. При этом лайк за объяснение однофакторного дисперсионного анализа и разбор проблематики множественного тестирования.

### Про тест Стьюдента без теста Велча

[Здесь](https://stepik.org/lesson/9249/step/2?unit=1829){target="_blank"} некорректно назван t-тест почему-то парным t-тестом. Видимо имелся ввиду двухвыборочный t-тест. Напоминаю, что парный или *зависимый* t-тест применяется к *зависимым* выборкам и формула расчета его другая.

По всему курсу t-критерий Стьюдента называется `критерий t-Стьюдента`.

Странная [постановка нулевой и альтернативной гипотезы](https://stepik.org/lesson/9249/step/3?unit=1829){target="_blank"} (0.20):

> нулевая гипотеза, будет предполагать, что на самом деле в генеральной совокупности никакого различия между этими средними значениями нет, тогда как альтернативная гипотеза \<...\> будет говорить, что на самом деле эти средние в генеральной совокупности не равны.

Более правильно будет сказать, что нулевая гипотеза — о том, что две генеральные совокупности (из которых взяты соответствующие выборки) имеют одинаковое среднее. Соответственно альтернативная — о том, что средние в генеральной совокупности не равны.

Далее, не было сказано ничего про тест Велча (тест Стьюдента с поправкой Велча), зато [сказано](https://stepik.org/lesson/9249/step/9?unit=1829){target="_blank"}, что нужно обязательно равенство дисперсий при сравнении двух групп t-тестом. Для теста Стьюдента без поправки Велча это действительно так, но в целом более надежно с точки зрения ошибки первого рода использовать тест Стьюдента с поправкой Велча.

Я сравнивала тест Стьюдента и тест Велча, вот выдержка из [материала](https://ubogoeva.github.io/R4Analytics/posts/welch_test.html){target="_blank"}:

> В большинстве случаев оба теста контролируют ошибку первого рода и мощность на заданном уровне. Однако у теста Стьюдента есть проблема с ошибкой первого рода (ложноположительные результаты) в ситуации с неравными дисперсиями и разным размером выборок.

|                                                                                      | тест Велча | тест Стьюдента |
|----------------------------------|-------------------|-------------------|
| Отличий нет, равные дисперсии, равные выборки                                        | ✅         | ✅             |
| Отличий нет, разные дисперсии, равные выборки                                        | ✅         | ✅             |
| Отличий нет, разные дисперсии, разные выборки, меньшая выборка с большей дисперсией  | ✅         | ❌             |
| Отличий нет, разные дисперсии, разные выборки, бОльшая выборка с большей дисперсией  | ✅         | ✅             |
| Отличия есть, равные дисперсии, равные выборки                                       | ✅         | ✅             |
| Отличия есть, разные дисперсии, равные выборки                                       | ✅         | ✅             |
| Отличия есть, разные дисперсии, разные выборки, меньшая выборка с большей дисперсией | 🟡         | ✅             |
| Отличия есть, разные дисперсии, разные выборки, бОльшая выборка с большей дисперсией | ✅         | 🟡             |

: Здесь ✅ — тест показал себя хорошо, ❌ — тест показал себя плохо, 🟡 — тест показал себя не оптимально, но не слишком плохо

Можно было хотя бы упомянуть про существование теста Велча, учитывая что в большинстве статистических программ считается именно он.

Также [сказано](https://stepik.org/lesson/9249/step/9?unit=1829){target="_blank"} про нормальность распределения как обязательное требование для t-теста, но только в случае, если значений в выборке меньше 30. Почитать, почему это не так, можно по [ссылке](https://koch-kir.medium.com/%D0%B8%D1%81%D1%82%D0%BE%D1%80%D0%B8%D1%8F-%D0%BE%D0%B4%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BE%D0%B1%D0%BC%D0%B0%D0%BD%D0%B0-%D0%B8%D0%BB%D0%B8-%D1%82%D1%80%D0%B5%D0%B1%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BA-%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8E-%D0%B2-%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85-%D1%82%D0%B5%D1%81%D1%82%D0%B0%D1%85-55139a5558d){target="_blank"}. В тексте этой статьи есть неточности, но общий посыл передан верно, ждем Матвея Славенко с подробным разбором этого статистического мифа.

### Про тест Манна-Уитни: недостаточно

Очень мимоходом [сказано](https://stepik.org/lesson/8082/step/10?unit=1361){target="_blank"} про тест Манна-Уитни, не сказано ничего про формулировку нулевой гипотезы, кажется что мы сравниваем средние, только в рангах, а это не совсем так.

Я думаю не помешало бы уделить больше внимания тесту Манна-Уитни, так как тест очень популярен в научном сообществе, для случаев, когда нарушается требование к нормальности распределения.

::: callout-tip
## Рекомендация

[Большая статья про тест Манна-Уитни](https://habr.com/ru/companies/X5Tech/articles/823078/){target="_blank"} на хабре от Сергея Матросова и аналитиков X5 Tech.
:::

Не хватило рекомендаций, что делать с выбросами помимо использования непараметрических методов, так как не всегда непараметрика это единственный возможный и верный вариант.

### Про дисперсионный анализ

Здесь все очень даже неплохо, мне понравился расчет F-значений в дисперсионном анализе вручную и объяснение внутригрупповой и межгрупповой суммы квадратов.

Но все-таки укажу на кое-какие огрехи: [тут](https://stepik.org/lesson/Многофакторный-ANOVA-9250/step/13){target="_blank"} указано требование к нормальности данных и гомогенности дисперсий, но если наблюдений больше 50, то ANOVA устойчива к нарушению обоих предположений. Это так, но я бы уточнила, что нам важнее нормальность распределения *остатков*, а не исходных данных. В остальном да, при достаточном размере выборки ANOVA устойчива к нарушению нормальности, а при равенстве объемов выборок в группах к гетерогенности дисперсий.

Про многофакторный дисперсионный анализ рассказано поверхностно, но без ошибок, понятно, что в курсе по *основам* статистики не изложить все, особенно по теме дисперсионного анализа. Возможно, стоило обратить внимание на то, что бывают разные способы расчета сумм квадратов в двухфакторном дисперсионном анализе, и при разных размерах выборок (= несбалансированный дизайн) это может повлиять на выводы (вот [тут](https://www.youtube.com/watch?v=NKMFgejt3U0){target="_blank"} можно посмотреть, основная проблема изложена).

::: callout-note
## Про разные типы сумм квадратов в ANOVA

[Статья](https://stats.stackexchange.com/questions/20452/how-to-interpret-type-i-type-ii-and-type-iii-anova-and-manova){target="_blank"} на stats.stackexchange с подробным разбором разных тип сумм квадратов и их отличием
:::

### Про поправки на множественное тестирование

Общая идея [проиллюстрирована](https://stepik.org/lesson/8085/step/3?unit=1364){target="_blank"} очень хорошо, и мне понравилось, что были использованы симуляции сравнений групп, а не просто формула FWER.

Но не хватило акцентов, какой метод в каком случае лучше использовать.

::: callout-note
FWER — family-wise error rate, групповая вероятность ошибки I рода.

Формула расчета FWER для независимых тестов

$$
FWER = 1 - (1-\alpha)^k, где
$$

*k* - количество тестов, $\alpha$ - уровень значимости.

При сравнении групп тесты зависимые, и по формуле мы можем оценить только верхнюю границу, максимально возможное значение FWER.
:::

Для дальнейшего углубления в конкретику, какую поправку использовать лучше, можно ознакомиться с моим [постом](https://ubogoeva.github.io/R4Analytics/posts/multiple_testing.html){target="_blank"} с детальным разбором поправок и [лекцией](https://disk.yandex.ru/d/QLnuA-Y3rw_eVg/2){target="_blank"} Матвея Славенко в литклубе биостатистики.

## Третья часть: корреляция и регрессия

Общее впечатление: часть недостаточно подробная, хотелось бы увидеть больше деталей и материалов для дальнейшего изучения. Но серьезных ошибок не было, общая суть методов передана верно.

### Корреляция

[Здесь](https://stepik.org/lesson/9992/step/5?unit=1923){target="_blank"} в объяснении преимуществ корреляции Спирмена говорится, что можно нарушить линейность, это так, но при этом важно, чтобы соблюдалась монотонность связи, на это не хватает акцента.

Не хватило методов, что можно сделать с выбросами помимо применения непараметрических тестов. В определенных ситуациях можно удалить выбросы, если они физически невозможны, также можно сделать различные преобразования, например логарифмирование. Но нужно учитывать, что может измениться интерпретация преобразованных данных.

### Регрессия

Здесь [сказано](https://stepik.org/lesson/9996/step/2?unit=1926){target="_blank"} про опасность экстраполяции, но при этом предсказанное значение лежит за пределами диапазона значений независимых переменных, что уже является экстраполяцией и не совсем корректно.

[Опечатка на слайде](https://stepik.org/lesson/8090/step/3?unit=1369){target="_blank"} и в речи (1.15): в требованиях к множественной линейной регрессии указана гетероскедастичность вместо гомоскедастичности.

Про проблему [мультиколлинеарности](https://stepik.org/lesson/9995/step/2?unit=1925){target="_blank"} (3.00) маловато конкретики и объяснения причин, почему мультиколлинеарность плохо.

В теме множественной регрессии не хватило про VIF для оценки мультиколлинеарности, про информационные критерии AIC, BIC и методы отбора лучшей модели.

::: callout-tip
## Рекомендация

На тему регрессии рекомендую [курс лекций](https://polydora.github.io/linmodr/lectures.html){target="_blank"} Марины Варфоломеевой и Вадима Хайтова.
:::

Справедливости ради, в третьей части курса ([Основы статистики. Часть 3](https://stepik.org/course/2152/syllabus){target="_blank"}) это было разобрано более подробно.

## Терминологические неточности {#terms}

Сюда относятся многочисленные "принять альтернативную гипотезу", "статистически достоверно" вместо статистически значимо, соберем их в одном месте:

-   В ответах к [заданию](https://stepik.org/lesson/8083/step/8?unit=1362){target="_blank"} "принимаем нулевую гипотезу"

-   "[Считать наши значения статистически достоверными](https://stepik.org/lesson/8078/step/7?unit=1358){target="_blank"}" 0.50

-   "[Принимаем различия статистически достоверными](https://stepik.org/lesson/8085/step/3?unit=1364){target="_blank"}" 1.26 1.45 3.24 5.04. Заметьте, тут в рамках одного видео такая формулировка встречается 4 раза, что нельзя списать на то, что автор просто оговорился.

-   На этом степе в задании "[различия считаются статистически достоверными](https://stepik.org/lesson/8078/step/11?unit=1358){target="_blank"}".

-   В формулировке [задания](https://stepik.org/lesson/9249/step/13?unit=1829){target="_blank"} "статистически достоверными".

-   "различиям между группами признавались статистически достоверными" в тексте [задания](https://stepik.org/lesson/8085/step/10?unit=1364){target="_blank"}.

-   [принять или отклонить нулевую гипотезу](https://stepik.org/lesson/8086/step/11?unit=1365){target="_blank"} 1.20

В алгоритме статистического вывода, мы не принимаем нулевую гипотезу, а можешь лишь отклонить нулевую гипотезу или не отклонить ее (можно принять альтернативную гипотезу, но нельзя принять нулевую гипотезу).

Некорректно говорить "достоверность" вместо статистической значимости, потому что в математике достоверное событие — то, которое происходит со 100% вероятностью. Про термин "достоверность" почитать можно дискуссию в чате, начиная с этого [сообщения](https://t.me/chat_biostat_R/10315){target="_blank"}, и поиском по чату можно найти достаточно аргументации, почему это нельзя использовать как замену статистической значимости.

И еще [статья](https://cyberleninka.ru/article/n/dostovernost-ili-statisticheskaya-znachimost-12-let-spustya){target="_blank"} на эту тему: *«Достоверность» или «Статистическая значимость» 12 лет спустя*, Зорин Никита Александрович.

## Выводы

Как уже отмечала выше, курс был актуален в свое время. В настоящий момент смотреть курс "Основы статистики" скорее не рекомендую, ниже предлагаю список хороших материалов:

Для удобства попробовала разбить на разные уровни

Junior:

1.  Книга "Статистика и котики" Владимир Савельев
2.  Книга "Статистика для всех" (Statistics in a nutshell) Сара Бослаф
3.  [Анализ данных и статистика в R](https://pozdniakov.github.io/tidy_stats/index.html){target="_blank"} Ивана Позднякова

Middle:

1.  Курс "[Линейные модели, дисперсионный и регрессионный анализ с использованием R](https://varmara.github.io/linmodr/){target="_blank"}" авторством Марины Варфоломеевой и Вадима Хайтова
2.  [Курс Data Analysis with R Specialization](https://www.coursera.org/specializations/statistics){target="_blank"} на курсере
3.  [StatQuest](https://www.youtube.com/@statquest){target="_blank"} - отличный канал с короткими, но очень четкими разборами конкретных тем по статистике.
4.  [TileStats](https://www.youtube.com/@tilestats){target="_blank"} - тоже очень хороший канал по статистике с похожим форматом.

Senior:

1.  Подборка Матвея Славенко в канале [душно про дату](https://t.me/choking_data){target="_blank"}: [первое](https://t.me/choking_data/51){target="_blank"}, [второе](https://t.me/choking_data/52){target="_blank"}

При этом всем хочу выразить Анатолию Карпову респект за популяризацию R в сообществе (по крайней мере раньше), и большую благодарность за бесплатные программы: [симулятор SQL](https://karpov.courses/simulator-sql){target="_blank"}, [курс по визуализации данных](https://karpov.courses/datavisualization){target="_blank"}.

## Благодарности

Матвею Славенко за уточнение сложных моментов и помощь с корректностью формулировок, Яне, Жене и Юле за конструктивные статистические дискуссии и рекомендации по тексту, Сергею Матросову за дополнительную мотивацию все-таки дописать пост и Дмитрию Пензару за исходное развитие дискуссии и пример с ЦПТ.

Обсудить можно в телеграм-канале [Статистика и R в науке и аналитике](https://t.me/stats_for_science){target="_blank"}, в комментариях к [посту](https://t.me/stats_for_science/125){target="_blank"} или здесь, авторизовавшись через GitHub.

![](images/tlg_short.png)
