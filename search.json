[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Об авторе блога",
    "section": "",
    "text": "&lt;div&gt;&lt;img src=\"https://mc.yandex.ru/watch/97025960\" style=\"position:absolute; left:-9999px;\" alt=\"\"&gt;&lt;/div&gt;\nМеня зовут Елена Убогоева. Я биоинформатик, R-энтузиаст, ex-аналитик данных в X5 Tech, в настоящий момент продуктовый аналитик в Литрес, команда монетизации. Веду телеграм-канал, посвященный R и статистике, преподаю на курсах Blastim: “Статистика, R и анализ данных” и “Анализ данных RNA-seq”.\nЭтот блог создан с помощью Quarto и будет содержать материалы и статьи, которые были ранее написаны в телеграм-канале.\nПровожу индивидуальные консультации по статистике и помогаю с собеседованиями по продуктовой аналитике, пишите в личку @lena_astr. Перед этим можно созвониться на 15 минут, чтобы обсудить, подходит ли этот формат.\nСтоимость консультаций:\nПокупка большего числа занятий обсуждается индивидуально."
  },
  {
    "objectID": "about.html#образование",
    "href": "about.html#образование",
    "title": "Об авторе блога",
    "section": "Образование",
    "text": "Образование\nИнститут цитологии и генетики СО РАН | Новосибирск\nАспирантура по направлению биоинформатики и системной биологии | 2020 - 2022\nНовосибирский государственный университет | Новосибирск\nМагистратура по направлению цитологии и генетики | 2018 - 2020\nНовосибирский государственный университет | Новосибирск\nБакалавриат по направлению цитологии и генетики | 2014 - 2018"
  },
  {
    "objectID": "about.html#преподавание",
    "href": "about.html#преподавание",
    "title": "Об авторе блога",
    "section": "Преподавание",
    "text": "Преподавание\n\nСтатистика, R и анализ данных от Blastim, учебный ассистент и лектор дополнительных занятий, с 2022 по настоящее время.\nАнализ данных RNA-seq от Blastim, лектор, октябрь - ноябрь 2023 года.\nСтатистика для селекционеров, лектор и ведущий курса, февраль - апрель 2024 года.\nКурс “Введение в tidyverse” на stepik.\nЗаписываю лекции на ютубе, плейлист по ссылке.\nВеду индивидуальные занятия по R, статистике и биоинформатике, отчет по итогам 2022-2023 года можно посмотреть здесь.\nПредыдущие проекты можно посмотреть здесь."
  },
  {
    "objectID": "about.html#список-публикаций",
    "href": "about.html#список-публикаций",
    "title": "Об авторе блога",
    "section": "Список публикаций",
    "text": "Список публикаций\n\nSamalova, M., Melnikava, A., Elsayad, K., Peaucelle, A., Gahurova, E., Gumulec, J., Spyroglou, I., Zemlyanskaya, E. V., Ubogoeva, E. V., Balkova, D., Demko, M., Blavet, N., Alexiou, P., Benes, V., Mouille, G., & Hejatko, J. (2023). Hormone-regulated expansins: Expression, localization, and cell wall biomechanics in Arabidopsis root growth. Plant physiology, 194(1), 209–228. https://doi.org/10.1093/plphys/kiad228\nLavrekha, V. V., Levitsky, V. G., Tsukanov, A. V., Bogomolov, A. G., Grigorovich, D. A., Omelyanchuk, N., Ubogoeva, E. V., Zemlyanskaya, E. V., Mironova, V. (2022). CisCross: A gene list enrichment analysis to predict upstream regulators in Arabidopsis thaliana. Frontiers in plant science, 13, 942710. https://doi.org/10.3389/fpls.2022.942710\nUbogoeva, E. V., Zemlyanskaya, E. V., Xu, J., Mironova, V. (2021). Mechanisms of stress response in the root stem cell niche. Journal of experimental botany, 72(19), 6746–6754. https://doi.org/10.1093/jxb/erab274\nZemlyanskaya, E. V., Omelyanchuk, N. A., Ubogoeva, E. V., Mironova, V. V. (2018). Deciphering Auxin-Ethylene Crosstalk at a Systems Level. International journal of molecular sciences, 19(12), 4060. https://doi.org/10.3390/ijms19124060"
  },
  {
    "objectID": "posts/ansombe_quartet.html#квартет-энскомба-anscombes-quartet",
    "href": "posts/ansombe_quartet.html#квартет-энскомба-anscombes-quartet",
    "title": "Anscombe’s quartet",
    "section": "Квартет Энскомба (Anscombe’s quartet)",
    "text": "Квартет Энскомба (Anscombe’s quartet)\nКвартет Энскомба представляет собой 4 набора данных с одинаковыми описательными статистиками (среднее, дисперсия, коэффициент корреляции), но с очень разными распределениями данных. Каждый набор содержит 11 значений (x, y). Francis Anscombe предложил эти наборы данных в 1973 году [1] в качестве иллюстрации важности полагаться не только на описательные статистики, но и визуализацию данных.\nЭтот набор данных встроен в R (вызвать можно просто набрав anscombe в консоли).\n\nanscombe\n\n   x1 x2 x3 x4    y1   y2    y3    y4\n1  10 10 10  8  8.04 9.14  7.46  6.58\n2   8  8  8  8  6.95 8.14  6.77  5.76\n3  13 13 13  8  7.58 8.74 12.74  7.71\n4   9  9  9  8  8.81 8.77  7.11  8.84\n5  11 11 11  8  8.33 9.26  7.81  8.47\n6  14 14 14  8  9.96 8.10  8.84  7.04\n7   6  6  6  8  7.24 6.13  6.08  5.25\n8   4  4  4 19  4.26 3.10  5.39 12.50\n9  12 12 12  8 10.84 9.13  8.15  5.56\n10  7  7  7  8  4.82 7.26  6.42  7.91\n11  5  5  5  8  5.68 4.74  5.73  6.89\n\n\nДавайте попробуем посчитать описательные статистики самостоятельно.\n\n# посчитаем среднее\napply(anscombe, 2, mean)\n\n      x1       x2       x3       x4       y1       y2       y3       y4 \n9.000000 9.000000 9.000000 9.000000 7.500909 7.500909 7.500000 7.500909 \n\n# дисперсию\napply(anscombe, 2, var)\n\n       x1        x2        x3        x4        y1        y2        y3        y4 \n11.000000 11.000000 11.000000 11.000000  4.127269  4.127629  4.122620  4.123249 \n\n# коэффициент корреляции, привожу два варианта как посчитать, интересно, какой кажется проще\nmap2_dbl(anscombe %&gt;% select(x1:x4), anscombe %&gt;% select(y1:y4), ~cor(.x, .y))\n\n       x1        x2        x3        x4 \n0.8164205 0.8162365 0.8162867 0.8165214 \n\nmap2_dbl(anscombe[1:4], anscombe[5:8], ~cor(.x, .y))\n\n       x1        x2        x3        x4 \n0.8164205 0.8162365 0.8162867 0.8165214 \n\n# еще простой способ отразить большинство описательных статистик - просто вызвать функцию summary\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n\nМожно увидеть, что описательные статистики совпадают. Что насчет распределения данных?"
  },
  {
    "objectID": "posts/ansombe_quartet.html#построим-графики-распределения-значений",
    "href": "posts/ansombe_quartet.html#построим-графики-распределения-значений",
    "title": "Anscombe’s quartet",
    "section": "Построим графики распределения значений",
    "text": "Построим графики распределения значений\n\n\nShow the code\n# отрисовываем графики по очереди\np1 &lt;- ggplot(anscombe, aes(x1,y1))+\n  geom_point(size = 3.5, fill = 'darkorange', color= 'orangered', \n             alpha = 0.8, shape = 21)+\n  labs(\n       title = \"Dataset 1\" ) +\n  geom_smooth(se = FALSE, method = \"lm\", formula = \"y ~ x\", size = 0.8, alpha = 0.9)+\n  theme_bw()\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nShow the code\np2 &lt;- ggplot(anscombe, aes(x2,y2))+\n  geom_point(size = 3.5, fill = 'darkorange', color= 'orangered', \n             alpha = 0.8, shape = 21)+\n  labs(title = \"Dataset 2\" ) +\n  geom_smooth(se = FALSE, method = \"lm\", formula = \"y ~ x\", \n              size = 0.8, alpha = 0.9)+\n  theme_bw()\np3 &lt;- ggplot(anscombe, aes(x3,y3))+\n   geom_point(size = 3.5, fill = 'darkorange', color= 'orangered', \n             alpha = 0.8, shape = 21)+\n  labs(title = \"Dataset 3\" ) +\n  geom_smooth(se = FALSE, method = \"lm\", formula = \"y ~ x\", \n              size = 0.8, alpha = 0.9)+\n  theme_bw()\np4 &lt;- ggplot(anscombe, aes(x4,y4))+\n   geom_point(size = 3.5, fill = 'darkorange', color= 'orangered', \n             alpha = 0.8, shape = 21)+\n  labs(title = \"Dataset 4\" ) +\n  geom_smooth(se = FALSE, method = \"lm\", formula = \"y ~ x\", \n              size = 0.8, alpha = 0.9)+\n  theme_bw()\n# объединяем их в один плот с помощью библиотеки `patchwork`\n(p1 | p2) / (p3 | p4)\n\n\n\n\n\n\n\n\n\nИтак, как и ожидалось, распределения данных оказались совершенно разными. Подчеркну еще раз важность визуализации данных перед началом анализа. Не стоит опираться только на средние, медианы, дисперсию, поскольку эта информация должна дополняться визуальным представлением данных, даже хотя бы для себя.\nЕще вот такой пример обманчивых описательных статистик:\n\n\n\nобратите внимание на датазавтра наверху\n\n\n\nКроме того, рекомендую строить диаграммы рассеяния (scatter plot) как в коде, приведенном выше, а не опираться только на боксплоты (boxplot), к примеру. Боксплоты сокращают информацию о данных, хотя и являются стандартом на конференциях и в публикациях. Про это можно почитать здесь. Думаю, для публикации неплохим вариантом могут быть violin plots или боксплоты с полупрозрачными точками, отрисованные с помощью geom_jitter (примеры применения можно посмотреть в статье про пределы погрешностей). Правда, это лучше сработает, если точек не больше ~30, на мой взгляд, иначе график будет сильно рябить.\nО корректной, не вводящей в заблуждение читателя визуализации данных написано уже немало статей и книг, пока что приведу несколько ссылок для самостоятельного ознакомления:\n\nЛекция Дженни Брайан (Jenny Bryan) о предобработке данных перед построением графиков\nКнига по визуализации данных, доступна онлайн\nЕще одна книга по визуализации данных, доступна онлайн\nСтатья про самые распространенные ошибки при построении графиков\nСайт colorbrewer с хорошими сочетаниями цветов для отрисовки графиков"
  },
  {
    "objectID": "posts/ansombe_quartet.html#список-источников",
    "href": "posts/ansombe_quartet.html#список-источников",
    "title": "Anscombe’s quartet",
    "section": "Список источников",
    "text": "Список источников\n\nAnscombe, F. J. (1973). “Graphs in Statistical Analysis”. American Statistician. 27 (1): 17–21. doi:10.1080/00031305.1973.10478966\nhttps://en.wikipedia.org/wiki/Anscombe%27s_quartet\n\nПодписывайтесь на телеграм-канал, будет много интересного"
  },
  {
    "objectID": "posts/R_question_how_to_ask.html",
    "href": "posts/R_question_how_to_ask.html",
    "title": "Как задать хороший вопрос в R чате?",
    "section": "",
    "text": "Для русскоязычного R-комьюнити есть два больших чата: R (язык программирования) и Горячая линия R. Здесь я бы хотела поделиться своим опытом задавания вопросов и создания воспроизводимых примеров (reprex, репрекс).\nReprex (reproducible example) – это минимальный пример кода, воспроизводящий ошибку или описывающий, что требуется сделать.\nТакой пример кода удобно копируется в чат с соответствующим форматированием, его легко читать и можно сразу же скопировать себе, чтобы попробовать помочь.\nДля создания репрексов рекомендуется использовать одноименный пакет reprex.\nУстановка: install.packages('reprex')\nДалее я обычно даже не загружаю пакет, а сразу пишу reprex::reprex(). Вариантов использования функции несколько, лично мне удобнее всего оказалось писать нужные строчки кода внутри фигурных скобок функции reprex::reprex({}).\nУ репрекса есть три важных свойства:\n\nкод должен работать (то есть все пакеты загружены и все переменные объявлены)\nкод легко запустить (никаких скриншотов и копирования из консоли со знаком &gt;)\nкод можно не запускать (в репрексе есть аутпут, и можно понять в чем ошибка, даже без запуска кода)\n\nНапример:\n\nreprex::reprex({\n    mtcars %&gt;% \n        filter(mpg &gt; 20) %&gt;% \n        group_by(cyl) %&gt;% \n        summarise(mpg)\n})\n\nПри попытке запустить такой код у меня сразу появилось, что нет функции %&gt;%, даже если пайп работал до этого. Репрекс создает совершенно новую сессию и поэтому необходимо загрузить все пакеты и объявить все переменные, даже если они уже были загружены и объявлены в скрипте. Соответственно, от своих реальных данных, на которых произошла ошибка, нужно взять минимальный воспроизводимый пример. Обычно я создаю игрушечные датасеты df &lt;- data.frame(a  = 1:10, b = letters[1:10]), на которых воссоздаю ошибку. Также можно использовать встроенные датасеты, например mtcars, iris.\nСозданный с помощью функции reprex::reprex() код можно сразу же копировать в телеграм-чат, оформление как код будет сразу же задано с помощью трех бэктиков ```. Однако в новых версиях телеграма появилась подсветка синтаксиса, если вставить код с указанием языка после трех бэктиков ```r, что максимально облегчает работу с кодом и повышает вероятность, что вам смогут помочь с запросом.\nВ случае если данные все же очень сложные, то можно воспользоваться функцией dput. Например, взять первые несколько строк head-ом и поместить в dput: dput(head(mtcars)), где вместо mtcars ваши данные. В результате будет сложная выдача structure(list...), которую можно скопировать и в репрексе создать такую переменную.\n\nreprex::reprex({\n    library(dplyr)\n    df &lt;- structure(list(mpg = c(21, 21, 22.8, 21.4, 18.7, 18.1), cyl = c(6, 6, 4, 6, 8, 6), \n    disp = c(160, 160, 108, 258, 360, 225), hp = c(110, 110, 93, 110, 175, 105), \n    drat = c(3.9, 3.9, 3.85, 3.08, 3.15, 2.76), wt = c(2.62, 2.875, 2.32, 3.215, 3.44, 3.46),\n    qsec = c(16.46, 17.02, 18.61, 19.44, 17.02, 20.22), vs = c(0, 0, 1, 1, 0, 1), \n    am = c(1, 1, 1, 0, 0, 0), gear = c(4, 4, 4, 3, 3, 3), \n    carb = c(4,4, 1, 1, 2, 1)), \n    row.names = c(\"Mazda RX4\", \"Mazda RX4 Wag\", \"Datsun 710\", \"Hornet 4 Drive\", \"Hornet Sportabout\", \"Valiant\"), class = \"data.frame\")\n    df %&gt;% filter(mpg &gt; 20)\n}) \n\nПри таком подходе рекомендуется постараться минимизировать пример, максимально изолировать ошибку, чтобы было удобнее читать и помогать.\nЕсли вопрос не об ошибке, а о том, что нужно сделать, то желательно показать ход мысли, как пытались решить самостоятельно, и можно создать образец данных, которые нужно получить. Вот пара примеров (здесь и здесь) моих вопросов в чате R.\nВообще создание репрекса может занять много времени, но это является крайне полезным. Несколько раз я начинала писать вопрос, создавала репрекс и на этапе создания понимала, в чем ошибка, в итоге репрекс помог сам по себе, даже без обращения к участникам чатов. Один раз успела отправить сообщение и при перечитывании поняла, что было не так, но мне уже успели ответить, не стала удалять.\nОтветы на часто (один раз) задаваемые вопросы:\nВопрос 1: почему бы просто не скинуть таблицу и образец своего скрипта, тогда можно будет сразу на реальных данных показать все?\nОтвет: мне кажется неудобным сохранять данные, сохранять скрипт себе, загружать таблицу заново, когда можно было бы просто скопировать из чата, не забивая себе файловую систему.\nВопрос 2: почему бы не использовать .RData?\nОтвет: в целом, рдату использовать чуть лучше, но все же минусы про файловую систему остаются актуальными. Плюс идея репрекса в минимизации и изолировании примера, чтобы оставались только проблемные строки и столбцы, для фокусировки внимания.\nЕще парочка ссылок: инструкция от Хэдли, пример создания репрекса на shiny, слайды и 50-минутное видео о репрексах от Дженни Брайан (презентация очень крутая, наиболее информативная, советую посмотреть).\nВ общем, рекомендую использовать этот подход, тогда освоение R будет более приятным и успешным. На стаковерфлоу результат репрекса тоже можно забрасывать, я думаю, но возможно туда еще нужно указать результаты sessionInfo() (поправьте в комментариях, если не так). Сама новые вопросы на стаковерфлоу не писала, хватает обычно уже существующих для моих задач.\nПодписывайтесь на телеграм-канал: https://t.me/stats_for_science, будет много интересного."
  },
  {
    "objectID": "posts/types_of_error_bars.html",
    "href": "posts/types_of_error_bars.html",
    "title": "Виды пределов погрешностей",
    "section": "",
    "text": "Сегодня поговорим о различных видах пределов погрешностей или усов, как пишут в русскоязычной литературе (error bars).\nПредупреждаю сразу: по ходу повествования я буду использовать все варианты написания этого термина, даже слово эррор бар.\nВажно отметить, что существует два принципиально разных вида отображения пределов погрешностей на графике:\nОни выглядят на графике одинаково, но по факту фундаментально различны. Давайте разбираться, в чем разница."
  },
  {
    "objectID": "posts/types_of_error_bars.html#descriptive-error-bars-описательные-пределы-погрешностей",
    "href": "posts/types_of_error_bars.html#descriptive-error-bars-описательные-пределы-погрешностей",
    "title": "Виды пределов погрешностей",
    "section": "Descriptive error bars (Описательные пределы погрешностей)",
    "text": "Descriptive error bars (Описательные пределы погрешностей)\nК описательным эррор барам относятся:\n\nРазмах (range): разница между максимальным и минимальным значением в выборке (Xmax - Xmin).\nМежквартильный размах (interquartile range, IQR): разница между третьм квартилем (Q3) и первым квартилем (Q1.).\nСтандартное отклонение (standard deviation, sd): квадратный корень из дисперсии.\n\nРазмах самая простая для понимания метрика, при этом редко использующаяся, поскольку сама по себе разница между максимальным и минимальным значением довольно-таки малоинформативна.\nМежквартильный размах (IQR), точнее 1.5*IQR чаще всего используется на боксплотах (boxplot), я редко встречала 1*IQR или 1.5*IQR как усы к обычным барплотам.\nБарплот (barplot) - столбчатая диаграмма для категориальных данных, их будет много чуть дальше.\n\n\n\nСамое простое описание составляющих боксплота\n\n\nЕсли расставить числа в ряд по возрастанию, то середина этого ряда - медиана (median) или второй квартиль (Q2). Первый квартиль (Q1) - значение, меньше которого 25% процентов данных, третий квартиль (Q3) - значение, меньше которого 75% данных.\nДумаю, что на рисунке понять проще:\n\n\n\nпро межквартильный размах (IQR)\n\n\nМежквартильный размах намного чаще используется для визуализации, так как предоставляет больше информации о данных.\nСтандартное отклонение (standard deviation) по-моему наиболее часто встречается в публикациях и на конференциях (по крайней мере в биологии), да и я обычно использую именно sd в качестве предела погрешностей.\nФормула стандартного отклонения (для генеральной совокупности): \\[\\Large sd = \\sqrt{var} = \\sqrt{\\frac{\\sum_{i=1}^{N}(x_{i} - \\mu)^2}{N}}\\]Где \\(\\mu\\) - среднее значение в генеральной совокупности, \\(N\\) - размер генеральной совокупности, var (variance) - дисперсия. Но мы обычно работаем с выборками, а не генеральной совокупностью, и в формуле вычисления sd в Excel и R используют несмещенную (unbiased) оценку дисперсии и стандартного отклонения (потому что для выборки): \\[\\Large sd = \\sqrt{var} = \\sqrt{\\frac{\\sum_{i=1}^{N}(x_{i} - \\overline{x})^2}{N-1}}\\]\nПочему именно \\(N-1\\) в знаменателе выходит за рамки нашего обсуждения, поэтому ограничусь ссылками: 1, 2, видео с таймкодом.\nЕще не сделала схему с детальным вычислением стандартного отклонения на реальных данных, поэтому пока можно посмотреть на статквесте.\nВажный момент! Все вышеописанные метрики отражают разброс значений в нашей выборке, без каких-либо предположений о происходящем в генеральной совокупности. В этом отличие от второго типа error bar."
  },
  {
    "objectID": "posts/types_of_error_bars.html#inferential-error-bars",
    "href": "posts/types_of_error_bars.html#inferential-error-bars",
    "title": "Виды пределов погрешностей",
    "section": "Inferential error bars",
    "text": "Inferential error bars\nК эррор барам, отражающим статистики вывода относятся:\n\nСтандартная ошибка среднего (standard error of mean, SEM или просто SE);\nДоверительный интервал (confidence interval, CI).\n\nПринципиальное отличие от описательных пределов погрешности в том, что грубо говоря, стандартная ошибка среднего/доверительный интервал пытаются отразить степень уверенности в поиске к примеру истинного среднего генеральной совокупности. В то время как описательные отражают, что происходит конкретно в нашей выборке.\nТут немного инфы для продвинутых (не открывайте, если не уверены, что хотите это знать!):\nНебольшое уточнение: с помощью бутстрепов можно оценивать не только доверительный интервал и стандартную ошибку для среднего, но и для медианы и даже для стандартного отклонения, но про это сейчас не будем\n\nСтандартная ошибка среднего\nТеперь еще немного вымученных формулировок, которые попробую сформулировать понятнее.\nВымученная формулировка: The standard error (SE) of a statistic is the standard deviation of its sampling distribution or an estimate of that standard deviation. (цитата прямо из википедии)\nФормула вычисления стандартной ошибки среднего очень простая - стандартное отклонение, деленное на квадратный корень из размера выборки. Но что на самом деле это значит, какой физический смысл стоит за результатом этого вычисления? Попробуйте сами ответить на этот вопрос, опираясь только на определение из википедии и формулу)\nТеперь попробуем представить, что мы провели некий эксперимент, например измеряли вес 20 мышей после какого-либо воздействия и усредняли полученные значения. При этом мы решили 10 раз повторить свой эксперимент, в результате чего получили 10 средних значений. После этого мы можем посчитать среднее средних (!) и стандартное отклонение средних. Вот это стандартное отклонение выборочных средних и есть стандартная ошибка среднего. Ура? Пойду воспроизводить эксперимент по 10 раз?\nНо мы не всегда (обычно никогда) можем себе позволить повторять эксперимент по 10 раз, и хитрость в том, что мы можем вычислить стандартную ошибку среднего без многократного повторения эксперимента, просто поделив стандартное отклонение на квадратный корень из размера выборки.\nВот тут хорошо расписано, как моделировать стандартную ошибку средних и что она действительно соответствует стандартному отклонению, деленному на квадратный корень из числа наблюдений.\n\\[\\huge SE = \\frac{sd}{\\sqrt{N}}\\] Формула SE (стандартной ошибки), где sd - это стандартное отклонение, N - количество наблюдений\nВот еще можно посмотреть про:\n\nотличия стандартного отклонения от стандартной ошибки https://www.youtube.com/watch?v=SzZ6GpcfoQY\nобъяснение стандартной ошибки с бутстреп-примером https://www.youtube.com/watch?v=XNgt7F6FqDU&t=341s\n\nВ статье, на которую я опиралась при написании этого материала, было указано, что для представления сравнения групп лучше использовать стандартную ошибку/доверительный интервал как error bar, а не стандартное отклонение и другие описательные статистики.\nНо у меня есть неприятное подозрение, что для публикаций и представлений своей работы на конференциях некоторые недобросовестные ученые используют se, чтобы на графиках были усы поменьше. Однако, я не хочу обидеть тех, кто использует стандартную ошибку и понимает физический смысл. Интересно будет собрать примеры работ, где использование se оправданно и разумно, и где это не так, поэтому если есть примеры, то пишите в комментарии.\nВ целом, плюс именно se в том, что при отрисовке сравнений двух или нескольких групп, перекрываемость усов позволяет судить об отсутствии статистической значимости различий (при этом наоборот не работает, про это будет еще чуть дальше), в то время как sd и остальные описательные пределы погрешностей - нет. Однако sd показывает данные почти как они есть, то есть реальный разброс в наших данных, без предположений о генеральной совокупности, поэтому лично я предпочитаю sd для отрисовки. Это тоже интересная тема для дискуссии, буду рада обсудить в комментариях.\nИ наконец…\n\n\nДоверительный интервал\nЕсли простыми словами, то доверительный интервал оценивает диапазон, в котором с заданной уверенностью (например 95%), можно ожидать истинное значение параметра, например среднего генеральной совокупности.\nПрикрепляю формулу (кстати все формулы записаны прямо силами Rmarkdown):\n\\[\\huge CI = \\overline{x} ± z\\frac{s}{\\sqrt{n}}\\]\nФормула доверительного интервала (CI), \\(\\overline{x}\\) - среднее значение выборки, z - значение уровня достоверности, например для 95% уровня достоверности, \\(z = 1.96\\), \\(\\frac{s}{\\sqrt{n}}\\) - формула уже знакомой стандартной ошибки.\nВообще я не люблю эту тему, но к счастью уже существует немало источников, которые объяснили доверительный интервал разными способами:\n\nВ книге у Ивана объяснение доверительных интервалов классическим образом через формулу стандартной ошибки;\nКлассное объяснение доверительных интервалов с помощью бутстрепа на статквесте (канал супер, всем рекомендую);\nБонусом для тех, кому это все слишком просто: я нашла совершенно дикую статью про доверительные интервалы, доверительные полосы и доверительные эллипсы (sic!), поэтому кто желает преисполниться - велком (вот ссылка). Краткого пересказа не будет, это надо прочитать самостоятельно.\n\nНебольшой вывод. Отрисовка доверительных интервалов сейчас считается модной, якобы их проще интерпретировать. Но на самом деле доверительный интервал как и p-value - это один из тех концептов, которые провоцируют просто огромное количество мисинтерпретаций, это кстати одна из причин, по которой я это не люблю рассказывать. Важно сейчас отметить вот что:\n\n\n\nИнтерпретация перекрывания inferential error bars. Ссылка на статью, откуда картинка\n\n\nТаким образом, перекрывание стандартных ошибок говорит об отсутствии значимости в различии, при этом обратное не верно, а с доверительными интервалами наоборот - отсутствие перекрывания доверительных интервалов говорит о значимости различий, в то время обратное не верно.\nВ этом смысле мне нравится концепция стандартного отклонения, потому что их перекрывание или не перекрывание не говорит нам вообще ничего, а значит - нельзя запутаться!). Чуть дальше разберем, как выглядят разные пределы погрешностей!\nВ любом случае, вне зависимости какой тип пределов погрешностей вы выбрали для отображения на графике, всегда нужно подписывать какой, потому что интерпретации совершенно разные."
  },
  {
    "objectID": "posts/types_of_error_bars.html#а-что-если-вообще-не-рисовать-пределы-погрешностей",
    "href": "posts/types_of_error_bars.html#а-что-если-вообще-не-рисовать-пределы-погрешностей",
    "title": "Виды пределов погрешностей",
    "section": "А что если вообще не рисовать пределы погрешностей?",
    "text": "А что если вообще не рисовать пределы погрешностей?\nЕсли число значений в выборке невелико (например меньше 10), то лучше нарисовать все числа как они есть, например с помощью диаграммы рассеяния (scatter plot) без редуцирования информации в боксплоты или барплоты с пределами погрешностей. Если значений больше, то возможно множество вариантов отрисовывания, часто исследователи используют просто барплоты с пределами погрешностей или боксплоты, однако здесь я предлагаю два возможных варианта более репрезентативного отображения данных.\nПервый - это отрисовать violin plot (скрипичная диаграмма), но не просто, а с небольшим боксплотом внутри. Я эту идею подчерпнула на курсе бластима по R, мне показалось очень забавно, прикрепляю небольшой пример как это выглядит на примере данных iris.\n\nlibrary(tidyverse)\nviolin_box &lt;- iris %&gt;% \n  ggplot(aes(x = Species, y = Sepal.Width))+\n  geom_violin(aes(fill = Species))+\n  geom_boxplot(width = 0.15, alpha = 0.8)+\n  theme_bw()\nviolin_box\n\n\n\n\n\n\n\n\nВторой вариант больше подойдет для относительно небольшого количества наблюдений, когда счет идет на десятки, но не тысячи точек. Это комбинация боксплота и отображения точек как они есть с помощью geom_jitter() в пакете ggplot2.\n\nbox_point &lt;- iris %&gt;% \n  ggplot(aes(Species, Sepal.Width))+\n  geom_boxplot()+\n  geom_jitter(aes(colour = Species), \n              position = position_jitter(width = 0.3, height = 0),\n              alpha = 0.6, size = 1.5)+\n  theme_bw()\nbox_point\n\n\n\n\n\n\n\n\nПо моему прикольно получилось! Эти варианты визуализации содержат гораздо больше информации, сравните например с обычными боксплотами и барплотами (здесь как предел погрешности использовала стандартное отклонение).\n\n📝 UPD: в комментариях посоветовали напомнить, что перекрывание или не-перекрывание усов в боксплотах и вайлин плотах не имеет отношения к статистике вывода, то есть не позволяет делать выводы о значимости различий\n\n\nbox &lt;- iris %&gt;% \n  ggplot(aes(Species, Sepal.Width, fill = Species))+\n  geom_boxplot()+\n  theme_bw()\nbar &lt;- iris %&gt;% \n  group_by(Species) %&gt;% \n  summarise(mean_PW = mean(Sepal.Width), sd_PW = sd(Sepal.Width)) %&gt;% \n  ggplot(aes(Species, mean_PW, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean_PW - sd_PW, ymax = mean_PW + sd_PW), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are standard deviation')+\n  theme_bw()\nbox\n\n\n\n\n\n\n\nbar\n\n\n\n\n\n\n\n\nА теперь все вместе на одном графике (обратите внимание на пакет patchwork для красивого объединения плотов на одном рисунке):\n\nlibrary(patchwork)\np &lt;- (violin_box + box_point) / (box + bar)\np + plot_annotation(tag_levels = 'A')\n\n\n\n\n\n\n\n\nГолосуйте, какой плот больше нравится и является более информативным. Мне лично здесь нравится вариант B - box+точки, кажется наиболее информативным и красивым. Возможно, если наблюдений будет больше, то лучше окажется первый вариант с вайлином плотом и боксом.\n\n📝 В violin plot-е (скрипичная диаграмма) форма отражает плотность распределения значений. Грубо говоря, чем больше значений в диапазоне, тем толще соответствующий диапазон на графике. В случае geom_jitter по оси X важна только принадлежность точек к группе, внутри одной группы точки по оси X распределяются так, чтобы не перекрывать друг друга.\n\nА теперь визуализация трех основных пределов погрешностей: стандартного отклонения, стандартной ошибки и доверительных интервалов на данных iris.\n\nlibrary(data.table)\nbar_se &lt;- iris %&gt;% \n  group_by(Species) %&gt;% \n  summarise(mean_PW = mean(Sepal.Width), se_PW = sd(Sepal.Width)/sqrt(length(Sepal.Width))) %&gt;% \n  ggplot(aes(Species, mean_PW, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean_PW - se_PW, ymax = mean_PW + se_PW), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are standard error')+\n  theme_bw()\n# bar_se\n\nbar_CI &lt;- iris %&gt;% \n  group_by(Species) %&gt;%\n  summarise(n=n(), mean=mean(Sepal.Length), sd=sd(Sepal.Length)) %&gt;%\n  mutate(se = sd/sqrt(n))  %&gt;%\n  mutate(ic = se * qt((1-0.05)/2 + .5, n-1)) %&gt;% \n  ggplot(aes(Species, mean, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean - ic, ymax = mean + ic), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are confidence intervals')+\n  theme_bw()\n# bar_CI\nbar + bar_se + bar_CI+  plot_layout(ncol = 2)\n\n\n\n\n\n\n\n\nТеперь я сделаю одну плохую вещь, а именно просто сравню тестом Стьюдента Sepal.Width для разных видов ириса. Как думаете, почему это плохо?\nЯ в этом примере не делаю поправку на множественное тестирование\n\niris %&gt;% \n  setDT() \ncat('versicolor vs setosa: \\np-value of the test', t.test(iris[Species == 'setosa', Sepal.Width], iris[Species == 'versicolor', Sepal.Width])$p.value)\n\nversicolor vs setosa: \np-value of the test 2.484228e-15\n\ncat('setosa vs virginica: \\np-value of the test', t.test(iris[Species == 'setosa', Sepal.Width], iris[Species == 'virginica', Sepal.Width])$p.value)\n\nsetosa vs virginica: \np-value of the test 4.570771e-09\n\ncat('virginica vs versicolor: \\np-value of the test', t.test(iris[Species == 'virginica', Sepal.Width], iris[Species == 'versicolor', Sepal.Width])$p.value)\n\nvirginica vs versicolor: \np-value of the test 0.001819483\n\n\nНо один раз в жизни можно, только для демонстрации того, что все выборки значимо отличаются друг от друга (без поправки), и на графиках можно увидеть что доверительные интервалы не перекрываются.\nУра! Я дописала, а вы дочитали, с чем я всех и поздравляю) Теперь перейдем к выводам."
  },
  {
    "objectID": "posts/types_of_error_bars.html#выводы",
    "href": "posts/types_of_error_bars.html#выводы",
    "title": "Виды пределов погрешностей",
    "section": "Выводы",
    "text": "Выводы\n\nСуществует два типа отображения пределов погрешностей на графике: описательные, которые описывают значения в конкретно нашей выборке и inferential (так и не придумала как переводить), которые пытаются отразить что-то о генеральной совокупности с заданной долей уверенности.\nДля отображения сравнений между группами рекомендуют использовать вторые, поскольку они позволяют делать выводы из перекрывания или не-перекрывания усов.\nОднако, есть способы рисовать распределение наших значений без использования мисинтерпретируемых пределов погрешностей, например violin+boxplot и boxplot+точки\n\nПодписывайтесь на телеграм канал: https://t.me/stats_for_science, будет много интересного. Обсудить пост можно здесь в комментариях."
  },
  {
    "objectID": "posts/welch_test.html",
    "href": "posts/welch_test.html",
    "title": "Тест Стьюдента и тест Велча",
    "section": "",
    "text": "Разберем недостатки схем по выбору статистических тестов, формулу теста Велча и сравним с помощью симуляций тест Стьюдента и тест Велча в разных условиях."
  },
  {
    "objectID": "posts/welch_test.html#проблема-дорожных-карт-по-статистике",
    "href": "posts/welch_test.html#проблема-дорожных-карт-по-статистике",
    "title": "Тест Стьюдента и тест Велча",
    "section": "Проблема дорожных карт по статистике",
    "text": "Проблема дорожных карт по статистике\nНаверняка каждый при проведении статистических тестов сталкивался с проблемой выбора подходящего теста. В научном сообществе есть определенная популярность у “дорожных карт” по выбору статистического метода, пример ниже:\n\n\n\nМожно кликнуть на картинку и перейти на изображение в лучшем качестве\n\n\nЯ выбрала первую попавшуюся схему по запросу how to choose statistical test flow chart, в этой схеме есть сразу несколько ошибок, например миф про 30 наблюдений (тут вообще странное, по мнению автора схемы, при размере выборки больше 30 наблюдений можно использовать z-test).\nОбычно этот миф звучит так: для небольших выборок меньше 30 наблюдений для применения t-теста нужно, чтобы было нормальное распределение данных, а если наблюдений больше 30, то можно использовать t-тест и так, в силу центральной предельной теоремы. Почему это миф, написано в статье “История одного обмана или требования к распределению в t-тесте”.\nСтатья подвергалась определенной критике профильных статистиков, но ключевой момент отражен верно — для t-теста не нужно нормальное распределение данных, нужно нормальное распределение тестовой статистики — то есть выборочных средних. Про это подробно собирается написать статистик Матвей Славенко, я обязательно сделаю репост, когда статья выйдет, так как для сообщества очень нужен такой материал.\nНо вернемся к тесту."
  },
  {
    "objectID": "posts/welch_test.html#тест-велча-теория",
    "href": "posts/welch_test.html#тест-велча-теория",
    "title": "Тест Стьюдента и тест Велча",
    "section": "Тест Велча: теория",
    "text": "Тест Велча: теория\nЧасто для двухвыборочного независимого теста Стьюдента можно встретить требование к равенству дисперсий, и это правильное требование, если использовать классический тест Стьюдента. Однако в большинстве статистических пакетов, в том числе в R, реализован тест Стьюдента с поправкой Велча (Welch) или просто тест Велча, или тест Стьюдента для неравных дисперсий (t-test for unequal variances), для которого нет требования по соблюдению равенства дисперсий.\nИ многие авторы рекомендуют использовать именно его, вне зависимости от равенства дисперсий. Давайте разберемся, так ли это.\n\n\n\n\n\n\nПримечание\n\n\n\nЗдесь и далее формулировка “тест Стьюдента” будет означать двухвыборочный независимый тест Стьюдента без поправки Велча.\nТест Велча - тест Стьюдента с поправкой Велча.\n\n\nФормула вычисления t-статистики теста Стьюдента:\n\\[\nt = \\frac{\\overline{X_1}-\\overline{X_2}}{s_x\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}},\ns_x = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\]\nЧтобы запустить именно тест Стьюдента в R, можно использовать аргумент var.equal = TRUE.\n\nt.test(rnorm(100, mean = 0, sd = 1), rnorm(100, mean = 0, sd = 1), var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  rnorm(100, mean = 0, sd = 1) and rnorm(100, mean = 0, sd = 1)\nt = -1.1878, df = 198, p-value = 0.2363\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.4285169  0.1063450\nsample estimates:\n  mean of x   mean of y \n-0.10910933  0.05197663 \n\n\nОднако это делать не рекомендуется, поскольку при равных дисперсиях тест Стьюдента не будет сильно отличаться от теста Велча, а при разных тест Велча точнее.\nФормула теста Велча:\n\\[\nt = \\frac{\\overline{X}_1 - \\overline{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n\\]\nКоличество степеней свободы:\n\\[\ndf = \\frac{(s_1^2/n_1 + s_2^2 / n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}\n\\]\nДля обучения мне проще начать рассказ с теста Стьюдента без поправки Велча, потому что на нем удобно посчитать вручную тестовую статистику и степени свободы. Однако потом обязательно уточняю, что рекомендуется использовать тест Велча, преимущество которого в необязательности требования равенства дисперсий.\n\n\n\n\n\n\nОффтоп\n\n\n\nПри этом в источниках о тесте Стьюдента очень часто можно встретить требование к равенству дисперсий, как и к нормальности распределения исходных данных.\nНо наиболее критичным требованием для проведения теста Стьюдента является независимость наблюдений.\n\n\nДавайте разберем с помощью симуляций, как работает тест Велча и тест Стьюдента в разных ситуациях.\n\nlibrary(tidyverse) # загрузим тайдиверс\n\nРазберем разные кейсы: проверим и ошибку первого рода, и мощность теста при равных и разных дисперсиях, и в зависимости от равенства объемов выборок."
  },
  {
    "objectID": "posts/welch_test.html#отличий-нет-проверка-на-ошибку-первого-рода",
    "href": "posts/welch_test.html#отличий-нет-проверка-на-ошибку-первого-рода",
    "title": "Тест Стьюдента и тест Велча",
    "section": "Отличий нет, проверка на ошибку первого рода",
    "text": "Отличий нет, проверка на ошибку первого рода\n\nОдинаковое среднее и дисперсия, равный размер выборок\nНачнем с ситуации, когда у нас обе выборки из генеральных совокупностей с одинаковым средним и дисперсией, например, здесь это нормальное распределение со средним 0.2 и стандартным отклонением 1.\n\n\n\n\n\n\nПримечание\n\n\n\nЗдесь и в дальнейшем для симуляций будет создаваться генеральная совокупность (размером 100000) с заданными параметрами среднего и стандартного отклонения, а далее будут многократно извлекаться “выборки” заданного размера. Таким образом будет соблюдаться общая логика статистического вывода — наличие генеральной совокупности с заданными параметрами и извлечение выборок.\n\n\nДля всех тестов в приведенных ниже расчетах зафиксировали уровень значимости \\(\\alpha=0.05\\).\nТест Велча\n\npopulation &lt;- rnorm(100000, mean = 0.2, sd = 1) # создание генеральной совокупности\np_values &lt;- replicate(1000, t.test(population %&gt;% \n                              sample(size = 10000, replace = FALSE), \n                            population %&gt;% \n                              sample(size = 10000, replace = FALSE))$p.value)\nhist(p_values, main = 'Распределение p-value для теста Велча',\n     sub = 'Равные средние, равные дисперсии')\n\n\n\n\n\n\n\nmean(p_values &lt; 0.05) # доля p-value, которые оказались меньше 0.05 (прокрасились) \n\n[1] 0.034\n\n\nТест Стьюдента\n\np_values &lt;- replicate(1000, t.test(population %&gt;% \n                              sample(size = 10000, replace = FALSE), \n                            population %&gt;% \n                              sample(size = 10000, replace = FALSE), \n                            var.equal = TRUE)$p.value)\nhist(p_values, main = 'Распределение p-value для теста Стьюдента',\n     sub = 'Равные средние, равные дисперсии')\n\n\n\n\n\n\n\nmean(p_values &lt; 0.05) # доля p-value, которые оказались меньше 0.05 (прокрасились)\n\n[1] 0.04\n\n\nЗдесь у нас вероятность ошибки первого рода для обоих тестов примерно 0.05, а также распределение p-value похоже на равномерное. Это ожидаемо и корректно, так как выборки извлекались из одинаковой генеральной совокупности, а значит, что доля ложноположительных результатов (=прокрасов) должна быть не больше заданного уровня \\(\\alpha = 0.05\\).\n\n\nОдинаковое среднее, разная дисперсия, равный размер выборок\nТеперь рассмотрим случай с неравными дисперсиями. Для этого создадим две генеральные совокупности с одинаковым средним, но в одной стандартное отклонение 1, в другой 2. Извлекаем две выборки размером 10000 значений и сравниваем их тестом Стьюдента и тестом Велча.\nТест Велча\n\npopulation1 &lt;- rnorm(100000, mean = 0.2, sd = 1) # создание первой генеральной совокупности\npopulation2 &lt;- rnorm(100000, mean = 0.2, sd = 2) # создание второй генеральной совокупности\n# проведение теста\np_values_welch &lt;- replicate(10000, t.test(population1 %&gt;% \n                                      sample(size = 10000, replace = FALSE), \n                                    population2 %&gt;% \n                                      sample(size = 10000, replace = FALSE))$p.value)\nhist(p_values_welch, main = 'Распределение p-value для теста Велча',\n     sub = 'Равные средние, разные дисперсии')\n\n\n\n\n\n\n\nmean(p_values_welch &lt; 0.05)\n\n[1] 0.0396\n\n\nТест Стьюдента\n\n# проведение теста\np_values_st &lt;- replicate(10000, t.test(population1 %&gt;% \n                                      sample(size = 10000, replace = FALSE), \n                                    population2 %&gt;% \n                                      sample(size = 10000, replace = FALSE), \n                                    var.equal = TRUE)$p.value)\nhist(p_values_st, main = 'Распределение p-value для теста Стьюдента',\n     sub = 'Равные средние, разные дисперсии')\n\n\n\n\n\n\n\nmean(p_values_st &lt; 0.05)\n\n[1] 0.0416\n\n\nЗдесь выводы те же самые, как в предыдущем случае. Хоть и дисперсия в генеральных совокупностях разная, оба теста сохраняют долю ошибки первого рода на нужном уровне (меньше 0.05).\nТут важно указать, что размер выборок в данном примере одинаковый. Однако тест Стьюдента без поправки Велча становится неустойчивым с точки зрения ошибки первого рода, в случае, когда у нас выборки сильно отличаются по размеру.\n\n\nОдинаковое среднее, разная дисперсия, разный размер выборок\nНапример, в выборке с большей дисперсией 3000 наблюдений, в выборке с меньшей дисперсией 7000 наблюдений.\n\n\n\n\n\n\nПримечание\n\n\n\nЗдесь я написала так для краткости, имелось ввиду: выборки, извлеченные из генеральной совокупности с большей дисперсией, содержат 3000 наблюдений, а выборки, извлеченные из генеральной совокупности с меньшей дисперсией, содержат 7000 наблюдений.\n\n\n\n\n\n\n\n\nПример\n\n\n\nТакая ситуация может встретиться в A/B тестировании, когда для 30% пользователей мы показываем тестовую версию, а контрольную версию видят 70% пользователей.\n\n\n\n# Тест Велча\nmean(replicate(10000, t.test(population1 %&gt;% \n                               sample(size = 7000, replace = FALSE), \n                             population2 %&gt;% \n                               sample(size = 3000, replace = FALSE))$p.value) &lt; 0.05)\n\n[1] 0.0489\n\n# Тест Стьюдента\nmean(replicate(10000, t.test(population1 %&gt;% \n                               sample(size = 7000, replace = FALSE), \n                             population2 %&gt;% \n                               sample(size = 3000, replace = FALSE), \n                             var.equal = TRUE)$p.value) &lt; 0.05)\n\n[1] 0.1201\n\n\nПолучилось, что тест Стьюдента в ситуации с неравными дисперсиями и разным размером выборки показал себя хуже и мы наблюдали ложные прокрасы в 12% случаев (вместо 5%, как должно было бы быть).\nС увеличением дисбаланса в размере выборок, ситуация становится хуже, например, вот что произойдет, если выборки отличаются по размеру в 9 раз (тоже может встретиться в A/B тестировании, пример, что это часто используемая практика по ссылке).\n\n# тест Велча\nmean(replicate(10000, t.test(population1 %&gt;% \n                               sample(size = 9000, replace = FALSE), \n                             population2 %&gt;% \n                               sample(size = 1000, replace = FALSE))$p.value) &lt; 0.05) \n\n[1] 0.05\n\n# тест Стьюдента\nmean(replicate(10000, t.test(population1 %&gt;% \n                               sample(size = 9000, replace = FALSE), \n                             population2 %&gt;% \n                               sample(size = 1000, replace = FALSE), \n                             var.equal = TRUE)$p.value) &lt; 0.05)\n\n[1] 0.2406\n\n\nТут для теста Стьюдента без поправки Велча получилось 24% ложноположительных результатов! Это очень много относительно заданного уровня \\(\\alpha=0.05\\). Получается, что мы будем находить значимые отличия почти в четверти случаев, и принимать неверные решения. Тест Велча при этом сохраняет долю ложноположительных результатов на уровне 5%, как и должно быть.\nДля выборок разного размера при увеличении неравенства дисперсий наблюдается дальнейшее ухудшение работы теста Стьюдента (в ситуации, когда меньшая выборка с большей дисперсией).\nДавайте построим график зависимости ошибки первого рода от неравенства дисперсий в выборке, где размер выборок отличается в 9 раз, при этом меньшая выборка с большей дисперсией.\n\n\nCode\nvar_size &lt;- seq(0, 5, 0.5)\ncalculate_mean_error_1st_type &lt;- function(x, var.equal) {\n  mean(replicate(1000, \n                 t.test(rnorm(9000, 0.2, 1), \n                        rnorm(1000, 0.2, 1+x), \n                        var.equal = var.equal)$p.value) &lt; 0.05)\n}\nwelch_error_1st_type &lt;- map_dbl(var_size, ~calculate_mean_error_1st_type(., FALSE))\nstudents_error_1st_type &lt;- map_dbl(var_size, ~calculate_mean_error_1st_type(., TRUE))\n\ndata.frame(var_size, welch_error_1st_type, students_error_1st_type) %&gt;% \n  pivot_longer(cols = c(welch_error_1st_type, students_error_1st_type), \n               names_to = 'type', values_to = 'error_1st_type') %&gt;% \n  ggplot(aes(var_size, error_1st_type))+\n  geom_point(aes(color = type))+\n  geom_line(aes(color = type))+\n  scale_x_continuous(name = 'Разница в стандартном отклонении между выборками')+\n  scale_color_discrete(name = 'Вид теста', labels = c('тест Стьюдента', 'тест Велча'))+\n  scale_y_continuous(name = 'Доля ошибки первого рода', limits = c(0, 0.5))+\n  ggtitle('Зависимость ошибки первого рода от стандартного отклонения', subtitle = 'меньшая выборка с большей дисперсией')+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nПри таком дисбалансе выборок, чем больше разница в дисперсии, тем хуже работает тест Стьюдента.\nПроверим, что будет, если наоборот, большая выборка будет с большей дисперсией.\n\n\nCode\nvar_size &lt;- seq(0, 5, 0.5)\ncalculate_mean_error_1st_type &lt;- function(x, var.equal) {\n  mean(replicate(1000, \n                 t.test(rnorm(1000, 0.2, 1), \n                        rnorm(9000, 0.2, 1+x), \n                        var.equal = var.equal)$p.value) &lt; 0.05)\n}\nwelch_error_1st_type &lt;- map_dbl(var_size, ~calculate_mean_error_1st_type(., FALSE))\nstudents_error_1st_type &lt;- map_dbl(var_size, ~calculate_mean_error_1st_type(., TRUE))\n\ndata.frame(var_size, welch_error_1st_type, students_error_1st_type) %&gt;% \n  pivot_longer(cols = c(welch_error_1st_type, students_error_1st_type), \n               names_to = 'type', values_to = 'error_1st_type') %&gt;% \n  ggplot(aes(var_size, error_1st_type))+\n  geom_point(aes(color = type))+\n  geom_line(aes(color = type))+\n  scale_x_continuous(name = 'Разница в стандартном отклонении между выборками')+\n  scale_color_discrete(name = 'Вид теста', labels = c('тест Стьюдента', 'тест Велча'))+\n  scale_y_continuous(name = 'Доля ошибки первого рода', limits = c(0, 0.5))+\n  ggtitle('Зависимость ошибки первого рода от стандартного отклонения', subtitle = 'большая выборка с большей дисперсией')+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nЗдесь тест Стьюдента работает даже лучше, доля ложноположительных результатов очень низкая. Но и тест Велча работает нормально, сохраняя ее на уровне примерно 0.05.\nПри этом при равных размерах выборок, разница в дисперсиях не влияет на оба теста.\n\n\nCode\nvar_size &lt;- seq(0, 5, 0.5)\ncalculate_mean_error_1st_type &lt;- function(x, var.equal) {\n  mean(replicate(1000, t.test(rnorm(1000, 0.2, 1), rnorm(1000, 0.2, 1+x), var.equal = var.equal)$p.value) &lt; 0.05)\n}\nwelch_error_1st_type &lt;- map_dbl(var_size, ~calculate_mean_error_1st_type(., FALSE))\nstudents_error_1st_type &lt;- map_dbl(var_size, ~calculate_mean_error_1st_type(., TRUE))\n\ndata.frame(var_size, welch_error_1st_type, students_error_1st_type) %&gt;% \n  pivot_longer(cols = c(welch_error_1st_type, students_error_1st_type), \n               names_to = 'type', values_to = 'error_1st_type') %&gt;% \n  ggplot(aes(var_size, error_1st_type))+\n  geom_point(aes(color = type))+\n  geom_line(aes(color = type))+\n  scale_x_continuous(name = 'Разница в стандартном отклонении между выборками')+\n  scale_color_discrete(name = 'Вид теста', labels = c('тест Стьюдента', 'тест Велча'))+\n  scale_y_continuous(name = 'Доля ошибки первого рода', limits = c(0, 0.5))+\n  ggtitle('Зависимость ошибки первого рода от стандартного отклонения', \n          subtitle = 'для теста Стьюдента и теста Велча для равных выборок')+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nТаким образом, при одинаковом размере выборок, тест Стьюдента устойчив к нарушению предположения о равенстве дисперсий. Однако, в ситуации, когда выборки разного размера, причем большая выборка с меньшей дисперсией, тест Стьюдента начинает завышать ошибку первого рода.\nПоэтому наиболее надежно будет использовать тест Велча в любом случае, вне зависимости от равенства дисперсий и размера выборок, так как он сохраняет ошибку первого рода на заданном уровне \\(\\alpha\\) .\n\n\n\n\n\n\nОффтоп\n\n\n\nКстати, и у теста Манна-Уитни не все хорошо в таком примере\n\nmean(replicate(1000, wilcox.test(population1 %&gt;% \n                               sample(size = 9000, replace = FALSE), \n                             population2 %&gt;% \n                               sample(size = 1000, replace = FALSE))$p.value) &lt; 0.05)\n\n[1] 0.129\n\n\n\n\nТеперь рассмотрим как поведут себя тесты, в случае, когда отличия действительно есть."
  },
  {
    "objectID": "posts/welch_test.html#отличия-есть-проверка-на-мощность-теста",
    "href": "posts/welch_test.html#отличия-есть-проверка-на-мощность-теста",
    "title": "Тест Стьюдента и тест Велча",
    "section": "Отличия есть, проверка на мощность теста",
    "text": "Отличия есть, проверка на мощность теста\n\nРазное среднее, одинаковая дисперсия, равный размер выборок\nНачнем с ситуации, когда извлекаем выборки из двух генеральных совокупностей с разным средним и равной дисперсией.\n\npop1 &lt;- rnorm(100000, mean = 0.2, sd = 1)\npop2 &lt;- rnorm(100000, mean = 0.3, sd = 1)\nsummary(pop1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-4.4529 -0.4758  0.1953  0.1967  0.8738  4.4452 \n\nsummary(pop2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-4.1232 -0.3741  0.2974  0.2967  0.9762  4.7235 \n\n\nВизуализируем полученные выборки, пунктиром показано среднее.\n\n\nCode\ndata.frame(sample1 = pop1 %&gt;% sample(10000, replace = FALSE), \n           sample2 = pop2 %&gt;% sample(10000, replace = FALSE)) %&gt;% \n  rownames_to_column(var = 'id') %&gt;% \n  pivot_longer(cols = c(sample1, sample2)) %&gt;% \n  ggplot(aes(value, fill = name))+\n  geom_density(alpha = 0.5)+\n  facet_wrap(~name, nrow = 2)+\n  stat_summary(aes(xintercept = ..x.., y = 0), \n               fun = mean, geom = \"vline\", orientation = \"y\", alpha = 0.8, linetype=\"dashed\")+\n  theme_bw()\n\n\n\n\n\n\n\n\n\nПроверим работу тестов:\nТест Велча:\n\np_value &lt;- replicate(10000, t.test(pop1 %&gt;% \n                               sample(10000, replace = FALSE), \n                             pop2 %&gt;% \n                               sample(10000, replace = FALSE))$p.value)\nhist(p_value)\n\n\n\n\n\n\n\nmean(p_value &lt; 0.05)\n\n[1] 1\n\n\nТест Стьюдента:\n\np_value &lt;- replicate(10000, t.test(pop1 %&gt;% \n                               sample(10000, replace = FALSE), \n                             pop2 %&gt;% \n                               sample(10000, replace = FALSE), \n                            var.equal = TRUE)$p.value)\nhist(p_value)\n\n\n\n\n\n\n\nmean(p_value &lt; 0.05)\n\n[1] 1\n\n\nОба теста нашли отличия там, где они есть в 100% случаев, что говорит о высокой мощности тестов, даже если отличия не очень большие (тут размер выборки примерно как в A/B тестировании, в биологии выборки будут поменьше).\nПопробуем добавить неравенство дисперсий.\n\n\nРазное среднее, разная дисперсия, равный размер выборок\nСреднее отличается, и еще стандартное отклонение в одной из выборок выше на 2.\nПроверим работу тестов:\n\npop1 &lt;- rnorm(100000, 0.2, 1) # создание генеральной совокупности\npop2 &lt;- rnorm(100000, 0.3, 3) # создание генеральной совокупности\nmean(replicate(10000, t.test(pop1 %&gt;% \n                               sample(10000, replace = FALSE), \n                             pop2 %&gt;% \n                               sample(10000, replace = FALSE))$p.value) &lt; 0.05)\n\n[1] 0.9166\n\n\n\nmean(replicate(10000, t.test(pop1 %&gt;% \n                               sample(10000, replace = FALSE), \n                             pop2 %&gt;% \n                               sample(10000, replace = FALSE),\n                             var.equal = TRUE)$p.value) &lt; 0.05)\n\n[1] 0.9145\n\n\nПри равных размерах выборок оба теста хорошо справляются с неравенством дисперсий. Мощность теста больше 80% в обоих случаях.\nЕще немного усложним и рассмотрим в ситуации с разным размером выборок.\n\n\nРазное среднее, разная дисперсия, разный размер выборок\n\npop1 &lt;- rnorm(100000, 0.2, 1)\npop2 &lt;- rnorm(100000, 0.3, 2)\nsummary(pop1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-4.7231 -0.4747  0.1995  0.1985  0.8761  4.2265 \n\nsummary(pop2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-7.6160 -1.0539  0.3081  0.3019  1.6534  9.5586 \n\n# тест Велча\nmean(replicate(10000, t.test(pop1 %&gt;% \n                               sample(3000, replace = FALSE), \n                             pop2 %&gt;% \n                               sample(7000, replace = FALSE))$p.value) &lt; 0.05)\n\n[1] 0.9355\n\n\n\n# тест Стьюдента\nmean(replicate(10000, t.test(pop1 %&gt;% \n                               sample(3000, replace = FALSE), \n                             pop2 %&gt;% \n                               sample(7000, replace = FALSE),\n                             var.equal = TRUE)$p.value) &lt; 0.05)\n\n[1] 0.8315\n\n\nЗдесь тест Велча показал себя несколько лучше, но оба теста корректно находят отличия там, где они есть.\nПроверим, что будет, если поменять местами выборки, чтобы в меньшей выборке была бОльшая дисперсия.\n\n# тест Велча\nmean(replicate(10000, t.test(pop1 %&gt;% \n                               sample(7000, replace = FALSE), \n                             pop2 %&gt;% \n                               sample(3000, replace = FALSE))$p.value) &lt; 0.05)\n\n[1] 0.7768\n\n\n\n# тест Стьюдента\nmean(replicate(10000, t.test(pop1 %&gt;% \n                               sample(7000, replace = FALSE), \n                             pop2 %&gt;% \n                               sample(3000, replace = FALSE),\n                             var.equal = TRUE)$p.value) &lt; 0.05)\n\n[1] 0.8785\n\n\nОба теста показали хороший результат в этом случае, возможно даже тест Стьюдента немного лучше."
  },
  {
    "objectID": "posts/welch_test.html#выводы",
    "href": "posts/welch_test.html#выводы",
    "title": "Тест Стьюдента и тест Велча",
    "section": "Выводы",
    "text": "Выводы\nВ большинстве случаев оба теста контролируют ошибку первого рода и мощность на заданном уровне. Однако у теста Стьюдента есть проблема с ошибкой первого рода (ложноположительные результаты) в ситуации с неравными дисперсиями и разным размером выборок.\n\nЗдесь ✅ — тест показал себя хорошо, ❌ — тест показал себя плохо, 🟡 — тест показал себя не оптимально, но не слишком плохо\n\n\n\n\n\n\n\n\nтест Велча\nтест Стьюдента\n\n\n\n\nОтличий нет, равные дисперсии, равные выборки\n✅\n✅\n\n\nОтличий нет, разные дисперсии, равные выборки\n✅\n✅\n\n\nОтличий нет, разные дисперсии, разные выборки, меньшая выборка с большей дисперсией\n✅\n❌\n\n\nОтличий нет, разные дисперсии, разные выборки, бОльшая выборка с большей дисперсией\n✅\n✅\n\n\nОтличия есть, равные дисперсии, равные выборки\n✅\n✅\n\n\nОтличия есть, разные дисперсии, равные выборки\n✅\n✅\n\n\nОтличия есть, разные дисперсии, разные выборки, меньшая выборка с большей дисперсией\n🟡\n✅\n\n\nОтличия есть, разные дисперсии, разные выборки, бОльшая выборка с большей дисперсией\n✅\n🟡\n\n\n\nПоэтому рекомендация использовать тест Велча вне зависимости от дисперсий остается актуальной.\n\n\n\n\n\n\nЧто можно еще изучить:\n\n\n\nВ этом материале не рассмотрела, что будет при небольших размерах выборок, проверила только часть из разобранных кейсов. В плане ошибки первого рода выводы не меняются на малых выборках, а вот для оценки мощности нужно реализовать более сильные эффекты, так как на малых выборках не хватает мощности обоих тестов.\nВозможно, вынесу разбор этого в отдельный пост, так как здесь уже и так информации достаточно много.\n\n\nПодписывайтесь на телеграм-канал, кто еще этого не сделал, пишите комментарии в телеграме или здесь!"
  },
  {
    "objectID": "posts/how_to_install_R.html#на-ubuntu-20.04-22.04",
    "href": "posts/how_to_install_R.html#на-ubuntu-20.04-22.04",
    "title": "Инструкция по установке R и RStudio",
    "section": "На Ubuntu 20.04, 22.04",
    "text": "На Ubuntu 20.04, 22.04\nШаг 1: Установить r-base:\nДля Ubuntu 22.04: https://www.how2shout.com/linux/how-to-install-r-base-ubuntu-22-04-lts-jammy/\nДля Ubuntu 20.04: https://linuxize.com/post/how-to-install-r-on-ubuntu-20-04/\nШаг 2: Установить зависимости RStudio\nВ терминале (вызвать можно с помощью сочетания клавиш Ctrl+Alt+T)\nsudo apt update\nsudo apt install libssl-dev libclang-dev libpq5\nШаг 3: Установить RStudio\nСкачать отсюда https://www.rstudio.com/products/rstudio/download/#download. Выбрать бесплатную версию, соответствующую вашей операционной системе. Запустить терминал, перейти в папку загрузок и запустить: sudo dpkg -i &lt;DEB_FILE_NAME&gt;, где ‘DEB_FILE_NAME’ название скачанного .deb файла\nШаг 4: Установить необходимые для многих R пакетов зависимости\nsudo apt update\nsudo apt -y install libpng-dev libxml2-dev libxml2 libxrender1 libxtst6 libxi6 libfontconfig1-dev libmagickwand-dev libmagick++-dev\nsudo apt -y install libudunits2-dev libgeos-dev libfontconfig1-dev libharfbuzz-dev libfribidi-dev libfreetype6-dev libtiff5-dev libjpeg-dev libpq-dev cargo libcurl4-openssl-dev\nБлагодаря этой инструкции мне удалось успешно установить tidyverse со всеми его зависимостями на свежую Ubuntu 22.04, так что надеюсь, что у вас тоже все получится!"
  },
  {
    "objectID": "posts/how_to_install_R.html#на-windows-10-11",
    "href": "posts/how_to_install_R.html#на-windows-10-11",
    "title": "Инструкция по установке R и RStudio",
    "section": "На Windows 10, 11",
    "text": "На Windows 10, 11\nШаг 1: Скачать R с официального сайта https://cran.r-project.org/bin/windows/base/ Запустить установщик.\nШаг 2: Скачать RStudio (бесплатную версию) https://www.rstudio.com/products/rstudio/download/ Запустить установщик с дефолтными параметрами.\nЕсли вдруг у вас на компьютере юзернейм написан кириллицей, то переходите к разделу часто встречающихся проблем. Если же нет, поздравляю с подключением!"
  },
  {
    "objectID": "posts/how_to_install_R.html#на-macos",
    "href": "posts/how_to_install_R.html#на-macos",
    "title": "Инструкция по установке R и RStudio",
    "section": "На MacOS",
    "text": "На MacOS\nВ целом, установка не сильно отличается от Windows.\nШаг 1: Скачать R с официального сайта https://cran.r-project.org/bin/macosx/\nЗапустить установщик\nШаг 2: Скачать RStudio (бесплатную версию) https://posit.co/download/rstudio-desktop/\nЗапустить установщик с дефолтными параметрами\nОднако, я заметила, что пользователи с процессором M1 сталкиваются с определенными проблемами при установке пакетов. Например, при установке пакета psych нужен gfortran на устройстве. Можно поискать решения, погуглив, например, ‘install gfortran mac M1’. Одно из решений приведено по ссылке. Кроме того, по этой ссылке рекомендации как компилировать пакет data.table для M1 процессора.\nUPD от 30.10.2024: я сама устанавливала R и RStudio и пакеты для работы на MacOS с процессором M3, и оказалось, что все работает без дополнительных настроек, просто скачиваем R и RStudio, и устанавливаем нужные пакеты как обычно через install.packages(). Возможно есть трудности с более старым процессорами линейки M."
  },
  {
    "objectID": "posts/how_to_install_R.html#рекомендации-по-настройке-rstudio-перед-началом-работы",
    "href": "posts/how_to_install_R.html#рекомендации-по-настройке-rstudio-перед-началом-работы",
    "title": "Инструкция по установке R и RStudio",
    "section": "Рекомендации по настройке RStudio перед началом работы",
    "text": "Рекомендации по настройке RStudio перед началом работы\nПервое, что советую сделать: настроить удаление RData при закрытии R и не восстанавливать при перезапуске.\n\n\n\nНужно выбрать не сохранять RData при выходе и не восстанавливать при запуске R\n\n\nРекомендую почитать материал по эффективной организации работы в R по ссылке, разобрано более подробно и с большим количеством ссылок на дополнительные материалы"
  },
  {
    "objectID": "posts/how_to_install_R.html#часто-встречающиеся-проблемы",
    "href": "posts/how_to_install_R.html#часто-встречающиеся-проблемы",
    "title": "Инструкция по установке R и RStudio",
    "section": "Часто встречающиеся проблемы",
    "text": "Часто встречающиеся проблемы\nОдна из распространенных проблем у пользователя R на Windows - это написанное кириллицей имя пользователя.\n\nНадежнее всего попробовать переименовать юзернейм например по этой инструкции. Можно погуглить еще, как переименовать пользователя в вашей версии Windows, вот еще одна ссылка.\nТакже можно переустановить систему с созданием юзернейма на латинице.\n\nНо если эти подходы кажутся сложными и долгими, можно изменить пути для записи устанавливаемых библиотек, чтобы они не содержали кириллицу. Однако, я не гарантирую, что это не повлечет проблем в дальнейшем, но этот путь кажется проще.\nТакже способ замены дефолтного пути может помочь, если по умолчанию R пытается поставить пакеты в папку OneDrive.\nШаг 1: Создайте папку в корневом диске C:// или D:// для установки пакетов без кириллических символов и пробелов, например C:/Rlib.\nШаг 2: Создайте папку для временных файлов без кириллических символов и пробелов, например C:/Temp\nШаг 3: Выполните в консоли Rstudio команду\nsystem(\"setx R_LIBS C:/Rlib\")\nsystem(\"setx TEMP C:/Temp\")\nsystem(\"setx TMP C:/Temp\")\nШаг 4: Перезапустите RStudio (можно сделать сочетанием клавиш Ctrl+Shift+F10)\nШаг 5: Проверьте, что R знает, куда ему ставить пакеты. Для этого выполните в консоли Rstudio команду .libPaths(). Скорее всего в выдаче будет две директории, исходная C:/Users/Юзер/AppData/..., и вновь созданная, то есть C:/Rlib. Чтобы переназначить новую директорию как дефолтную для установки пакетов запустите следующий код:\nmyPaths &lt;- .libPaths()   # get the paths\nmyPaths &lt;- c(myPaths[2], myPaths[1])  # switch them\n.libPaths(myPaths)  # reassign them\nШаг 6: Однако это понадобится делать каждый раз при перезапуске сессии RStudio. Чтобы сделать эту настройку постоянной, можно прописать этот код в файле Rprofile. Найти этот файл можно следующим образом: Tools -&gt; Global Options -&gt; General\n\n\n\nздесь содержится путь к актуальной версии R\n\n\nПерейти в ./library/base/R\n\n\n\nоткрыть файл Rprofile текстовым редактором, например Notepad++\n\n\nВ конце файла вставить строки, переназначающие нашу дефолтную библиотеку:\nmyPaths &lt;- .libPaths()\nmyPaths &lt;- c(myPaths[2], myPaths[1])\n.libPaths(myPaths)\nПерезапустите RStudio. Надеюсь, это поможет успешно устанавливать пакеты и осваивать R!\nВот тут по ссылке можно почитать более подробно и с картинками.\nНебольшое напоминание - не рекомендуется использовать кириллицу и пробелы в названиях столбцов и файлов, потому что могут быть ошибки с кодировкой при пересылании файла, в результате чего кириллица превратится в ???\nИсправить это можно с помощью File - Reopen with encoding, выбрать UTF-8 в качестве кодировки. Но в целом рекомендую даже комментарии, не говоря уж об остальном писать только латиницей, это позволит избежать проблем с кодировкой в будущем.\nПри написании этого материала использовала следующие источники\n\nhttps://bdemeshev.github.io/installation/r/R_installation.html\nhttps://www.accelebrate.com/library/how-to-articles/r-rstudio-library\nМатериалы со школы NGSchool\n\nПодписывайтесь на мой телеграм-канал, следите за новостями, обещаю интересные материалы по статистике и R!"
  },
  {
    "objectID": "posts/review_of_statistics_course.html",
    "href": "posts/review_of_statistics_course.html",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "",
    "text": "По итогам многочисленных дискуссий в чатах по статистике и биоинформатике (BioStat &lt;- R | Чат по статистике и R, BIOINF | Education & Career), я решила написать обзор на курс “Основы статистики” на платформе stepik. Давайте разберем его достоинства и недостатки, а также есть ли смысл его смотреть сейчас."
  },
  {
    "objectID": "posts/review_of_statistics_course.html#общее-описание-курса",
    "href": "posts/review_of_statistics_course.html#общее-описание-курса",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Общее описание курса",
    "text": "Общее описание курса\nНемного контекста: курс был опубликован в начале 2015го года, и был одним из первых бесплатных русскоязычных курсов по статистике (а может и самый первый). Конечно, были и есть книги, но не было лекций в интерактивном формате.\nК тому же не все переводы книг по статистике хороши, например, перевод книги Гланца “Медико-биологическая статистика” оставляет желать лучшего. Книга “Статистика и котики”, которая хороша для старта в статистике, была опубликована позже, в 2016. Это я к тому, что такого многообразия материалов по статистике, как появилось в последние ~5 лет еще не было, и на тот момент вводный курс по основам статистики был очень актуален для сообщества.\nЯ сама посмотрела курс “Основы статистики” в 2017 году, после довольно слабого курса по статистике в университете, и для меня курс был полезен для старта, после чего продолжила изучать статистику преимущественно по книгам (а сейчас преподаю сама). В тот момент курс показался достойным, мне понравился простой язык изложения, расчет формул на игрушечных примерах, а также удобный интерактивный формат заданий и их проверки на степике.\nКурс состоит из трех блоков:\n\nВведение, выборка и генеральная совокупность, типы переменных, описательная статистика, ЦПТ, p-value.\nСравнение средних: t-test, однофакторная и многофакторная ANOVA, проблема множественных тестирований.\nКорреляция и простая и множественная линейная регрессия, отбор моделей.\n\nВ общем такой джентльменский набор тем для старта.\nРазберем подробно каждую часть, выделяя что понравилось, а также указывая на неточности и ошибки. Платформа степик не позволяет делать ссылки с таймкодами, поэтому буду прикреплять ссылки на видео и подписывать время в тексте."
  },
  {
    "objectID": "posts/review_of_statistics_course.html#первая-часть-введение",
    "href": "posts/review_of_statistics_course.html#первая-часть-введение",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Первая часть: введение",
    "text": "Первая часть: введение\nОбщее впечатление: большая часть вещей объяснена нормально, неплохой блок про статистический вывод, объяснено, чем p-value является и не является, но при этом проскальзывают неосторожные формулировки, а иногда и ошибки. Основные разобраны ниже, а также отдельно вынесены терминологические неточности (в основном что касается принять нулевую гипотезу и тп).\n\nОписательные статистики: смещенные и несмещенные оценки\nПо всему разделу описательных статистик перескакивает мысль с дисперсии генеральной совокупности на дисперсию выборки, в знаменателе формулы то \\(n\\), то \\(n-1\\), плюс не хватило объяснения, почему используются греческие или латинские буквы для обозначения дисперсии или среднего, это сбивает с толку слушателей.\nАнатолий Карпов объясняет (на 3.30), что \\(n-1\\) в знаменателе формулы дисперсии выборки связано со степенями свободы, но это не совсем так. Такое же объяснение приводится и для коэффициента корреляции, хотя в расчете коэффициента корреляции вообще степеней свободы \\(n-2\\).\nЗдесь важно прояснить две вещи. Первое: при делении на \\(n\\) у нас систематически занижается дисперсия выборки относительно дисперсии генеральной совокупности, и деление на \\(n-1\\) позволяет получить несмещенную оценку дисперсии (здесь или здесь можно посмотреть, как это происходит). Второе: при растущем объеме выборки обе формулы дают значение, которое приближается к дисперсии генеральной совокупности. То есть в курсе объяснение через степени свободы не совсем ошибка, но немного уводит в сторону.\n\n\n\n\n\n\nКомментарий\n\n\n\nПочему именно n-1 в знаменателе\n\n\n\n\n\n\n\n\nОбсуждение в чате Биостата\n\n\n\nВот начиная с этого сообщения обсудили, что в принципе это объяснение тоже имеет смысл\n\n\nКроме этого, стандартное отклонение называется в лекциях и стандартным, и среднеквадратичным отклонением. Понятно, что это одно и то же, но это не было проговорено явно, в результате слушатели курса в растерянности. Исторически в русскоязычной литературе использовался вариант “среднеквадратичное отклонение”, но сейчас чаще встречается вариант “стандартное отклонение”, мне кажется это более правильно, так как прямой перевод standard deviation.\nВот тут сказано, что между первым и третьим квартилем в боксплоте находится ровно 50% наблюдений. В принципе это часто так, но не обязательно, например, это будет неверно в случае, если в данных есть повторяющиеся значения.\n\nboxplot(c(1, 2, 2, 2, 2, 3, 3, 3))\n\n\n\n\n\n\n\n\nЗдесь в “ящике” бокса находится 7/8 значений, то есть 87.5%. Можно придумать и совсем экстремальный случай, когда в ящике бокса находятся все наблюдения и “усов” нет совсем. Конечно, это редко когда встречается, но в любом случае проявление неаккуратности формулировки, хотя и не слишком существенное.\nА вот следующий пример будет гораздо хуже ⬇️\n\n\nДоверительные интервалы, которым нельзя доверять\nВот тут было что-то совсем странное с интерпретацией доверительных интервалов (с 1.05).\nДословно текст:\n\nПотому что если у нас среднее номер 2 не попадает в доверительный интервал для среднего номер 1, и наоборот, среднее номер 1 не попадает в доверительный интервал для среднего номер 2, то такие различия у нас будут достигать уровня статистической значимости.\n\n\n\n\nСкриншот из видео\n\n\nТакая интерпретация перекрывания доверительных интервалов совсем неверная.\nЗдесь я писала про доверительные интервалы и пределы погрешностей. В двух словах: отсутствие перекрывания 95% доверительных интервалов говорит о статистически значимых различиях (p &lt; 0.05), но речь идет именно о перекрывании усов, а вовсе не о том, что доверительный интервал одной выборки не перекрывается с выборочным средним второй.\nПерекрывание усов со средним не интерпретируется в терминах статистической значимости. На картинке выше доверительные интервалы перекрываются, и это не говорит о том, что различий нет, поскольку только отсутствие перекрывания говорит о статистически значимых различиях:\n\n\n\nИнтерпретация перекрывания пределов погрешностей, доверительные интервалы — 95% CI. Ссылка на источник картинки\n\n\nНаличие перекрывания не говорит о том, что различий нет. Еще стоит отметить, что в принципе делать выводы о различиях средних на основании перекрывания/не перекрывания доверительных интервалов плохая практика.\nСчитаю это очень серьезной неточностью и даже ошибкой курса, учитывая, что в целом доверительный интервал как явление дает простор для мисинтерпретации, так еще и в курсе приведено заведомо неверное объяснение.\n\n\nБаг про центральную предельную теорему\nДмитрий Пензар достаточно подробно про это расписал, главное замечание в том, что в формулировке Карпова ЦПТ становится практически бесполезной (ссылка на лекцию).\n\nПредположим исследуемый нами признак имеет нормальное распределение в генеральной совокупности с некоторым средним и стандартным отклонением, и мы многократно извлекаем выборки равные n по объему, и в каждой выборке рассчитываем среднее значение, после чего строим распределение этих выборочных средних. Так вот, такое распределение будет являться нормальным со средним, совпадающим с этим показателем генеральной совокупности. И, что самое интересное, со стандартным отклонением, которое называется стандартная ошибка среднего, se равным sigma/корень(n).\n\nНе хватило объяснения основной сути ЦПТ.\nОсновная суть ЦПТ в том, что какой бы ни была форма распределения в генеральной совокупности, выборочное распределение средних будет стремиться к нормальному. Это применимо для признака, который обладает конечными математическим ожиданием и дисперсией.\nИллюстрация на примере логнормального распределения:\n\nlog_distr &lt;- rlnorm(10000) # создаем \"генеральную совокупность\"\nhist(log_distr, breaks = 30) # строим гистограмму\n\n\n\n\n\n\n\n\nИзвлекаем тысячу раз выборки размером 30, считаем среднее этих выборок, построим распределение.\n\nsamp_means_log &lt;- replicate(1000, mean(sample(log_distr, 30))) \nhist(samp_means_log, breaks = 30)\n\n\n\n\n\n\n\n\nРаспределение выборочных средних из логнормального распределения получилось очень похожим на нормальное распределение. Это происходит благодаря центральной предельной теореме.\nВот тут можно посмотреть еще: Шайни апп для центральной предельной теоремы, особенно эффектно выглядит на примере равномерного распределения."
  },
  {
    "objectID": "posts/review_of_statistics_course.html#вторая-часть-сравнение-средних",
    "href": "posts/review_of_statistics_course.html#вторая-часть-сравнение-средних",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Вторая часть: сравнение средних",
    "text": "Вторая часть: сравнение средних\nОбщее впечатление: самая слабая часть курса, наибольшее количество ошибок сосредоточено именно здесь. При этом лайк за объяснение однофакторного дисперсионного анализа и разбор проблематики множественного тестирования.\n\nПро тест Стьюдента без теста Велча\nЗдесь некорректно назван t-тест почему-то парным t-тестом. Видимо имелся ввиду двухвыборочный t-тест. Напоминаю, что парный или зависимый t-тест применяется к зависимым выборкам и формула расчета его другая.\nПо всему курсу t-критерий Стьюдента называется критерий t-Стьюдента.\nСтранная постановка нулевой и альтернативной гипотезы (0.20):\n\nнулевая гипотеза, будет предполагать, что на самом деле в генеральной совокупности никакого различия между этими средними значениями нет, тогда как альтернативная гипотеза &lt;…&gt; будет говорить, что на самом деле эти средние в генеральной совокупности не равны.\n\nБолее правильно будет сказать, что нулевая гипотеза — о том, что две генеральные совокупности (из которых взяты соответствующие выборки) имеют одинаковое среднее. Соответственно альтернативная — о том, что средние в генеральной совокупности не равны.\nДалее, не было сказано ничего про тест Велча (тест Стьюдента с поправкой Велча), зато сказано, что нужно обязательно равенство дисперсий при сравнении двух групп t-тестом. Для теста Стьюдента без поправки Велча это действительно так, но в целом более надежно с точки зрения ошибки первого рода использовать тест Стьюдента с поправкой Велча.\nЯ сравнивала тест Стьюдента и тест Велча, вот выдержка из материала:\n\nВ большинстве случаев оба теста контролируют ошибку первого рода и мощность на заданном уровне. Однако у теста Стьюдента есть проблема с ошибкой первого рода (ложноположительные результаты) в ситуации с неравными дисперсиями и разным размером выборок.\n\n\nЗдесь ✅ — тест показал себя хорошо, ❌ — тест показал себя плохо, 🟡 — тест показал себя не оптимально, но не слишком плохо\n\n\n\n\n\n\n\n\nтест Велча\nтест Стьюдента\n\n\n\n\nОтличий нет, равные дисперсии, равные выборки\n✅\n✅\n\n\nОтличий нет, разные дисперсии, равные выборки\n✅\n✅\n\n\nОтличий нет, разные дисперсии, разные выборки, меньшая выборка с большей дисперсией\n✅\n❌\n\n\nОтличий нет, разные дисперсии, разные выборки, бОльшая выборка с большей дисперсией\n✅\n✅\n\n\nОтличия есть, равные дисперсии, равные выборки\n✅\n✅\n\n\nОтличия есть, разные дисперсии, равные выборки\n✅\n✅\n\n\nОтличия есть, разные дисперсии, разные выборки, меньшая выборка с большей дисперсией\n🟡\n✅\n\n\nОтличия есть, разные дисперсии, разные выборки, бОльшая выборка с большей дисперсией\n✅\n🟡\n\n\n\nМожно было хотя бы упомянуть про существование теста Велча, учитывая что в большинстве статистических программ считается именно он.\nТакже сказано про нормальность распределения как обязательное требование для t-теста, но только в случае, если значений в выборке меньше 30. Почитать, почему это не так, можно по ссылке. В тексте этой статьи есть неточности, но общий посыл передан верно, ждем Матвея Славенко с подробным разбором этого статистического мифа.\n\n\nПро тест Манна-Уитни: недостаточно\nОчень мимоходом сказано про тест Манна-Уитни, не сказано ничего про формулировку нулевой гипотезы, кажется что мы сравниваем средние, только в рангах, а это не совсем так.\nЯ думаю не помешало бы уделить больше внимания тесту Манна-Уитни, так как тест очень популярен в научном сообществе, для случаев, когда нарушается требование к нормальности распределения.\n\n\n\n\n\n\nРекомендация\n\n\n\nБольшая статья про тест Манна-Уитни на хабре от Сергея Матросова и аналитиков X5 Tech.\n\n\nНе хватило рекомендаций, что делать с выбросами помимо использования непараметрических методов, так как не всегда непараметрика это единственный возможный и верный вариант.\n\n\nПро дисперсионный анализ\nЗдесь все очень даже неплохо, мне понравился расчет F-значений в дисперсионном анализе вручную и объяснение внутригрупповой и межгрупповой суммы квадратов.\nНо все-таки укажу на кое-какие огрехи: тут указано требование к нормальности данных и гомогенности дисперсий, но если наблюдений больше 50, то ANOVA устойчива к нарушению обоих предположений. Это так, но я бы уточнила, что нам важнее нормальность распределения остатков, а не исходных данных. В остальном да, при достаточном размере выборки ANOVA устойчива к нарушению нормальности, а при равенстве объемов выборок в группах к гетерогенности дисперсий.\nПро многофакторный дисперсионный анализ рассказано поверхностно, но без ошибок, понятно, что в курсе по основам статистики не изложить все, особенно по теме дисперсионного анализа. Возможно, стоило обратить внимание на то, что бывают разные способы расчета сумм квадратов в двухфакторном дисперсионном анализе, и при разных размерах выборок (= несбалансированный дизайн) это может повлиять на выводы (вот тут можно посмотреть, основная проблема изложена).\n\n\n\n\n\n\nПро разные типы сумм квадратов в ANOVA\n\n\n\nСтатья на stats.stackexchange с подробным разбором разных тип сумм квадратов и их отличием\n\n\n\n\nПро поправки на множественное тестирование\nОбщая идея проиллюстрирована очень хорошо, и мне понравилось, что были использованы симуляции сравнений групп, а не просто формула FWER.\nНо не хватило акцентов, какой метод в каком случае лучше использовать.\n\n\n\n\n\n\nNote\n\n\n\nFWER — family-wise error rate, групповая вероятность ошибки I рода.\nФормула расчета FWER для независимых тестов\n\\[\nFWER = 1 - (1-\\alpha)^k, где\n\\]\nk - количество тестов, \\(\\alpha\\) - уровень значимости.\nПри сравнении групп тесты зависимые, и по формуле мы можем оценить только верхнюю границу, максимально возможное значение FWER.\n\n\nДля дальнейшего углубления в конкретику, какую поправку использовать лучше, можно ознакомиться с моим постом с детальным разбором поправок и лекцией Матвея Славенко в литклубе биостатистики."
  },
  {
    "objectID": "posts/review_of_statistics_course.html#третья-часть-корреляция-и-регрессия",
    "href": "posts/review_of_statistics_course.html#третья-часть-корреляция-и-регрессия",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Третья часть: корреляция и регрессия",
    "text": "Третья часть: корреляция и регрессия\nОбщее впечатление: часть недостаточно подробная, хотелось бы увидеть больше деталей и материалов для дальнейшего изучения. Но серьезных ошибок не было, общая суть методов передана верно.\n\nКорреляция\nЗдесь в объяснении преимуществ корреляции Спирмена говорится, что можно нарушить линейность, это так, но при этом важно, чтобы соблюдалась монотонность связи, на это не хватает акцента.\nНе хватило методов, что можно сделать с выбросами помимо применения непараметрических тестов. В определенных ситуациях можно удалить выбросы, если они физически невозможны, также можно сделать различные преобразования, например логарифмирование. Но нужно учитывать, что может измениться интерпретация преобразованных данных.\n\n\nРегрессия\nЗдесь сказано про опасность экстраполяции, но при этом предсказанное значение лежит за пределами диапазона значений независимых переменных, что уже является экстраполяцией и не совсем корректно.\nОпечатка на слайде и в речи (1.15): в требованиях к множественной линейной регрессии указана гетероскедастичность вместо гомоскедастичности.\nПро проблему мультиколлинеарности (3.00) маловато конкретики и объяснения причин, почему мультиколлинеарность плохо.\nВ теме множественной регрессии не хватило про VIF для оценки мультиколлинеарности, про информационные критерии AIC, BIC и методы отбора лучшей модели.\n\n\n\n\n\n\nРекомендация\n\n\n\nНа тему регрессии рекомендую курс лекций Марины Варфоломеевой и Вадима Хайтова.\n\n\nСправедливости ради, в третьей части курса (Основы статистики. Часть 3) это было разобрано более подробно."
  },
  {
    "objectID": "posts/review_of_statistics_course.html#terms",
    "href": "posts/review_of_statistics_course.html#terms",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Терминологические неточности",
    "text": "Терминологические неточности\nСюда относятся многочисленные “принять альтернативную гипотезу”, “статистически достоверно” вместо статистически значимо, соберем их в одном месте:\n\nВ ответах к заданию “принимаем нулевую гипотезу”\n“Считать наши значения статистически достоверными” 0.50\n“Принимаем различия статистически достоверными” 1.26 1.45 3.24 5.04. Заметьте, тут в рамках одного видео такая формулировка встречается 4 раза, что нельзя списать на то, что автор просто оговорился.\nНа этом степе в задании “различия считаются статистически достоверными”.\nВ формулировке задания “статистически достоверными”.\n“различиям между группами признавались статистически достоверными” в тексте задания.\nпринять или отклонить нулевую гипотезу 1.20\n\nВ алгоритме статистического вывода, мы не принимаем нулевую гипотезу, а можешь лишь отклонить нулевую гипотезу или не отклонить ее (можно принять альтернативную гипотезу, но нельзя принять нулевую гипотезу).\nНекорректно говорить “достоверность” вместо статистической значимости, потому что в математике достоверное событие — то, которое происходит со 100% вероятностью. Про термин “достоверность” почитать можно дискуссию в чате, начиная с этого сообщения, и поиском по чату можно найти достаточно аргументации, почему это нельзя использовать как замену статистической значимости.\nИ еще статья на эту тему: «Достоверность» или «Статистическая значимость» 12 лет спустя, Зорин Никита Александрович."
  },
  {
    "objectID": "posts/review_of_statistics_course.html#выводы",
    "href": "posts/review_of_statistics_course.html#выводы",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Выводы",
    "text": "Выводы\nКак уже отмечала выше, курс был актуален в свое время. В настоящий момент смотреть курс “Основы статистики” скорее не рекомендую, ниже предлагаю список хороших материалов:\nДля удобства попробовала разбить на разные уровни\nJunior:\n\nКнига “Статистика и котики” Владимир Савельев\nКнига “Статистика для всех” (Statistics in a nutshell) Сара Бослаф\nАнализ данных и статистика в R Ивана Позднякова\n\nMiddle:\n\nКурс “Линейные модели, дисперсионный и регрессионный анализ с использованием R” авторством Марины Варфоломеевой и Вадима Хайтова\nКурс Data Analysis with R Specialization на курсере\nStatQuest - отличный канал с короткими, но очень четкими разборами конкретных тем по статистике.\nTileStats - тоже очень хороший канал по статистике с похожим форматом.\n\nSenior:\n\nПодборка Матвея Славенко в канале душно про дату: первое, второе\n\nПри этом всем хочу выразить Анатолию Карпову респект за популяризацию R в сообществе (по крайней мере раньше), и большую благодарность за бесплатные программы: симулятор SQL, курс по визуализации данных."
  },
  {
    "objectID": "posts/review_of_statistics_course.html#благодарности",
    "href": "posts/review_of_statistics_course.html#благодарности",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Благодарности",
    "text": "Благодарности\nМатвею Славенко за уточнение сложных моментов и помощь с корректностью формулировок, Яне, Жене и Юле за конструктивные статистические дискуссии и рекомендации по тексту, Сергею Матросову за дополнительную мотивацию все-таки дописать пост и Дмитрию Пензару за исходное развитие дискуссии и пример с ЦПТ.\nОбсудить можно в телеграм-канале Статистика и R в науке и аналитике, в комментариях к посту или здесь, авторизовавшись через GitHub."
  },
  {
    "objectID": "posts/YandexMetricsQuarto.html",
    "href": "posts/YandexMetricsQuarto.html",
    "title": "Как добавить яндекс-метрику на сайт Quarto",
    "section": "",
    "text": "Всем привет!\nВ какой-то момент мне стало интересно, как работает яндекс-метрика для веб-аналитики, и я решила попробовать это сделать на своем сайте со статьями по R.\nПошаговая инструкция:\n\nДля начала нужно создать счетчик на сайте метрики, вписать туда URL сайта, принять условия соглашения и тп.\nПоявится уникальный номер счетчика и код счетчика в JavaScript, который нужно добавить на сайт в пределах тегов &lt;head&gt;&lt;/head&gt; или &lt;body&gt;&lt;/body&gt;. Как это сделать в Quarto-сайте не было написано, но все оказалось очень просто и изящно.\nНужно сохранить вышеприведенный код счетчика в файл .js в директории проекта сайта например с названием metrics.js.\nВ файле _quarto.yml, где хранятся основные настройки сайта вписать:\nformat:\n  html:\n    include-before-body: &lt;path_to_file/metrics.js&gt;\nПроверить, что счетчик установлен на странице метрики, если все сделано правильно, то по ссылке появится всплывающее окно о том, что счетчик активен.\nАнализировать аналитику сайта.\n\n\n\n\n\n\n\nGoogle-analytics\n\n\n\nGoogle-аналитику можно было прикрепить на сайт относительно нативным образом, встроенным в Quarto."
  },
  {
    "objectID": "posts/multiple_testing.html",
    "href": "posts/multiple_testing.html",
    "title": "Поправки на множественное тестирование",
    "section": "",
    "text": "Разберем, что такое поправки на множественное тестирование, зачем они нужны, как работают основные методы, которые часто используются в науке и индустрии, а также на что опираться при выборе поправки в своем исследовании.\nНачнем разбор с классификации."
  },
  {
    "objectID": "posts/multiple_testing.html#классификация-поправок-на-множественное-тестирование",
    "href": "posts/multiple_testing.html#классификация-поправок-на-множественное-тестирование",
    "title": "Поправки на множественное тестирование",
    "section": "Классификация поправок на множественное тестирование",
    "text": "Классификация поправок на множественное тестирование\nСуществует 2 принципиально разных подхода к поправкам на множественное тестирование.\n\nКонтроль групповой вероятности ошибки I рода (FWER, family-wise error rate)\n\nТесты, которые поправляют значимость у набора p-value (поправка Бонферрони, Холма, Шидака и тд.) вне зависимости, какой тест был применен до этого;\nТесты для попарных сравнений групп: пост-хоки (поправка Тьюки, поправка Даннета, тест Фишера LSD и тд).\n\nКонтроль доли ложных открытий (FDR, false discovery rate): поправка Benjamini-Hochberg, поправка Benjamini-Yekutieli.\n\nНебольшое напоминание про типы ошибок:\n\n\n\nhttps://t.me/stats_for_science/69\n\n\nРазберем разные виды поправок подробнее."
  },
  {
    "objectID": "posts/multiple_testing.html#симуляция-независимых-тестов-для-подсчета-fwer",
    "href": "posts/multiple_testing.html#симуляция-независимых-тестов-для-подсчета-fwer",
    "title": "Поправки на множественное тестирование",
    "section": "Симуляция независимых тестов для подсчета FWER",
    "text": "Симуляция независимых тестов для подсчета FWER\nГенерируем заданное количество раз (5, 10, 50, 100) выборки размером 100 элементов из одной генеральной совокупности (стандартного нормального распределения) и сравниваем их t-тестом. Повторяем это 10000 раз, чтобы оценить долю случаев, где мы получили p-value &lt; 0.05 (ложнопозитивный результат).\nТесты независимые, поскольку каждый раз извлекаем новую выборку, следовательно, мы ожидаем увидеть результат, близкий к рассчитанному по формуле выше.\n\n\nCode\npaste('Для 5 тестов: ', mean(replicate(10000, sum(replicate(5, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05) != 0)))\n\n\n[1] \"Для 5 тестов:  0.2257\"\n\n\n\\(FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05)^5 = 0.226\\)\n\n\nCode\npaste('Для 10 тестов: ', mean(replicate(10000, sum(replicate(10, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05) != 0)))\n\n\n[1] \"Для 10 тестов:  0.4046\"\n\n\n\\(FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{10} = 0.401\\)\n\n\nCode\npaste('Для 50 тестов: ', mean(replicate(10000, sum(replicate(50, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05) != 0)))\n\n\n[1] \"Для 50 тестов:  0.925\"\n\n\n\\(FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{50} = 0.923\\)\n\n\nCode\npaste('Для 100 тестов: ', mean(replicate(10000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05) != 0)))\n\n\n[1] \"Для 100 тестов:  0.9938\"\n\n\n\\(FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{100} = 0.994\\)\nДействительно, при симуляции значения FWER сходятся с теоретически рассчитанными. Что можно сделать, чтобы избежать ошибок первого рода?"
  },
  {
    "objectID": "posts/multiple_testing.html#поправка-бонферрони-bonferroni",
    "href": "posts/multiple_testing.html#поправка-бонферрони-bonferroni",
    "title": "Поправки на множественное тестирование",
    "section": "Поправка Бонферрони (Bonferroni)",
    "text": "Поправка Бонферрони (Bonferroni)\nСамый простой способ контролировать вероятность ошибки первого рода – это изменить критический уровень значимости \\(\\alpha\\).\n\\[ FWER = 1 - (1-\\frac{\\alpha}{k})^k,  \\tag{2}\\]\nДелим \\(\\alpha\\) на число тестов -&gt; получаем новый p-уровень значимости, ниже которого результаты будут считаться статистически значимыми.\nИли умножаем каждое p-value на количество тестов, и если поправленное p-value &lt; 0.05, то результат считается статистически значимым.\nПри таком подходе мы контролируем вероятность совершить хоть одну ошибку первого рода на уровне 0.05, однако сильно завышаем вероятность ошибки второго рода (то есть не найти значимый эффект, где он на самом деле есть), следовательно, уменьшаем мощность теста.\nПроверим FWER после поправки.\n\n\nCode\npaste('Для 5 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(5, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05/5) != 0)))\n\n\n[1] \"Для 5 тестов FWER по Бонферрони:  0.0491\"\n\n\n\n\nCode\npaste('Для 10 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(10, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05/10) != 0)))\n\n\n[1] \"Для 10 тестов FWER по Бонферрони:  0.0462\"\n\n\n\n\nCode\npaste('Для 50 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(50, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05/50) != 0)))\n\n\n[1] \"Для 50 тестов FWER по Бонферрони:  0.0476\"\n\n\n\n\nCode\npaste('Для 100 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05/100) != 0)))\n\n\n[1] \"Для 100 тестов FWER по Бонферрони:  0.0484\"\n\n\nДа, мы контролируем FWER на заданном уровне 0.05.\nПоправка Бонферрони используется редко, в основном в областях, где цена ошибок первого рода (ложнопозитивного результата) очень высока, например в исследованиях GWAS на человеке. В остальных случаях рекомендуют использовать менее консервативные поправки."
  },
  {
    "objectID": "posts/multiple_testing.html#поправка-холма-holm",
    "href": "posts/multiple_testing.html#поправка-холма-holm",
    "title": "Поправки на множественное тестирование",
    "section": "Поправка Холма (Holm)",
    "text": "Поправка Холма (Holm)\nМенее консервативная поправка. Метод часто называют “Бонферрони-Холма”, однако Карло Бонферрони не имел отношения к разработке этой формулы. Разберем на примере как работает.\n\np_value &lt;- c(0.004, 0.87, 0.003, 0.04, 0.18, 0.24)\n\nСортируем и ранжируем p-value по возрастанию, далее по формуле умножаем каждое p-value на \\((m+1-rank)\\), где \\(m\\) - количество тестов, \\(rank\\) - ранг p-value.\n\n\n\n\n\npvalue\nrank_pvalue\nformula\nresult\n\n\n\n\n0.003\n1\n0.003*(6 + 1 - 1)\n0.018\n\n\n0.004\n2\n0.004*(6 + 1 - 2)\n0.020\n\n\n0.040\n3\n0.04*(6 + 1 - 3)\n0.160\n\n\n0.180\n4\n0.18*(6 + 1 - 4)\n0.540\n\n\n0.240\n5\n0.24*(6 + 1 - 5)\n0.480\n\n\n0.870\n6\n0.87*(6 + 1 - 6)\n0.870\n\n\n\n\n\nДалее нужно задать, что поправленные p-value могут только возрастать, и при этом p-value заменяется на бОльшее, поэтому процедура поправки Холма называется пошаговой нисходящей – step-down.\n\n\n\n\n\npvalue\nrank_pvalue\nformula\nresult\np_adjusted\n\n\n\n\n0.003\n1\n0.003*(6 + 1 - 1)\n0.018\n0.018\n\n\n0.004\n2\n0.004*(6 + 1 - 2)\n0.020\n0.020\n\n\n0.040\n3\n0.04*(6 + 1 - 3)\n0.160\n0.160\n\n\n0.180\n4\n0.18*(6 + 1 - 4)\n0.540\n0.540\n\n\n0.240\n5\n0.24*(6 + 1 - 5)\n0.480\n0.540\n\n\n0.870\n6\n0.87*(6 + 1 - 6)\n0.870\n0.870\n\n\n\n\n\nМожем убедиться, что у нас подсчитано все верно:\n\np.adjust(sort(p_value), method = 'holm')\n\n[1] 0.018 0.020 0.160 0.540 0.540 0.870\n\n\nПоскольку для самого минимального p-value поправленное p-value такое же как и в Бонферрони, то поправка Холма контролирует FWER на том же уровне 0.05, что и поправка Бонферрони, при этом не так сильно снижает мощность тестов.\nПроверим на 100 тестах:\n\nreplicate(1000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) %&gt;% \n  p.adjust(method = 'holm') &lt; 0.05) != 0) %&gt;%\n  mean()\n\n[1] 0.059\n\n\nТаким образом, мы все еще контролируем вероятность совершить хоть одну ошибку первого рода на уровне 0.05, и оставляем больше значимых результатов, по сравнению с поправкой Бонферрони. Поэтому во многих случаях рекомендуют использовать именно поправку Холма для множественных сравнений.\n\n\n\n\n\n\nСсылка на оригинальную статью:\n\n\n\nHolm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6, 65–70. https://www.jstor.org/stable/4615733.\n\n\nТеперь перейдем к поправкам, которые используются в конкретных тестах."
  },
  {
    "objectID": "posts/multiple_testing.html#тест-фишера-lsd-least-significant-difference",
    "href": "posts/multiple_testing.html#тест-фишера-lsd-least-significant-difference",
    "title": "Поправки на множественное тестирование",
    "section": "Тест Фишера LSD (Least significant difference)",
    "text": "Тест Фишера LSD (Least significant difference)\nИспользуется как постхок тест только после значимой ANOVA для сравнения средних групп между собой (напоминаю, что ANOVA, дисперсионный анализ дает ответ на вопрос, есть ли хоть какое-то различие между группами, но не говорит между какими). Также тест можно применять только для сравнения трех групп.\nФормула вычисления критерия:\n\\[\nt = \\frac{\\overline{X_1}-\\overline{X2}}{\\sqrt{MSE(\\frac{1}{n_1}+\\frac{1}{n_2})}}, где\n\\]\n\\(\\overline{X_1}\\), \\(\\overline{X_2}\\) – средние групп 1 и 2, \\(n_1\\), \\(n_2\\) – размер групп 1 и 2, \\(MSE\\) – mean square error из таблицы ANOVA, то есть общая дисперсия между всеми группами.\nДля трех групп имеет большую мощность чем Тьюки. Но если групп больше чем 3, то контролирует FWER на уровне больше 0.05 и следовательно к использованию не рекомендуется.\nПодробнее, почему это так, можно посмотреть здесь."
  },
  {
    "objectID": "posts/multiple_testing.html#поправка-тьюки-tukey-tukeyhsd",
    "href": "posts/multiple_testing.html#поправка-тьюки-tukey-tukeyhsd",
    "title": "Поправки на множественное тестирование",
    "section": "Поправка Тьюки (Tukey, TukeyHSD)",
    "text": "Поправка Тьюки (Tukey, TukeyHSD)\nИспользуется как постхок тест вне зависимости от значимости ANOVA (подробнее ниже) для сравнения средних групп между собой, чтобы узнать какие именно группы различаются. Также нет ограничения на количество групп, участвующих в сравнении.\nВ этом тесте сравнивается каждая группа с каждой, поэтому у него будет минимальная мощность, так как тестов больше всего. Если нам не нужно сравнивать каждую группу с каждой, то лучше использовать тест Даннета, который сравнивает одну группу с остальными и имеет более высокую мощность.\nФормула расчета тестовой статистики:\n\\[ q_s = \\frac{M_1 - M_2}{\\sqrt{\\frac{SS_w}{2}(\\frac{1}{n_A}+\\frac{1}{n_B})}},  \\]\nгде M1 &gt; M2 (средние в группе), nA, nB - размер 1 и 2 выборки, \\(SS_W\\) - внутригрупповая сумма квадратов в ANOVA.\nДля проверки гипотезы используется studentized range distribution, студентизированное распределение (не путать с t-распределением).\nУ теста Тьюки есть допущения к использованию:\n\nНезависимость наблюдений\nПримерное равенство дисперсий\nПримерно нормальное распределение данных в группах\n\nЕсли допущения про нормальность распределения и равенство дисперсий не выполняются, то можно использовать непараметрические аналоги теста.\n\n\n\n\n\n\nПро значимую ANOVA\n\n\n\nТест Тьюки вовсе необязательно использовать только после значимой ановы, как нередко пишут в учебниках, просто в тесте при расчете используется внутригрупповая сумма квадратов и количество степеней свободы из таблицы ANOVA. Поэтому в докомпьютерное время расчет критерия Тьюки был проще после дисперсионного анализа, и при незначимой анове сравнивать группы между собой уже не имело смысла. Сейчас в R в функции TukeyHSD() для расчета критерия Тьюки в качестве инпута используется результат ановы, но никто не запрещает применять тест и если анова оказалась незначимой.\nТакже может быть и ситуация, когда по результатам ANOVA получилось, что средние групп различаются между собой, но при этом по Тьюки нет, можно почитать здесь, почему так бывает."
  },
  {
    "objectID": "posts/multiple_testing.html#тест-данна-dunn",
    "href": "posts/multiple_testing.html#тест-данна-dunn",
    "title": "Поправки на множественное тестирование",
    "section": "Тест Данна (Dunn)",
    "text": "Тест Данна (Dunn)\nЯвляется непараметрическим постхок тестом, аналогом теста Тьюки, для ситуаций, когда его допущения не выполняются.\nПо сути сравнивает средний ранг групп, вычисленных после теста Краскелла-Уоллиса (Kruskal-Wallis), таким образом как бы учитывая общую дисперсию между группами (чего не будет происходить в попарных тестах Манна-Уитни). Далее полученные p-value должны быть поправлены любым методом, например Бонферрони, Холм, FDR.\nЛично мне это в свое время сломало мозг, что это поправка в поправке, вроде используем постхок тест, но при этом его результат тоже нужно поправить тестом на выбор (в функции dunn_test() из пакета rstatix поправка Холма происходит автоматически).\nКак альтернатива, в качестве непараметрического аналога Тьюки можно использовать попарные тесты Манна-Уитни с поправками, однако ранги будут рассчитаны отдельно для каждого теста.\nОригинальная статья про метод:\nDunn, O. J. (1964) Multiple comparisons using rank sums Technometrics, 6(3):241-252."
  },
  {
    "objectID": "posts/multiple_testing.html#тест-даннета-dunnet",
    "href": "posts/multiple_testing.html#тест-даннета-dunnet",
    "title": "Поправки на множественное тестирование",
    "section": "Тест Даннета (Dunnet)",
    "text": "Тест Даннета (Dunnet)\nС помощью этого теста сравнивают одну группу с остальными группами, например, когда задача сравнить контрольную группу и несколько воздействий, и не нужно сравнение каждой группы с каждой\nНапример, у нас 4 группы, из которой одна группа контрольная, с которой мы проводим сравнения. У нас будет всего 3 сравнения: control - A, control - B, control - C, что увеличивает мощность теста.\nДля теста Даннета должны соблюдаться такие же допущения, как и для теста Тьюки: независимость наблюдений, примерно равная дисперсия в группах и нормальное распределение.\nПосмотреть детально можно здесь.\nТеперь перейдем к принципиально другому подходу поправок – контроле доли ложных открытий (FDR)."
  },
  {
    "objectID": "posts/multiple_testing.html#определение-fdr",
    "href": "posts/multiple_testing.html#определение-fdr",
    "title": "Поправки на множественное тестирование",
    "section": "Определение FDR",
    "text": "Определение FDR\nFDR, false discovery rate – доля ложнопозитивных результатов.\nВ скрининговых экспериментах, таких как анализ RNA-seq данных важнее контролировать долю ложнопозитивных результатов (FDR), чем вероятность совершить хоть одно ложное открытие.\n\n\n\n\n\n\n\n\n\nH0 верна (различий нет)\nH0 неверна (различие есть)\n\n\n\n\nНе отклонить H0\nTrue Negative (TN)\nFalse Negative (FN)\n\n\nОтклонить H0\nFalse Positive (FP)\nTrue Positive (TP)\n\n\n\n\\[ FDR = \\frac{FP}{FP + TP} \\]\nПодробнее в этом видео."
  },
  {
    "objectID": "posts/multiple_testing.html#расчет-fdr",
    "href": "posts/multiple_testing.html#расчет-fdr",
    "title": "Поправки на множественное тестирование",
    "section": "Расчет FDR",
    "text": "Расчет FDR\nРасмотрим контроль FDR по методу Бенджамини-Хохберга (Benjamini-Hochberg), так как он используется чаще всего. Также FDR можно посчитать с помощью метода Benjamini-Yekutieli, но он имеет меньшую мощность и используется реже.\n\np_values &lt;- c(0.361, 0.387, 0.005, 0.009, 0.022, 0.051, 0.101, 0.019)\n\n\nСортируем и ранжируем p-value по возрастанию;\nКаждое p-value умножаем на \\(\\frac{m}{rank}\\), где \\(m\\) – количество тестов, \\(rank\\) – ранг p-value.\n\n\n\n\n\n\npvalue\nrank_pvalue\nformula\nresult\n\n\n\n\n0.005\n1\n0.005*(8/1)\n0.0400000\n\n\n0.009\n2\n0.009*(8/2)\n0.0360000\n\n\n0.019\n3\n0.019*(8/3)\n0.0506667\n\n\n0.022\n4\n0.022*(8/4)\n0.0440000\n\n\n0.051\n5\n0.051*(8/5)\n0.0816000\n\n\n0.101\n6\n0.101*(8/6)\n0.1346667\n\n\n0.361\n7\n0.361*(8/7)\n0.4125714\n\n\n0.387\n8\n0.387*(8/8)\n0.3870000\n\n\n\n\n\nИтоговое FDR вычисляется так, чтобы p-value не убывали, но при этом приводится в меньшую сторону (в отличие от поправки Холма), поэтому процедура называется пошаговой восходящей – step-up.\n\n\n\n\n\npvalue\nrank_pvalue\nformula\nresult\np_adjusted\nreject_H0\n\n\n\n\n0.005\n1\n0.005*(8/1)\n0.0400000\n0.0360000\nyes\n\n\n0.009\n2\n0.009*(8/2)\n0.0360000\n0.0360000\nyes\n\n\n0.019\n3\n0.019*(8/3)\n0.0506667\n0.0440000\nyes\n\n\n0.022\n4\n0.022*(8/4)\n0.0440000\n0.0440000\nyes\n\n\n0.051\n5\n0.051*(8/5)\n0.0816000\n0.0816000\nno\n\n\n0.101\n6\n0.101*(8/6)\n0.1346667\n0.1346667\nno\n\n\n0.361\n7\n0.361*(8/7)\n0.4125714\n0.3870000\nno\n\n\n0.387\n8\n0.387*(8/8)\n0.3870000\n0.3870000\nno\n\n\n\n\n\nFDR в основном используется в скрининговых экспериментах, где ключевые результаты могут быть проверены уже более прицельным экспериментом (например некоторые дифференциально экспрессирующиеся гены по результатам RNA-seq проверяют количественной ПЦР)."
  },
  {
    "objectID": "posts/contest_samokat.html#продуктовые-вопросы",
    "href": "posts/contest_samokat.html#продуктовые-вопросы",
    "title": "Решение контеста самокат",
    "section": "Продуктовые вопросы",
    "text": "Продуктовые вопросы\n\nКак определить, какой продавец мошенник, а какой — нет? Какие ещё могут быть схемы мошенничества?\nМы можем предположить, что продавец мошенник по следующим признакам:\n\nНереалистично низкая цена на товар (например, скидка больше 30% относительно рыночной цены товаров или больше 2 сигм относительно таких же товаров от других продавцов).\nАккаунт продавца недавно создан, с большим количеством дорогих товаров (особенно в сочетании с первым пунктом о слишком большой скидке на них).\nНедостаточно много отзывов о продавце (но это будет у любого недавно зарегистрировавшегося продавца).\nЕсли зафиксированы попытки продавца общаться с покупателем вне площадки (можно установить при анализе общения во внутреннем мессенджере платформы).\nИспользование данных ИНН, которые уже использовались на площадке.\nНетипичное поведение после регистрации, аномальная динамика роста количества заказов\n\nВесьма вероятно, что модель машинного обучения будет обучена на этих и других признаках для определения мошенников.\nДругие возможные схемы мошенничества:\n\nПродажа поддельных товаров известных брендов.\nРегистрация нескольких пользовательских аккаунтов мошенника, где происходит накрутка истории заказов и повышение рейтинга мошенника.\nФишинговые ссылки, где покупатель переходит на подставной сайт и у него воруют личные данные и данные банковских карт.\n“Схема с предоплатой”. Мошенник требует предоплату за товар и после ее получения пропадает, товар оказывается не выслан, и мошенник был зарегистрирован не под своим именем (данные продавца украдены из слитых баз).\nФишинговые электронные письма с “выгодными” предложениями, которые маскируются под настоящие письма от маркетплейса, но ведут не на тот сайт, который будет красть данные банковских карт.\n\nДля борьбы с мошенниками можно использовать как автоматические системы (ML модели), так и ручной контроль (модерацию объявлений, проверку продавцов и товаров).\n\n\nКакие продуктовые фичи могут помочь нашим клиентам избежать неприятных ситуаций с мошенничеством?\n\nСистема рейтинга и отзывов: Позволяет покупателям делиться своим опытом и оценивать продавцов. При этом, должна быть возможность проверки и модерации отзывов, чтобы предотвратить их фальсификацию.\nТщательная проверка продавцов. Например, при активации продавца требовать скан паспорт и селфи с паспортом с листом, где написана текущая дата и сервис, чтобы подтвердить личность продавца. Такая система верификации реализована в LightDoc. В итоге, если продавец оказался мошенником, то есть его документы и фотография, а селфи с указанием текущей даты защищает от использования слитых баз данных с паспортными данными.\nБезопасная сделка со стороны маркетплейса. Покупатель переводит деньги на специальный счет маркетплейса, и они перечисляются продавцу только после того, как покупатель подтвердил получение товара (как в p2p криптовалютных биржах).\nЧат на платформе: Все общение между продавцом и покупателем происходит внутри платформы. Это позволяет контролировать переписку и предотвратить попытки мошенничества. Например, так реализовано в Avito.\nАвтоматический анализ объявлений: Использование AI для анализа объявлений и выявления подозрительных. Например, если цена товара сильно отличается от среднерыночной (больше чем на 2 сигмы), объявление может быть автоматически помечено как подозрительное.\nВозможность жалобы на продавца: Покупатели должны иметь возможность быстро и легко отправить жалобу на продавца, если они считают, что стали жертвами мошенничества.\nИнформационная поддержка: Разъяснение клиентам о типичных схемах мошенничества и о том, как себя вести в таких ситуациях.\nСкрытие контактных данных покупателя.\n\n\n\nЧерез какую механику мошенник узнает контакты покупателя? Что можем сделать, чтобы усложнить жизнь фродерам?\nНа большинстве площадок контактные данные покупателя становятся доступны продавцу после оформления заказа. Мошенник может также попытаться узнать контакты покупателя, предлагая ему общаться вне платформы, например, через личные сообщения, электронную почту или телефон.\nЧтобы усложнить жизнь фродерам, можно предпринять следующие шаги:\n\nСкрыть контактные данные покупателя и использовать алгоритм подмены номера с переадресацией. Таким образом, фродер не сможет написать напрямую в мессенджер whatsapp или telegram. При звонках будет озвучиваться предупреждение, что это звонок от маркетплейса.\nРекомендовать покупателям и продавцам использовать только внутреннюю систему сообщений. Это поможет защитить личные данные пользователей, и позволит модераторам отслеживать возможные попытки мошенничества.\nПредупреждение пользователей: Информировать пользователей о рисках, связанных с предоставлением своих контактных данных третьим лицам.\nБлокировка ссылок и контактов в сообщениях: В сообщениях между продавцом и покупателем можно запретить отправку ссылок и контактных данных.\nВерификация продавцов: Проверять продавцов при регистрации, требуя подтверждения их личности и банковских реквизитов.\n“Безопасная сделка”: Внедрение системы, при которой деньги переводятся продавцу только после подтверждения получения товара покупателем.\nИспользование алгоритмов машинного обучения для выявления подозрительной активности: Это может включать в себя анализ поведения пользователей и продавцов, анализ текста сообщений и так далее.\nБыстрая блокировка и удаление аккаунтов, замеченных в мошенничестве.\nПостоянное обновление и улучшение системы безопасности, регулярный мониторинг и анализ активности на платформе."
  },
  {
    "objectID": "posts/contest_samokat.html#дизайн-ab-тестов",
    "href": "posts/contest_samokat.html#дизайн-ab-тестов",
    "title": "Решение контеста самокат",
    "section": "Дизайн A/B тестов",
    "text": "Дизайн A/B тестов\n\nОпределите основную метрику (дополнительные метрики) и принцип разделения на группы\nИз чата ответ на вопрос:\nЦель - поймать всех фродеров на этапе онбординга\n\nЕсли правильно понял вопрос, то количество регистраций останется такое же, мы надеемся, что упадет количество активированных фродеров\nДалее терминологически группа с ML-моделью будет называться экспериментальная или B-группа, с ручным определением – контрольная (A-группа).\n\nОпределение метрик\nОсновные (core) метрики:\n\nДоля активированных фродеров. Ожидаем, что эта доля будет статистически значимо ниже в группе с ML-моделью по сравнению с ручным определением.\n\nДополнительные прокси метрики:\n\nКоличество жалоб от покупателей на мошенничество: ожидаем, что эта метрика как минимум не должна расти в экспериментальной группе, а лучше если снизится.\nСреднее время выявления мошенника: ожидаем, что оно снизится в группе с применением модели (и не увеличится).\n\nДополнительные warning метрики:\n\nДоля жалоб обычных мерчантов, которых незаслуженно заблокировали. Ожидаем, что эта метрика не начнет расти.\nСреднее время продавца на прохождение активации: не должно увеличиться в экспериментальной группе.\nКоличество возвратов средств: не должно быть выше в экспериментальной группе\n\n\n\nПринцип разделения на группы\nУ нас неравномерно распределение мерчантов по типу бизнеса: 25200 наблюдений с типом IE (индивидуальный предприниматель) и 9800 с типом LLC (общество с ограниченной ответственностью). Кроме этого, распределение доли выявленных мошенников тоже неравномерно:\n\n\n\n\n\n\n0\n1\n\n\n\n\nIE\n22330\n2374\n\n\nLLC\n9142\n454\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЕсли посчитать тест хи-квадрат, чтобы сравнить пропорции фродеров в разных типах бизнеса, то окажется, что они статистически значимо различаются, p-value порядка 4.51e-49, следовательно при сплитовании групп для A/B теста нам критически важно сбалансировать долю типов бизнеса.\nСделать это можно следующим образом: сначала рассчитать пропорцию продавцов каждого вида бизнеса\n\nДля IE: 25200 / (25200 + 9800) = 0.72 (72% всех продавцов)\nДля LLC: 9800 / (25200 + 9800) = 0.28 (28% всех продавцов)\n\nДалее после расчета необходимого количества продавцов рассчитаем деление на группы.\n\n\n\nРассчитайте, какой эффект можно статистически значимо отследить. Укажите его\nЗафиксируем значение \\(\\alpha = 0.05\\) для уровня значимости и \\(\\beta = 0.8%\\) для уровня мощности.\nОбратимся к историческим данным, которые у нас есть.\nНа данный момент по этим данным доля фродеров среди активированных пользователей:\n1611 / (18290 + 1611) = 0.0809 ~ 8%\nМы считаем для бизнеса значимым изменением, если удастся уменьшить долю до 6%. Следовательно, MDE = 8% - 6% = 2% = 0.02\nРассчитаем по формуле для z-теста необходимый размер выборки:\n\\[\nN = \\frac{2\\sigma^2(z\\frac{1-\\alpha}{2} + z_{1-\\beta})^2}{d_{min}^2}\n\\]\n\\[\nN = \\frac{2p(1-p)(z_{0.975} + z_{0.80})^2}{d_{min}^2} = \\frac{(2*0.08*0.92)*(1.96+0.84)^2}{0.02^2} = 2876\n\\]\nРазмер выборки получился 2876 человек с округлением, теперь необходимо рассчитать количество недель, в течение которых мы будем проводить A/B тест. Для этого будет опираться на известные данные.\n\n\nРасчет необходимого количества недель проведения теста\nСначала необходимо исключить из данных продавцов, где registration_date = 1970-01-01. Скорее всего, это продавцы, которые зарегистировались до рассматриваемого в датасете периода, либо некорректные данные. Для расчета среднего количества регистраций в неделю такие наблюдения исключаем.\nСначала визуализируем полученные результаты, чтобы оценить сезонность в данных:\n\n\n\n\n\n\n\n\n\nЗначительной сезонности в течение года не наблюдается, можно рассчитать среднее. Среднее количество регистраций продавцов в неделю получилось ~670. Чтобы набрать 2876 продавцов, нам нужно проводить тест 4.29 недели, с округлением до целого: 5 недель составит длительность проведения A/B теста.\nС учетом неравномерности продавцов по типу бизнеса нужно сделать следующее сплитование:\n\nКоличество IE: 2876*0.72 = 2070 продавец\nКоличество LLC: 2876*0.28 = 806 продавец\n\nДалее делим пополам: в контрольной и тестовой группе по 1035 продавцов типа IE, и 806 продавцов типа LLC.\nОднако, поскольку эксперимент идет в течение недель, то нам нужно: когда будут приходить новые продавцы регистрироваться, назначать им случайным образом в контрольную или тестовую группу они попадут с приблизительным соблюдением пропорций 72% и 28%. Сделать это можно с помощью функций в python с обязательным сохранением сида случайности, чтобы иметь возможность воспроизвести разделение на группы. Далее, после того как сплитование проведено, нужно убедиться что нужные пропорции сохранились и доля родавцов IE и LLC в контрольной и тестовой группах остались примерно равными.\n​"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Статистика и R в науке и аналитике",
    "section": "",
    "text": "Здесь будут размещаться статьи по статистике и R с телеграм-канала “Статистика и R в науке и аналитике”.\nСайт написан на R с использованием Quarto.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРазбор курса ‘Основы статистики’\n\n\n\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nFeb 14, 2025\n\n\nElena U\n\n\n\n\n\n\n\n\n\n\n\n\nТест Стьюдента и тест Велча\n\n\n\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nNov 24, 2024\n\n\nElena U\n\n\n\n\n\n\n\n\n\n\n\n\nРешение контеста самокат\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\nMay 29, 2024\n\n\nElena U\n\n\n\n\n\n\n\n\n\n\n\n\nКак добавить яндекс-метрику на сайт Quarto\n\n\n\n\n\n\nanalytics\n\n\n\n\n\n\n\n\n\nApr 16, 2024\n\n\nElena U\n\n\n\n\n\n\n\n\n\n\n\n\nПоправки на множественное тестирование\n\n\n\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nNov 29, 2023\n\n\nElena U\n\n\n\n\n\n\n\n\n\n\n\n\nКак задать хороший вопрос в R чате?\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nDec 2, 2022\n\n\nElena U\n\n\n\n\n\n\n\n\n\n\n\n\nВиды пределов погрешностей\n\n\n\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\nElena U\n\n\n\n\n\n\n\n\n\n\n\n\nИнструкция по установке R и RStudio\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\nOct 30, 2022\n\n\nElena U\n\n\n\n\n\n\n\n\n\n\n\n\nAnscombe’s quartet\n\n\n\n\n\n\nstatistics\n\n\n\n\n\n\n\n\n\nOct 19, 2022\n\n\nElena U\n\n\n\n\n\n\nNo matching items"
  }
]