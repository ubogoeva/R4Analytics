[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Об авторе блога",
    "section": "",
    "text": "Меня зовут Елена Убогоева. Я биоинформатик, R-энтузиаст, а в настоящий момент работаю дата-аналитиком. Веду телеграм-канал, посвященный R и статистике, преподаю на курсах Blastim: “Статистика, R и анализ данных” и “Анализ данных RNA-seq”.\nЭтот блог создан с помощью Quarto и будет содержать материалы и статьи, которые были ранее написаны в телеграм-канале."
  },
  {
    "objectID": "about.html#образование",
    "href": "about.html#образование",
    "title": "Об авторе блога",
    "section": "Образование",
    "text": "Образование\nИнститут цитологии и генетики СО РАН | Новосибирск\nАспирантура по направлению биоинформатики и системной биологии | 2020 - настоящее время\nНовосибирский государственный университет | Новосибирск\nМагистратура по направлению цитологии и генетики | 2018 - 2020\nНовосибирский государственный университет | Новосибирск\nБакалавриат по направлению цитологии и генетики | 2014 - 2018"
  },
  {
    "objectID": "about.html#список-публикаций",
    "href": "about.html#список-публикаций",
    "title": "Об авторе блога",
    "section": "Список публикаций:",
    "text": "Список публикаций:\n\nLavrekha, V. V., Levitsky, V. G., Tsukanov, A. V., Bogomolov, A. G., Grigorovich, D. A., Omelyanchuk, N., Ubogoeva, E. V., Zemlyanskaya, E. V., Mironova, V. (2022). CisCross: A gene list enrichment analysis to predict upstream regulators in Arabidopsis thaliana. Frontiers in plant science, 13, 942710. https://doi.org/10.3389/fpls.2022.942710\nUbogoeva, E. V., Zemlyanskaya, E. V., Xu, J., Mironova, V. (2021). Mechanisms of stress response in the root stem cell niche. Journal of experimental botany, 72(19), 6746–6754. https://doi.org/10.1093/jxb/erab274\nZemlyanskaya, E. V., Omelyanchuk, N. A., Ubogoeva, E. V., Mironova, V. V. (2018). Deciphering Auxin-Ethylene Crosstalk at a Systems Level. International journal of molecular sciences, 19(12), 4060. https://doi.org/10.3390/ijms19124060"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Статистика и R в науке и аналитике",
    "section": "",
    "text": "Здесь будут размещаться статьи по статистике и R, ссылки на которые раньше размещались в телеграм-канале “Статистика и R”.\nСайт написан на R с использованием Quarto.\n\n\n\n\n\n\n\n\n  \n\n\n\n\nЯзык программирования R для анализа данных: лекция 6\n\n\nВведение в статистику вывода\n\n\n\n\n\n\n\n\n\nElena U\n\n\n\n\n\n\n  \n\n\n\n\nРазбор курса ‘Основы статистики’\n\n\n\n\n\n\n\n\n\n\n\n\nElena U\n\n\n\n\n\n\n  \n\n\n\n\nПоправки на множественное тестирование\n\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2023\n\n\nElena U\n\n\n\n\n\n\n  \n\n\n\n\nВиды пределов погрешностей\n\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\nElena U\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#рекомендуемая-литература",
    "href": "posts/lectures/statR_lecture6.html#рекомендуемая-литература",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Рекомендуемая литература",
    "text": "Рекомендуемая литература\n\nКниги:\n\n“Статистика для всех” Сара Бослаф (Statistics in a Nutshell)\n“Статистика и котики” Владимир Савельев\n“Анализ данных и статистика в R” Иван Поздняков\n\nКурсы\n\nВведение в статистику (Части 1, 2, 3) на платформе Stepik\nСтатистика, R и анализ данных от Бластима\nIntroduction to Probability and Data with R на платформе Coursera\n\n\n\n\n\n\n\n\nNote\n\n\nБольше источников здесь"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#план-лекции",
    "href": "posts/lectures/statR_lecture6.html#план-лекции",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "План лекции",
    "text": "План лекции\n\nТипы переменных и типы шкал\nПонятие генеральной совокупности и выборки\nОписательные статистики\nСтатистика вывода\nТест Стьюдента, ограничения, особенности"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#данные-для-работы",
    "href": "posts/lectures/statR_lecture6.html#данные-для-работы",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Данные для работы",
    "text": "Данные для работы\n\nlibrary(tidyverse)\nwc3_units &lt;- read_tsv('https://raw.githubusercontent.com/ubogoeva/tidyverse_tutorial/master/data/wc3_heroes.txt',\n                      col_names = TRUE, \n                      na = '-', \n                      name_repair = 'minimal') %&gt;% \n  janitor::clean_names() # для правильных названий колонок"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#предмет-статистики",
    "href": "posts/lectures/statR_lecture6.html#предмет-статистики",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Предмет статистики",
    "text": "Предмет статистики\nВообще, статистика делится на два блока:\n\nОписательная статистика (descriptive statistics)\nОписываем имеющиеся у нас данные с помощью статистик, например среднее, медиана, дисперсия, стандартное отклонение и тп.\nСтатистика вывода (inferential statistics)\nПытаемся сделать вывод о всей генеральной совокупности данных. Например, стандартная ошибка, доверительный интервал и различные тестовые статистики - t-статистика, F-статистика, \\(\\chi^2\\)-статистика."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#параметры-и-статистики",
    "href": "posts/lectures/statR_lecture6.html#параметры-и-статистики",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Параметры и статистики",
    "text": "Параметры и статистики\nPopulation - генеральная совокупность.\nSample - выборка.\n\n\n\n\n\n\n\nPopulation\nParameter (обозначают греческими буквами: \\(\\mu\\), \\(\\sigma\\).\n\n\nSample\nStatistics (обозначают например \\(\\overline{x}\\), \\(sd\\))\n\n\n\nНапример, у стандартного нормального распределения среднее \\(\\mu\\) 0 и стандартное отклонение \\(\\sigma\\) 1, и эти значения являются параметрами, поскольку описывают теоретическое распределение (генеральную совокупность).\nНапример, в датасете iris среднее Sepal.Length равно 5.84, а стандартное отклонение 0.828, и эти значения являются статистиками (описывают выборку).\n\nmean(iris$Sepal.Length) \n\n[1] 5.843333\n\nsd(iris$Sepal.Length)\n\n[1] 0.8280661"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#типы-переменных-и-типы-шкал",
    "href": "posts/lectures/statR_lecture6.html#типы-переменных-и-типы-шкал",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Типы переменных и типы шкал",
    "text": "Типы переменных и типы шкал\n\n\nКоличественные\n\nНепрерывные (рост, вес, длина корня)\nДискретные (количество детей в семье)\nИнтервальные (температура в градусах Цельсия)\nРанговые (места в соревнованиях, тяжесть болезни)\n\nКачественные (категориальные, номинативные)\n\nБинарные (есть мутация или нет)"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#классификации-типов-переменных",
    "href": "posts/lectures/statR_lecture6.html#классификации-типов-переменных",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Классификации типов переменных",
    "text": "Классификации типов переменных\nПо дизайну эксперимента\n\nНезависимые переменные - то, влияние чего мы хотим изучить (генотип, обработка, наличие/отсутствие мутации, есть болезнь или нет). Выбирается экспериментатором.\nЗависимые переменные - то, что мы измеряем в исследовании (рост, вес, экспрессия генов).\n\nВажно для проведения статистических тестов, записи формулы линейной модели.\nНапример:\n\nlm1 &lt;- lm(YIELD ~ genotype, data = df)\n\nYEILD – зависимая переменная, genotype – независимая."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#что-такое-генеральная-совокупность",
    "href": "posts/lectures/statR_lecture6.html#что-такое-генеральная-совокупность",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Что такое генеральная совокупность?",
    "text": "Что такое генеральная совокупность?\n\n\nГенеральная совокупность — совокупность всех объектов (единиц), относительно которых предполагается делать выводы при изучении конкретной задачи.\nГенеральная совокупность состоит из всех объектов, которые имеют качества, свойства, интересующие исследователя.\nНапример: все клетки определенной клеточной линии, все растения определенного генотипа."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#что-такое-выборка",
    "href": "posts/lectures/statR_lecture6.html#что-такое-выборка",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Что такое выборка?",
    "text": "Что такое выборка?\n\nВыборка — часть генеральной совокупности элементов, доступная для исследования."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#классификация-выборки",
    "href": "posts/lectures/statR_lecture6.html#классификация-выборки",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Классификация выборки",
    "text": "Классификация выборки\n\nПо принципу отбора:\n\nНезависимые\nЗависимые (например до и после применения лекарства)\n\nПо корректности отбора:\n\nРепрезентативные\nНерепрезентативные\n\nОсновные стратегии отбора:\n\nПростая случайная выборка\nСтратифицированная"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#как-можно-описать-значения-в-выборке",
    "href": "posts/lectures/statR_lecture6.html#как-можно-описать-значения-в-выборке",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Как можно описать значения в выборке?",
    "text": "Как можно описать значения в выборке?\nОписательные статистики:\n\nМеры центральной тенденции\nМеры изменчивости"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#меры-центральной-тенденции",
    "href": "posts/lectures/statR_lecture6.html#меры-центральной-тенденции",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Меры центральной тенденции",
    "text": "Меры центральной тенденции\n\nСреднее - среднее арифметическое всех значений.\nМедиана - середина упорядоченного ряда значений.\nМода - наиболее часто встречающееся значение в выборке.\n\n\nmean(wc3_units$gold) # среднее \n\n[1] NA\n\nmean(wc3_units$gold, na.rm = TRUE) # среднее без учета пропущенных значений \n\n[1] 195.625\n\nmedian(wc3_units$gold, na.rm = TRUE) # медиана\n\n[1] 190\n\n\nДля вычисления моды можно использовать функцию dplyr::count()"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#вычисление-моды-dplyrcount",
    "href": "posts/lectures/statR_lecture6.html#вычисление-моды-dplyrcount",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Вычисление моды: dplyr::count()",
    "text": "Вычисление моды: dplyr::count()\n\n\nwc3_units %&gt;% \n  count(armor_type)\n\n\n# A tibble: 6 × 2\n  armor_type       n\n  &lt;chr&gt;        &lt;int&gt;\n1 Fort             1\n2 Heavy           29\n3 Invulnerable     1\n4 Light           11\n5 Medium          15\n6 Unarmored       14\n\n\n\n\n\nwc3_units %&gt;%    \n  count(armor_type) %&gt;%    \n  arrange(desc(n))\n\n\n# A tibble: 6 × 2\n  armor_type       n\n  &lt;chr&gt;        &lt;int&gt;\n1 Heavy           29\n2 Medium          15\n3 Unarmored       14\n4 Light           11\n5 Fort             1\n6 Invulnerable     1"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#меры-изменчивости",
    "href": "posts/lectures/statR_lecture6.html#меры-изменчивости",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Меры изменчивости",
    "text": "Меры изменчивости\n\nРазмах – разность между максимальным и минимальным значениями.\nМежквартильный размах – разница между верхним и нижним квартилем.\nДисперсия – сумма квадратов отклонений, деленная на их количество.\nОтклонение – это разность между средним арифметическим и конкретным значением.\nСтандартное отклонение – корень из дисперсии."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#формула-дисперсии-и-стандартного-отклонения",
    "href": "posts/lectures/statR_lecture6.html#формула-дисперсии-и-стандартного-отклонения",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Формула дисперсии и стандартного отклонения",
    "text": "Формула дисперсии и стандартного отклонения\nДисперсия (variance):\n\\[ var = \\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n}, \\]\nгде \\(\\overline{x}\\) - среднее, n - количество элементов в выборке\nСтандартное отклонение (standard deviation, sd)\n\\[ sd = \\sqrt{var} =\\sqrt{\\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n}} \\]\nЗдесь приведена оценка для генеральной совокупности – то есть в знаменателе n.\nПо умолчанию функции var() и sd() считают несмещенную оценку - в знаменателе n-1."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#межквартильный-размах-или-как-интерпретировать-боксплот",
    "href": "posts/lectures/statR_lecture6.html#межквартильный-размах-или-как-интерпретировать-боксплот",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Межквартильный размах или как интерпретировать боксплот",
    "text": "Межквартильный размах или как интерпретировать боксплот\nБоксплот"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#полезные-функции-для-генерации-различных-распределений",
    "href": "posts/lectures/statR_lecture6.html#полезные-функции-для-генерации-различных-распределений",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Полезные функции для генерации различных распределений",
    "text": "Полезные функции для генерации различных распределений\nМожно посмотреть в cheatsheet по base R.\n\nНаиболее полезные функции: density (d*()), cumulative distribution (p*()) и random (r*()).\n\n\n\n\n\n\nСо списком всех доступных в base R распределений можно ознакомиться, вызвав\n\n?Distributions"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#стандартное-нормальное-распределение",
    "href": "posts/lectures/statR_lecture6.html#стандартное-нормальное-распределение",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Стандартное нормальное распределение",
    "text": "Стандартное нормальное распределение\nСтандартное нормальное распределение имеет среднее 0 и стандартное отклонение 1. Важно отметить, что здесь мы говорим о параметрах генеральной совокупности, а не о статистиках."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#функция-плотности-вероятности-нормального-распределения-dnorm",
    "href": "posts/lectures/statR_lecture6.html#функция-плотности-вероятности-нормального-распределения-dnorm",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Функция плотности вероятности нормального распределения: dnorm()",
    "text": "Функция плотности вероятности нормального распределения: dnorm()\n\n\nDensity function\n\ndnorm(0) # что получится, если запустить dnorm(1)?\n\n[1] 0.3989423\n\n\n\ndnorm(1) # а если запустить dnorm(-1)?\n\n[1] 0.2419707\n\n\n\ndnorm(-1)\n\n[1] 0.2419707"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#функция-плотности-вероятности-стандартного-нормального-распределения",
    "href": "posts/lectures/statR_lecture6.html#функция-плотности-вероятности-стандартного-нормального-распределения",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Функция плотности вероятности стандартного нормального распределения",
    "text": "Функция плотности вероятности стандартного нормального распределения\n\n\n\n\n\n\nЗабавный момент: для дискретных распределений называется probability mass function, для непрерывных - probability density function, на русский язык переводится одинаково: функция плотности вероятности.\n\n\n\nДавайте отрисуем функцию плотности вероятности стандартного нормального распределения с помощью dnorm().\n\nvec &lt;- seq(-3, 3, 0.01) \nplot(vec, dnorm(vec))"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#функция-плотности-вероятности-шкалы-iq",
    "href": "posts/lectures/statR_lecture6.html#функция-плотности-вероятности-шкалы-iq",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Функция плотности вероятности шкалы IQ",
    "text": "Функция плотности вероятности шкалы IQ\n\niq &lt;- seq(50, 150, 0.1) \nplot(iq, dnorm(iq, mean = 100, sd = 15))\n\n\nШкала IQ отнормирована таким образом, чтобы среднее генеральной совокупности было равно 100, а стандартное отклонение 15."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#pnorm---кумулятивная-функция-распределения-cumulative-density-function",
    "href": "posts/lectures/statR_lecture6.html#pnorm---кумулятивная-функция-распределения-cumulative-density-function",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "pnorm() - кумулятивная функция распределения (cumulative density function)",
    "text": "pnorm() - кумулятивная функция распределения (cumulative density function)\nНа примере стандартного нормального распределения.\n\nplot(vec, pnorm(vec))\n\n\npnorm() отражает вероятность получить такое же или меньшее значение в нормальном распределении (в данном случае в стандартном)."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#pnorm---кумулятивная-функция-распределения-cumulative-density-function-1",
    "href": "posts/lectures/statR_lecture6.html#pnorm---кумулятивная-функция-распределения-cumulative-density-function-1",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "pnorm() - кумулятивная функция распределения (cumulative density function)",
    "text": "pnorm() - кумулятивная функция распределения (cumulative density function)\nНа примере шкалы IQ.\n\n\nЧему будет равно значение pnorm(100) для этой шкалы? То есть какая вероятность получить значение меньше чем 100?\n\npnorm(100, mean = 100, sd = 15) # не забываем прописывать mean, sd\n\n[1] 0.5\n\n\nСреднее равно 100, следовательно -&gt; пояснение на графике\nЧему равно значение pnorm(130) для шкалы IQ?\n\npnorm(130, mean = 100, sd = 15)\n\n[1] 0.9772499"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#rnorm---функция-для-генерации-случайных-значений-из-заданного-распределения",
    "href": "posts/lectures/statR_lecture6.html#rnorm---функция-для-генерации-случайных-значений-из-заданного-распределения",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "rnorm() - функция для генерации случайных значений из заданного распределения",
    "text": "rnorm() - функция для генерации случайных значений из заданного распределения\n\nset.seed(42) # для воспроизводимости 'рандома' \nrnorm(30) \n\n [1]  1.37095845 -0.56469817  0.36312841  0.63286260  0.40426832 -0.10612452\n [7]  1.51152200 -0.09465904  2.01842371 -0.06271410  1.30486965  2.28664539\n[13] -1.38886070 -0.27878877 -0.13332134  0.63595040 -0.28425292 -2.65645542\n[19] -2.44046693  1.32011335 -0.30663859 -1.78130843 -0.17191736  1.21467470\n[25]  1.89519346 -0.43046913 -0.25726938 -1.76316309  0.46009735 -0.63999488\n\nrnorm(30)\n\n [1]  0.45545012  0.70483734  1.03510352 -0.60892638  0.50495512 -1.71700868\n [7] -0.78445901 -0.85090759 -2.41420765  0.03612261  0.20599860 -0.36105730\n[13]  0.75816324 -0.72670483 -1.36828104  0.43281803 -0.81139318  1.44410126\n[19] -0.43144620  0.65564788  0.32192527 -0.78383894  1.57572752  0.64289931\n[25]  0.08976065  0.27655075  0.67928882  0.08983289 -2.99309008  0.28488295\n\n\nСид нужно фиксировать каждый раз перед запуском чего-то зависящего от случайности."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#вычисление-стандартного-отклонения",
    "href": "posts/lectures/statR_lecture6.html#вычисление-стандартного-отклонения",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Вычисление стандартного отклонения",
    "text": "Вычисление стандартного отклонения\n\nset.seed(50) # для фиксации рандома \nsamp &lt;- rnorm(100, mean = 100, sd = 15) \nsqrt(sum((samp - mean(samp)) ^ 2) / (length(samp))) # совпадает ли с результатом функции sd? sd(samp)\n\n[1] 14.81449\n\n\nПочему не совпадает?\n\\[ sd = \\sqrt{var} =\\sqrt{\\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n}} \\]"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#формула-стандартного-отклонения",
    "href": "posts/lectures/statR_lecture6.html#формула-стандартного-отклонения",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Формула стандартного отклонения",
    "text": "Формула стандартного отклонения\nВо встроенной функции sd(), которая опирается на функцию var(), в формуле n-1 в знаменателе.\n\\[ sd = \\sqrt{var} =\\sqrt{\\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n - 1}} \\]\nТакая оценка стандартного отклонения называется несмещенной (unbiased) оценкой.\nПочему n-1 в знаменателе -&gt; объяснение на графике."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#значение-центральной-предельной-теоремы",
    "href": "posts/lectures/statR_lecture6.html#значение-центральной-предельной-теоремы",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Значение центральной предельной теоремы",
    "text": "Значение центральной предельной теоремы\nМысленный эксперимент: многократно извлекаем выборки из генеральной совокупности, считаем средние по выборкам.\n\nsamp_means &lt;- replicate(1000, mean(rnorm(100, mean = 100, sd = 15))) \nhist(samp_means, breaks = 30) \n\n\nРаспределение средних, извлеченных из нормального распределения, примерно нормальное. Это неудивительно, попробуем теперь в качестве генеральной совокупности использовать лог-нормальное распределение."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#лог-нормальное-распределение",
    "href": "posts/lectures/statR_lecture6.html#лог-нормальное-распределение",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Лог-нормальное распределение",
    "text": "Лог-нормальное распределение\n\nhist(rlnorm(100), breaks = 30)"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#распределение-средних-лог-нормального-распределения",
    "href": "posts/lectures/statR_lecture6.html#распределение-средних-лог-нормального-распределения",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Распределение средних лог-нормального распределения",
    "text": "Распределение средних лог-нормального распределения\n\nsamp_means_log &lt;- replicate(1000, mean(rlnorm(100))) \nhist(samp_means_log, breaks = 30)\n\n\nА вот распределение средних из изначально не-нормального распределение тоже похоже на нормальное распределение! Это получается благодаря центральной предельной теореме.\nШайни апп для центральной предельной теоремы"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#выведение-стандартной-ошибки",
    "href": "posts/lectures/statR_lecture6.html#выведение-стандартной-ошибки",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Выведение стандартной ошибки",
    "text": "Выведение стандартной ошибки\n\n\nСреднее выборочного распределения средних близко к популяционному среднему:\n\nmean(samp_means)\n\n[1] 100.0026\n\n\nЧему же равно стандартное отклонение средних?\n\nsd(samp_means)\n\n[1] 1.503984\n\n\nОно примерно равно стандартному отклонению генеральной совокупности деленное на 10 - корень из размера выборки (100)."
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#формула-стандартной-ошибки",
    "href": "posts/lectures/statR_lecture6.html#формула-стандартной-ошибки",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Формула стандартной ошибки",
    "text": "Формула стандартной ошибки\n\\[ \\sigma_{\\overline{x}}= \\frac{\\sigma} {\\sqrt{n}} \\]\nСтандартное отклонение выборочного распределения средних называется еще стандартной ошибкой или standard error of the mean (s.e.m.). Нередко стандартную ошибку используют на графиках в качестве error bars.\n\nsem &lt;- 15/sqrt(length(samp)) \nsem\n\n[1] 1.5\n\n\nПоскольку обычно мы не знаем истинное стандартное отклонение генеральной совокупности (\\(\\sigma\\)), то используем стандартное отклонение выборки \\(sd\\).\n\\[ s_{\\overline{x}}= \\frac{sd} {\\sqrt{n}} \\]"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#доверительный-интервал",
    "href": "posts/lectures/statR_lecture6.html#доверительный-интервал",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Доверительный интервал",
    "text": "Доверительный интервал\nМы хотим поймать симметрично 95% от площади под кривой. Для этого нам нужно отбросить по 2.5% с обоих сторон. Эти 2.5% соответствуют примерно двум стандартным отклонениям от среднего. Если быть точнее, то 1.96. Если быть еще точнее:\n\nqnorm(0.975) \n\n[1] 1.959964\n\nzcr &lt;- qnorm(1 - (1 - 0.95)/2) \nzcr\n\n[1] 1.959964\n\n\n\nsem &lt;- 15/sqrt(length(samp)) \nmean(samp) - sem*zcr #нижняя граница mean(samp) + sem*zcr #верхняя граница\n\n[1] 95.35715"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#доверительный-интервал-1",
    "href": "posts/lectures/statR_lecture6.html#доверительный-интервал-1",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Доверительный интервал",
    "text": "Доверительный интервал\nПопробуем отрисовать доверительные интервалы:\n\nlibrary(tidyverse) \nsample_size &lt;- 100 \nset.seed(40) \nci_simulations &lt;- tibble(   m = replicate(sample_size, mean(rnorm(sample_size, mean = 100, sd = 15))),   se = 15/sqrt(sample_size),   lower = m - se*zcr,   higher = m + se*zcr,   parameter_inside = lower&lt;100 & higher&gt;100 ) \nmany_ci_gg &lt;- ggplot(data = ci_simulations, aes(x = 1:sample_size,y = m)) +   geom_pointrange(aes(ymin = lower,ymax = higher,colour = parameter_inside))+   geom_hline(yintercept = 100)+   coord_flip() +   theme_minimal()"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#визуализация-доверительных-интервалов",
    "href": "posts/lectures/statR_lecture6.html#визуализация-доверительных-интервалов",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Визуализация доверительных интервалов",
    "text": "Визуализация доверительных интервалов\n\nmany_ci_gg\n\n\nЕще одна Визуализация доверительных интервалов"
  },
  {
    "objectID": "posts/lectures/statR_lecture6.html#алгоритм-статистического-вывода",
    "href": "posts/lectures/statR_lecture6.html#алгоритм-статистического-вывода",
    "title": "Язык программирования R для анализа данных: лекция 6",
    "section": "Алгоритм статистического вывода",
    "text": "Алгоритм статистического вывода\n\nФормулировка нулевой и альтернативной гипотезы.\nВычисление тестовых статистик.\nПодсчет p-value как площади под кривой выборочного распределения тестовых статистик.\nВывод: отклоняем или не отклоняем нулевую гипотезу."
  },
  {
    "objectID": "posts/multiple_testing.html",
    "href": "posts/multiple_testing.html",
    "title": "Поправки на множественное тестирование",
    "section": "",
    "text": "Время чтения ~10 минут\nРазберем, что такое поправки на множественное тестирование, зачем они нужны, как работают основные методы, которые часто используются в науке и индустрии, а также на что опираться при выборе поправки в своем исследовании.\nНачнем разбор с классификации."
  },
  {
    "objectID": "posts/multiple_testing.html#классификация-поправок-на-множественное-тестирование",
    "href": "posts/multiple_testing.html#классификация-поправок-на-множественное-тестирование",
    "title": "Поправки на множественное тестирование",
    "section": "Классификация поправок на множественное тестирование",
    "text": "Классификация поправок на множественное тестирование\nСуществует 2 принципиально разных подхода к поправкам на множественное тестирование.\n\nКонтроль групповой вероятности ошибки I рода (FWER, family-wise error rate)\n\nТесты, которые поправляют значимость у набора p-value (поправка Бонферрони, Холма, Шидака и тд.) вне зависимости, какой тест был применен до этого;\nТесты для попарных сравнений групп: пост-хоки (поправка Тьюки, поправка Даннета, тест Фишера LSD и тд).\n\nКонтроль доли ложных открытий (FDR, false discovery rate): поправка Benjamini-Hochberg, поправка Benjamini-Yekutieli.\n\nНебольшое напоминание про типы ошибок:\n\n\n\nhttps://t.me/stats_for_science/69\n\n\nРазберем разные виды поправок подробнее."
  },
  {
    "objectID": "posts/multiple_testing.html#симуляция-независимых-тестов-для-подсчета-fwer",
    "href": "posts/multiple_testing.html#симуляция-независимых-тестов-для-подсчета-fwer",
    "title": "Поправки на множественное тестирование",
    "section": "Симуляция независимых тестов для подсчета FWER",
    "text": "Симуляция независимых тестов для подсчета FWER\nГенерируем заданное количество раз (5, 10, 50, 100) выборки размером 100 элементов из одной генеральной совокупности (стандартного нормального распределения) и сравниваем их t-тестом. Повторяем это 10000 раз, чтобы оценить долю случаев, где мы получили p-value &lt; 0.05 (ложнопозитивный результат).\nТесты независимые, поскольку каждый раз извлекаем новую выборку, следовательно, мы ожидаем увидеть результат, близкий к рассчитанному по формуле выше.\n\n\nCode\npaste('Для 5 тестов: ', mean(replicate(10000, sum(replicate(5, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05) != 0)))\n\n\n[1] \"Для 5 тестов:  0.2239\"\n\n\n\\(FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05)^5 = 0.226\\)\n\n\nCode\npaste('Для 10 тестов: ', mean(replicate(10000, sum(replicate(10, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05) != 0)))\n\n\n[1] \"Для 10 тестов:  0.3976\"\n\n\n\\(FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{10} = 0.401\\)\n\n\nCode\npaste('Для 50 тестов: ', mean(replicate(10000, sum(replicate(50, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05) != 0)))\n\n\n[1] \"Для 50 тестов:  0.9211\"\n\n\n\\(FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{50} = 0.923\\)\n\n\nCode\npaste('Для 100 тестов: ', mean(replicate(10000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05) != 0)))\n\n\n[1] \"Для 100 тестов:  0.9951\"\n\n\n\\(FWER = 1 - (1-\\alpha)^k = 1 - (1-0.05) ^{100} = 0.994\\)\nДействительно, при симуляции значения FWER сходятся с теоретически рассчитанными. Что можно сделать, чтобы избежать ошибок первого рода?"
  },
  {
    "objectID": "posts/multiple_testing.html#поправка-бонферрони-bonferroni",
    "href": "posts/multiple_testing.html#поправка-бонферрони-bonferroni",
    "title": "Поправки на множественное тестирование",
    "section": "Поправка Бонферрони (Bonferroni)",
    "text": "Поправка Бонферрони (Bonferroni)\nСамый простой способ контролировать вероятность ошибки первого рода – это изменить критический уровень значимости \\(\\alpha\\).\n\\[ FWER = 1 - (1-\\frac{\\alpha}{k})^k,  \\tag{2}\\]\nДелим \\(\\alpha\\) на число тестов -&gt; получаем новый p-уровень значимости, ниже которого результаты будут считаться статистически значимыми.\nИли умножаем каждое p-value на количество тестов, и если поправленное p-value &lt; 0.05, то результат считается статистически значимым.\nПри таком подходе мы контролируем вероятность совершить хоть одну ошибку первого рода на уровне 0.05, однако сильно завышаем вероятность ошибки второго рода (то есть не найти значимый эффект, где он на самом деле есть), следовательно, уменьшаем мощность теста.\nПроверим FWER после поправки.\n\n\nCode\npaste('Для 5 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(5, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05/5) != 0)))\n\n\n[1] \"Для 5 тестов FWER по Бонферрони:  0.051\"\n\n\n\n\nCode\npaste('Для 10 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(10, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05/10) != 0)))\n\n\n[1] \"Для 10 тестов FWER по Бонферрони:  0.0435\"\n\n\n\n\nCode\npaste('Для 50 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(50, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05/50) != 0)))\n\n\n[1] \"Для 50 тестов FWER по Бонферрони:  0.0479\"\n\n\n\n\nCode\npaste('Для 100 тестов FWER по Бонферрони: ', mean(replicate(10000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) &lt; 0.05/100) != 0)))\n\n\n[1] \"Для 100 тестов FWER по Бонферрони:  0.0452\"\n\n\nДа, мы контролируем FWER на заданном уровне 0.05.\nПоправка Бонферрони используется редко, в основном в областях, где цена ошибок первого рода (ложнопозитивного результата) очень высока, например в исследованиях GWAS на человеке. В остальных случаях рекомендуют использовать менее консервативные поправки."
  },
  {
    "objectID": "posts/multiple_testing.html#поправка-холма-holm",
    "href": "posts/multiple_testing.html#поправка-холма-holm",
    "title": "Поправки на множественное тестирование",
    "section": "Поправка Холма (Holm)",
    "text": "Поправка Холма (Holm)\nМенее консервативная поправка. Метод часто называют “Бонферрони-Холма”, однако Карло Бонферрони не имел отношения к разработке этой формулы. Разберем на примере как работает.\n\np_value &lt;- c(0.004, 0.87, 0.003, 0.04, 0.18, 0.24)\n\nСортируем и ранжируем p-value по возрастанию, далее по формуле умножаем каждое p-value на \\((m+1-rank)\\), где \\(m\\) - количество тестов, \\(rank\\) - ранг p-value.\n\n\n\n\n\npvalue\nrank_pvalue\nformula\nresult\n\n\n\n\n0.003\n1\n0.003*(6 + 1 - 1)\n0.018\n\n\n0.004\n2\n0.004*(6 + 1 - 2)\n0.020\n\n\n0.040\n3\n0.04*(6 + 1 - 3)\n0.160\n\n\n0.180\n4\n0.18*(6 + 1 - 4)\n0.540\n\n\n0.240\n5\n0.24*(6 + 1 - 5)\n0.480\n\n\n0.870\n6\n0.87*(6 + 1 - 6)\n0.870\n\n\n\n\n\nДалее нужно задать, что поправленные p-value могут только возрастать, и при этом p-value заменяется на бОльшее, поэтому процедура поправки Холма называется пошаговой нисходящей – step-down.\n\n\n\n\n\npvalue\nrank_pvalue\nformula\nresult\np_adjusted\n\n\n\n\n0.003\n1\n0.003*(6 + 1 - 1)\n0.018\n0.018\n\n\n0.004\n2\n0.004*(6 + 1 - 2)\n0.020\n0.020\n\n\n0.040\n3\n0.04*(6 + 1 - 3)\n0.160\n0.160\n\n\n0.180\n4\n0.18*(6 + 1 - 4)\n0.540\n0.540\n\n\n0.240\n5\n0.24*(6 + 1 - 5)\n0.480\n0.540\n\n\n0.870\n6\n0.87*(6 + 1 - 6)\n0.870\n0.870\n\n\n\n\n\nМожем убедиться, что у нас подсчитано все верно:\n\np.adjust(sort(p_value), method = 'holm')\n\n[1] 0.018 0.020 0.160 0.540 0.540 0.870\n\n\nПоскольку для самого минимального p-value поправленное p-value такое же как и в Бонферрони, то поправка Холма контролирует FWER на том же уровне 0.05, что и поправка Бонферрони, при этом не так сильно снижает мощность тестов.\nПроверим на 100 тестах:\n\nreplicate(1000, sum(replicate(100, t.test(rnorm(100), rnorm(100))$p.value) %&gt;% \n  p.adjust(method = 'holm') &lt; 0.05) != 0) %&gt;%\n  mean()\n\n[1] 0.054\n\n\nТаким образом, мы все еще контролируем вероятность совершить хоть одну ошибку первого рода на уровне 0.05, и оставляем больше значимых результатов, по сравнению с поправкой Бонферрони. Поэтому во многих случаях рекомендуют использовать именно поправку Холма для множественных сравнений.\n\n\n\n\n\n\nСсылка на оригинальную статью:\n\n\n\nHolm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6, 65–70. https://www.jstor.org/stable/4615733.\n\n\nТеперь перейдем к поправкам, которые используются в конкретных тестах."
  },
  {
    "objectID": "posts/multiple_testing.html#тест-фишера-lsd-least-significant-difference",
    "href": "posts/multiple_testing.html#тест-фишера-lsd-least-significant-difference",
    "title": "Поправки на множественное тестирование",
    "section": "Тест Фишера LSD (Least significant difference)",
    "text": "Тест Фишера LSD (Least significant difference)\nИспользуется как постхок тест только после значимой ANOVA для сравнения средних групп между собой (напоминаю, что ANOVA, дисперсионный анализ дает ответ на вопрос, есть ли хоть какое-то различие между группами, но не говорит между какими). Также тест можно применять только для сравнения трех групп.\nФормула вычисления критерия:\n\\[\nt = \\frac{\\overline{X_1}-\\overline{X2}}{\\sqrt{MSE(\\frac{1}{n_1}+\\frac{1}{n_2})}}, где\n\\]\n\\(\\overline{X_1}\\), \\(\\overline{X_2}\\) – средние групп 1 и 2, \\(n_1\\), \\(n_2\\) – размер групп 1 и 2, \\(MSE\\) – mean square error из таблицы ANOVA, то есть общая дисперсия между всеми группами.\nДля трех групп имеет большую мощность чем Тьюки. Но если групп больше чем 3, то контролирует FWER на уровне больше 0.05 и следовательно к использованию не рекомендуется.\nПодробнее, почему это так, можно посмотреть здесь."
  },
  {
    "objectID": "posts/multiple_testing.html#поправка-тьюки-tukey-tukeyhsd",
    "href": "posts/multiple_testing.html#поправка-тьюки-tukey-tukeyhsd",
    "title": "Поправки на множественное тестирование",
    "section": "Поправка Тьюки (Tukey, TukeyHSD)",
    "text": "Поправка Тьюки (Tukey, TukeyHSD)\nИспользуется как постхок тест вне зависимости от значимости ANOVA (подробнее ниже) для сравнения средних групп между собой, чтобы узнать какие именно группы различаются. Также нет ограничения на количество групп, участвующих в сравнении.\nВ этом тесте сравнивается каждая группа с каждой, поэтому у него будет минимальная мощность, так как тестов больше всего. Если нам не нужно сравнивать каждую группу с каждой, то лучше использовать тест Даннета, который сравнивает одну группу с остальными и имеет более высокую мощность.\nФормула расчета тестовой статистики:\n\\[ q_s = \\frac{M_1 - M_2}{\\sqrt{\\frac{SS_w}{2}(\\frac{1}{n_A}+\\frac{1}{n_B})}},  \\]\nгде M1 &gt; M2 (средние в группе), nA, nB - размер 1 и 2 выборки, \\(SS_W\\) - внутригрупповая сумма квадратов в ANOVA.\nДля проверки гипотезы используется studentized range distribution, студентизированное распределение (не путать с t-распределением).\nУ теста Тьюки есть допущения к использованию:\n\nНезависимость наблюдений\nПримерное равенство дисперсий\nПримерно нормальное распределение данных в группах\n\nЕсли допущения про нормальность распределения и равенство дисперсий не выполняются, то можно использовать непараметрические аналоги теста.\n\n\n\n\n\n\nПро значимую ANOVA\n\n\n\nТест Тьюки вовсе необязательно использовать только после значимой ановы, как нередко пишут в учебниках, просто в тесте при расчете используется внутригрупповая сумма квадратов и количество степеней свободы из таблицы ANOVA. Поэтому в докомпьютерное время расчет критерия Тьюки был проще после дисперсионного анализа, и при незначимой анове сравнивать группы между собой уже не имело смысла. Сейчас в R в функции TukeyHSD() для расчета критерия Тьюки в качестве инпута используется результат ановы, но никто не запрещает применять тест и если анова оказалась незначимой.\nТакже может быть и ситуация, когда по результатам ANOVA получилось, что средние групп различаются между собой, но при этом по Тьюки нет, можно почитать здесь, почему так бывает."
  },
  {
    "objectID": "posts/multiple_testing.html#тест-данна-dunn",
    "href": "posts/multiple_testing.html#тест-данна-dunn",
    "title": "Поправки на множественное тестирование",
    "section": "Тест Данна (Dunn)",
    "text": "Тест Данна (Dunn)\nЯвляется непараметрическим постхок тестом, аналогом теста Тьюки, для ситуаций, когда его допущения не выполняются.\nПо сути сравнивает средний ранг групп, вычисленных после теста Краскелла-Уоллиса (Kruskal-Wallis), таким образом как бы учитывая общую дисперсию между группами (чего не будет происходить в попарных тестах Манна-Уитни). Далее полученные p-value должны быть поправлены любым методом, например Бонферрони, Холм, FDR.\nЛично мне это в свое время сломало мозг, что это поправка в поправке, вроде используем постхок тест, но при этом его результат тоже нужно поправить тестом на выбор (в функции dunn_test() из пакета rstatix поправка Холма происходит автоматически).\nКак альтернатива, в качестве непараметрического аналога Тьюки можно использовать попарные тесты Манна-Уитни с поправками, однако ранги будут рассчитаны отдельно для каждого теста.\nОригинальная статья про метод:\nDunn, O. J. (1964) Multiple comparisons using rank sums Technometrics, 6(3):241-252."
  },
  {
    "objectID": "posts/multiple_testing.html#тест-даннета-dunnet",
    "href": "posts/multiple_testing.html#тест-даннета-dunnet",
    "title": "Поправки на множественное тестирование",
    "section": "Тест Даннета (Dunnet)",
    "text": "Тест Даннета (Dunnet)\nС помощью этого теста сравнивают одну группу с остальными группами, например, когда задача сравнить контрольную группу и несколько воздействий, и не нужно сравнение каждой группы с каждой\nНапример, у нас 4 группы, из которой одна группа контрольная, с которой мы проводим сравнения. У нас будет всего 3 сравнения: control - A, control - B, control - C, что увеличивает мощность теста.\nДля теста Даннета должны соблюдаться такие же допущения, как и для теста Тьюки: независимость наблюдений, примерно равная дисперсия в группах и нормальное распределение.\nПосмотреть детально можно здесь.\nТеперь перейдем к принципиально другому подходу поправок – контроле доли ложных открытий (FDR)."
  },
  {
    "objectID": "posts/multiple_testing.html#определение-fdr",
    "href": "posts/multiple_testing.html#определение-fdr",
    "title": "Поправки на множественное тестирование",
    "section": "Определение FDR",
    "text": "Определение FDR\nFDR, false discovery rate – доля ложнопозитивных результатов.\nВ скрининговых экспериментах, таких как анализ RNA-seq данных важнее контролировать долю ложнопозитивных результатов (FDR), чем вероятность совершить хоть одно ложное открытие.\n\n\n\n\n\n\n\n\n\nH0 верна (различий нет)\nH0 неверна (различие есть)\n\n\n\n\nНе отклонить H0\nTrue Negative (TN)\nFalse Negative (FN)\n\n\nОтклонить H0\nFalse Positive (FP)\nTrue Positive (TP)\n\n\n\n\\[ FDR = \\frac{FP}{FP + TP} \\]\nПодробнее в этом видео."
  },
  {
    "objectID": "posts/multiple_testing.html#расчет-fdr",
    "href": "posts/multiple_testing.html#расчет-fdr",
    "title": "Поправки на множественное тестирование",
    "section": "Расчет FDR",
    "text": "Расчет FDR\nРасмотрим контроль FDR по методу Бенджамини-Хохберга (Benjamini-Hochberg), так как он используется чаще всего. Также FDR можно посчитать с помощью метода Benjamini-Yekutieli, но он имеет меньшую мощность и используется реже.\n\np_values &lt;- c(0.361, 0.387, 0.005, 0.009, 0.022, 0.051, 0.101, 0.019)\n\n\nСортируем и ранжируем p-value по возрастанию;\nКаждое p-value умножаем на \\(\\frac{m}{rank}\\), где \\(m\\) – количество тестов, \\(rank\\) – ранг p-value.\n\n\n\n\n\n\npvalue\nrank_pvalue\nformula\nresult\n\n\n\n\n0.005\n1\n0.005*(8/1)\n0.0400000\n\n\n0.009\n2\n0.009*(8/2)\n0.0360000\n\n\n0.019\n3\n0.019*(8/3)\n0.0506667\n\n\n0.022\n4\n0.022*(8/4)\n0.0440000\n\n\n0.051\n5\n0.051*(8/5)\n0.0816000\n\n\n0.101\n6\n0.101*(8/6)\n0.1346667\n\n\n0.361\n7\n0.361*(8/7)\n0.4125714\n\n\n0.387\n8\n0.387*(8/8)\n0.3870000\n\n\n\n\n\nИтоговое FDR вычисляется так, чтобы p-value не убывали, но при этом приводится в меньшую сторону (в отличие от поправки Холма), поэтому процедура называется пошаговой восходящей – step-up.\n\n\n\n\n\npvalue\nrank_pvalue\nformula\nresult\np_adjusted\nreject_H0\n\n\n\n\n0.005\n1\n0.005*(8/1)\n0.0400000\n0.0360000\nyes\n\n\n0.009\n2\n0.009*(8/2)\n0.0360000\n0.0360000\nyes\n\n\n0.019\n3\n0.019*(8/3)\n0.0506667\n0.0440000\nyes\n\n\n0.022\n4\n0.022*(8/4)\n0.0440000\n0.0440000\nyes\n\n\n0.051\n5\n0.051*(8/5)\n0.0816000\n0.0816000\nno\n\n\n0.101\n6\n0.101*(8/6)\n0.1346667\n0.1346667\nno\n\n\n0.361\n7\n0.361*(8/7)\n0.4125714\n0.3870000\nno\n\n\n0.387\n8\n0.387*(8/8)\n0.3870000\n0.3870000\nno\n\n\n\n\n\nFDR в основном используется в скрининговых экспериментах, где ключевые результаты могут быть проверены уже более прицельным экспериментом (например некоторые дифференциально экспрессирующиеся гены по результатам RNA-seq проверяют количественной ПЦР)."
  },
  {
    "objectID": "posts/statistics_course_why_not.html",
    "href": "posts/statistics_course_why_not.html",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "",
    "text": "По итогам многочисленных дискуссий в чатах по статистике и биоинформатике (BioStat &lt;- R | Чат по статистике и R, BIOINF | Education & Career), я решила пересмотреть на удвоенной скорости курс “Основы статистики” на платформе stepik самостоятельно. Давайте разберем его достоинства и недостатки, а также есть ли смысл его смотреть в 2023-2024 году."
  },
  {
    "objectID": "posts/statistics_course_why_not.html#достоинства-курса",
    "href": "posts/statistics_course_why_not.html#достоинства-курса",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Достоинства курса",
    "text": "Достоинства курса\nИз достоинств данного курса стоит отметить, что он был создан в то время, когда было очень мало русскоязычных материалов по статистике такого формата. Да, были книги, но лекций на интерактивных платформах с возможностью проверять себя – не было.\nЯ сама посмотрела курс примерно в 2018 году, после очень плохого курса по статистике в университете и узнала что-то новое для себя, после чего уже начала изучать статистику преимущественно по книгам (а сейчас преподаю сама). На тот момент мне курс показался очень качественным, понравился простой язык изложения, не перегруженность формулами, формат заданий и их проверки (это преимущество в целом платформ по типу stepik, coursera, не конкретного курса).\nДа, я не совсем поняла объяснение центральной предельной теоремы, но на тот момент это было не единственное, что осталось непонятным, поэтому не заподозрила авторов курса в неверном объяснении. Потом в чатах увидела, что очень многие критикуют курс, в том числе из-за некорректного объяснения центральной предельной теоремы (почитать можно здесь) и наконец решила пересмотреть и расписать самостоятельно. Обнаружила, что автор очень неаккуратно общается с терминами, формулировками, не говоря уже про совсем неверное объяснение ЦПТ.\nРазберем наиболее существенные неточности от самых серьезных к менее серьезным и в разбивке по блокам курса. Платформа степик к сожалению не позволяет делать ссылки с таймкодами, поэтому буду прикреплять ссылки на видео и подписывать время в тексте."
  },
  {
    "objectID": "posts/statistics_course_why_not.html#неверная-интерпретация-доверительных-интервалов",
    "href": "posts/statistics_course_why_not.html#неверная-интерпретация-доверительных-интервалов",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Неверная интерпретация доверительных интервалов",
    "text": "Неверная интерпретация доверительных интервалов\nВот тут было что-то совсем странное с интерпретацией доверительных интервалов (с 1.05).\n\n\n\n\n\n\nТекст\n\n\n\n“Потому что если у нас среднее номер 2 не попадает в доверительный интервал для среднего номер 1, и наоборот, среднее номер 1 не попадает в доверительный интервал для среднего номер 2, то такие различия у нас будут достигать уровня статистической значимости”.\n\n\n\n\n\nСкриншот из видео\n\n\nДопустим, не будем придираться к формулировке что различия будут достигать уровень статистической значимости (?), хотя на самом деле это сомнительная формулировка, но интерпретация доверительных интервалов совсем неверная.\nЯ писала про доверительные интервалы и пределы погрешностей. Отсутствие перекрывания 95% доверительных интервалов говорит о статистически значимых различиях (p &lt; 0.05), но речь идет именно о перекрывании усов, а вовсе не в том, что доверительный интервал одной выборки не перекрывается со средним второй. Перекрывание со средним ничего не значит, а что на картинке выше доверительные интервалы перекрываются, не говорит о том что различий нет, поскольку только отсутствие перекрывания говорит о статистически значимых различиях (вот здесь подробнее писала). Наличие перекрывания не говорит о том, что различий нет.\nСчитаю это очень серьезной неточностью и даже ошибкой курса, учитывая, что в целом доверительный интервал как явление дает простор для мисинтерпретации, так еще и в курсе приведено заведомо неверное объяснение."
  },
  {
    "objectID": "posts/statistics_course_why_not.html#терминологические-неточности",
    "href": "posts/statistics_course_why_not.html#терминологические-неточности",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Терминологические неточности",
    "text": "Терминологические неточности\nСюда относятся многочисленные “принять альтернативную гипотезу”, “статистически достоверно” вместо статистически значимо, соберем их в одном месте:\n\n“Принять альтернативную гипотезу” 0:38\nВ ответах к заданию “принимаем нулевую гипотезу”\n“Считать наши значения статистически достоверными” 0.50\n“Принимаем различия статистически достоверными” 1.26 1.45 3.24 5.04. Заметьте, тут в рамках одного видео такая формулировка встречается 4 раза, что нельзя списать на то, что автор просто оговорился.\nПринимали различия стат достоверными1.24\nНа этом степе в задании “различия считаются статистически достоверными”.\nВ задании статистически достоверными\n“различиям между группами признавались статистически достоверными” в тексте задания\nпринять или отклонить нулевую гипотезу 1.20\n\nВ общем, пока я собирала эту подборку и пересматривала заново, я чуть не сошла с ума, так что давайте перейдем от “достоверностей” к другому.\nТеперь разберем по разделам."
  },
  {
    "objectID": "posts/statistics_course_why_not.html#первая-часть-введение",
    "href": "posts/statistics_course_why_not.html#первая-часть-введение",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Первая часть: введение",
    "text": "Первая часть: введение\nОбщее впечатление: в целом большая часть вещей объяснена нормально, особенно простых.\nЗдесь немного странная история про перевод из количественной переменной в номинативную: “измерить рост наших испытуемых, это будет непрерывная количественная переменная, проранжировать наших испытуемых, то есть перевести их в ранговую переменную, а потом разделить на две группы: 1 выше среднего, 2 ниже среднего, то есть сделать номинативную переменную”. Все-таки последняя переменная не будет в чистом виде номинативной, потому что можно задать операцию сравнения. Хотя конечно сравнивать две группы уже имеет мало смысла.\nТерминологическая непоследовательность в определении дисперсии выборки и генеральной совокупности и стандартное/среднеквадратичное отклонение и почему -1 в знаменателе формулы дисперсии.\n50% наблюдений в боксе https://stepik.org/lesson/9294/step/5?unit=1827\nНо это не обязательно так, например, это будет неверно в случае, если в данных есть повторяющиеся значения.\n\nboxplot(c(1, 2, 2, 2, 2, 3, 3, 3))\n\n\n\n\nЗдесь в “ящике” бокса находится 7/8 значений, то есть 87.5%"
  },
  {
    "objectID": "posts/statistics_course_why_not.html#вторая-часть-сравнение-средних",
    "href": "posts/statistics_course_why_not.html#вторая-часть-сравнение-средних",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Вторая часть: сравнение средних",
    "text": "Вторая часть: сравнение средних\nЗдесь некорректно назван t-тест почему-то парным t-тестом. Видимо имелся ввиду двухвыборочный t-тест. Напоминаю, что парный или зависимый t-тест применяется к зависимым выборкам и формула расчета его другая.\nПостановка нулевой и альтернативной гипотезы: средние в генеральной совокупности не равны. В комментариях исправили, но много ли кто читает комментарии после просмотра видео.\nНе было ничего про тест Велча\nПро формулу и одинаковый размер выборки\nНе то про QQ\nMU тест жесть https://stepik.org/lesson/8082/step/10?unit=1361\nпарный ттест\nкритерий т-стьюдента называется вообще везде\nhttps://stepik.org/lesson/9249/step/6?unit=1829\nстранная формулировка нулевой гипотезы\nhttps://stepik.org/lesson/9249/step/9?unit=1829\nнормальное распределение\nВ части про поправки на множественное тестирование, все поправки собраны в одну кучу. https://stepik.org/lesson/8085/step/7?unit=1364"
  },
  {
    "objectID": "posts/statistics_course_why_not.html#про-корреляции",
    "href": "posts/statistics_course_why_not.html#про-корреляции",
    "title": "Разбор курса ‘Основы статистики’",
    "section": "Про корреляции",
    "text": "Про корреляции\nНормальное вместо т-распределения или нет\nЭкстраполяция https://stepik.org/lesson/9996/step/2?unit=1926\nОпечатка гетероскедастичность https://stepik.org/lesson/8090/step/3?unit=1369\nПро регрессию недостаточно подробно и к сожалению нет ссылок на другие источники для дальнейшего развития. VIF, критерий AIC, BIC, виды отбора лучшей модели"
  },
  {
    "objectID": "posts/types_of_error_bars.html",
    "href": "posts/types_of_error_bars.html",
    "title": "Виды пределов погрешностей",
    "section": "",
    "text": "Сегодня поговорим о различных видах пределов погрешностей или усов, как пишут в русскоязычной литературе (error bars).\nПредупреждаю сразу: по ходу повествования я буду использовать все варианты написания этого термина, даже слово эррор бар.\nВажно отметить, что существует два принципиально разных вида отображения пределов погрешностей на графике:\nОни выглядят на графике одинаково, но по факту фундаментально различны. Давайте разбираться, в чем разница."
  },
  {
    "objectID": "posts/types_of_error_bars.html#descriptive-error-bars-описательные-пределы-погрешностей",
    "href": "posts/types_of_error_bars.html#descriptive-error-bars-описательные-пределы-погрешностей",
    "title": "Виды пределов погрешностей",
    "section": "Descriptive error bars (Описательные пределы погрешностей)",
    "text": "Descriptive error bars (Описательные пределы погрешностей)\nК описательным эррор барам относятся:\n\nРазмах (range): разница между максимальным и минимальным значением в выборке (Xmax - Xmin).\nМежквартильный размах (interquartile range, IQR): разница между третьм квартилем (Q3) и первым квартилем (Q1.).\nСтандартное отклонение (standard deviation, sd): квадратный корень из дисперсии.\n\nРазмах самая простая для понимания метрика, при этом редко использующаяся, поскольку сама по себе разница между максимальным и минимальным значением довольно-таки малоинформативна.\nМежквартильный размах (IQR), точнее 1.5*IQR чаще всего используется на боксплотах (boxplot), я редко встречала 1*IQR или 1.5*IQR как усы к обычным барплотам.\nБарплот (barplot) - столбчатая диаграмма для категориальных данных, их будет много чуть дальше.\n\n\n\nСамое простое описание составляющих боксплота\n\n\nЕсли расставить числа в ряд по возрастанию, то середина этого ряда - медиана (median) или второй квартиль (Q2). Первый квартиль (Q1) - значение, меньше которого 25% процентов данных, третий квартиль (Q3) - значение, меньше которого 75% данных.\nДумаю, что на рисунке понять проще:\n\n\n\nпро межквартильный размах (IQR)\n\n\nМежквартильный размах намного чаще используется для визуализации, так как предоставляет больше информации о данных.\nСтандартное отклонение (standard deviation) по-моему наиболее часто встречается в публикациях и на конференциях (по крайней мере в биологии), да и я обычно использую именно sd в качестве предела погрешностей.\nФормула стандартного отклонения (для генеральной совокупности): \\[\\Large sd = \\sqrt{var} = \\sqrt{\\frac{\\sum_{i=1}^{N}(x_{i} - \\mu)^2}{N}}\\]Где \\(\\mu\\) - среднее значение в генеральной совокупности, \\(N\\) - размер генеральной совокупности, var (variance) - дисперсия. Но мы обычно работаем с выборками, а не генеральной совокупностью, и в формуле вычисления sd в Excel и R используют несмещенную (unbiased) оценку дисперсии и стандартного отклонения (потому что для выборки): \\[\\Large sd = \\sqrt{var} = \\sqrt{\\frac{\\sum_{i=1}^{N}(x_{i} - \\overline{x})^2}{N-1}}\\]\nПочему именно \\(N-1\\) в знаменателе выходит за рамки нашего обсуждения, поэтому ограничусь ссылками: 1, 2, видео с таймкодом.\nЕще не сделала схему с детальным вычислением стандартного отклонения на реальных данных, поэтому пока можно посмотреть на статквесте.\nВажный момент! Все вышеописанные метрики отражают разброс значений в нашей выборке, без каких-либо предположений о происходящем в генеральной совокупности. В этом отличие от второго типа error bar."
  },
  {
    "objectID": "posts/types_of_error_bars.html#inferential-error-bars",
    "href": "posts/types_of_error_bars.html#inferential-error-bars",
    "title": "Виды пределов погрешностей",
    "section": "Inferential error bars",
    "text": "Inferential error bars\nК эррор барам, отражающим статистики вывода относятся:\n\nСтандартная ошибка среднего (standard error of mean, SEM или просто SE);\nДоверительный интервал (confidence interval, CI).\n\nПринципиальное отличие от описательных пределов погрешности в том, что грубо говоря, стандартная ошибка среднего/доверительный интервал пытаются отразить степень уверенности в поиске к примеру истинного среднего генеральной совокупности. В то время как описательные отражают, что происходит конкретно в нашей выборке.\nТут немного инфы для продвинутых (не открывайте, если не уверены, что хотите это знать!):\nНебольшое уточнение: с помощью бутстрепов можно оценивать не только доверительный интервал и стандартную ошибку для среднего, но и для медианы и даже для стандартного отклонения, но про это сейчас не будем\n\nСтандартная ошибка среднего\nТеперь еще немного вымученных формулировок, которые попробую сформулировать понятнее.\nВымученная формулировка: The standard error (SE) of a statistic is the standard deviation of its sampling distribution or an estimate of that standard deviation. (цитата прямо из википедии)\nФормула вычисления стандартной ошибки среднего очень простая - стандартное отклонение, деленное на квадратный корень из размера выборки. Но что на самом деле это значит, какой физический смысл стоит за результатом этого вычисления? Попробуйте сами ответить на этот вопрос, опираясь только на определение из википедии и формулу)\nТеперь попробуем представить, что мы провели некий эксперимент, например измеряли вес 20 мышей после какого-либо воздействия и усредняли полученные значения. При этом мы решили 10 раз повторить свой эксперимент, в результате чего получили 10 средних значений. После этого мы можем посчитать среднее средних (!) и стандартное отклонение средних. Вот это стандартное отклонение выборочных средних и есть стандартная ошибка среднего. Ура? Пойду воспроизводить эксперимент по 10 раз?\nНо мы не всегда (обычно никогда) можем себе позволить повторять эксперимент по 10 раз, и хитрость в том, что мы можем вычислить стандартную ошибку среднего без многократного повторения эксперимента, просто поделив стандартное отклонение на квадратный корень из размера выборки.\nВот тут хорошо расписано, как моделировать стандартную ошибку средних и что она действительно соответствует стандартному отклонению, деленному на квадратный корень из числа наблюдений.\n\\[\\huge SE = \\frac{sd}{\\sqrt{N}}\\] Формула SE (стандартной ошибки), где sd - это стандартное отклонение, N - количество наблюдений\nВот еще можно посмотреть про:\n\nотличия стандартного отклонения от стандартной ошибки https://www.youtube.com/watch?v=SzZ6GpcfoQY\nобъяснение стандартной ошибки с бутстреп-примером https://www.youtube.com/watch?v=XNgt7F6FqDU&t=341s\n\nВ статье, на которую я опиралась при написании этого материала, было указано, что для представления сравнения групп лучше использовать стандартную ошибку/доверительный интервал как error bar, а не стандартное отклонение и другие описательные статистики.\nНо у меня есть неприятное подозрение, что для публикаций и представлений своей работы на конференциях некоторые недобросовестные ученые используют se, чтобы на графиках были усы поменьше. Однако, я не хочу обидеть тех, кто использует стандартную ошибку и понимает физический смысл. Интересно будет собрать примеры работ, где использование se оправданно и разумно, и где это не так, поэтому если есть примеры, то пишите в комментарии.\nВ целом, плюс именно se в том, что при отрисовке сравнений двух или нескольких групп, перекрываемость усов позволяет судить об отсутствии статистической значимости различий (при этом наоборот не работает, про это будет еще чуть дальше), в то время как sd и остальные описательные пределы погрешностей - нет. Однако sd показывает данные почти как они есть, то есть реальный разброс в наших данных, без предположений о генеральной совокупности, поэтому лично я предпочитаю sd для отрисовки. Это тоже интересная тема для дискуссии, буду рада обсудить в комментариях.\nИ наконец…\n\n\nДоверительный интервал\nЕсли простыми словами, то доверительный интервал оценивает диапазон, в котором с заданной уверенностью (например 95%), можно ожидать истинное значение параметра, например среднего генеральной совокупности.\nПрикрепляю формулу (кстати все формулы записаны прямо силами Rmarkdown):\n\\[\\huge CI = \\overline{x} ± z\\frac{s}{\\sqrt{n}}\\]\nФормула доверительного интервала (CI), \\(\\overline{x}\\) - среднее значение выборки, z - значение уровня достоверности, например для 95% уровня достоверности, \\(z = 1.96\\), \\(\\frac{s}{\\sqrt{n}}\\) - формула уже знакомой стандартной ошибки.\nВообще я не люблю эту тему, но к счастью уже существует немало источников, которые объяснили доверительный интервал разными способами:\n\nВ книге у Ивана объяснение доверительных интервалов классическим образом через формулу стандартной ошибки;\nКлассное объяснение доверительных интервалов с помощью бутстрепа на статквесте (канал супер, всем рекомендую);\nБонусом для тех, кому это все слишком просто: я нашла совершенно дикую статью про доверительные интервалы, доверительные полосы и доверительные эллипсы (sic!), поэтому кто желает преисполниться - велком (вот ссылка). Краткого пересказа не будет, это надо прочитать самостоятельно.\n\nНебольшой вывод. Отрисовка доверительных интервалов сейчас считается модной, якобы их проще интерпретировать. Но на самом деле доверительный интервал как и p-value - это один из тех концептов, которые провоцируют просто огромное количество мисинтерпретаций, это кстати одна из причин, по которой я это не люблю рассказывать. Важно сейчас отметить вот что:\n\n\n\nИнтерпретация перекрывания inferential error bars. Ссылка на статью, откуда картинка\n\n\nТаким образом, перекрывание стандартных ошибок говорит об отсутствии значимости в различии, при этом обратное не верно, а с доверительными интервалами наоборот - отсутствие перекрывания доверительных интервалов говорит о значимости различий, в то время обратное не верно.\nВ этом смысле мне нравится концепция стандартного отклонения, потому что их перекрывание или не перекрывание не говорит нам вообще ничего, а значит - нельзя запутаться!). Чуть дальше разберем, как выглядят разные пределы погрешностей!\nВ любом случае, вне зависимости какой тип пределов погрешностей вы выбрали для отображения на графике, всегда нужно подписывать какой, потому что интерпретации совершенно разные."
  },
  {
    "objectID": "posts/types_of_error_bars.html#а-что-если-вообще-не-рисовать-пределы-погрешностей",
    "href": "posts/types_of_error_bars.html#а-что-если-вообще-не-рисовать-пределы-погрешностей",
    "title": "Виды пределов погрешностей",
    "section": "А что если вообще не рисовать пределы погрешностей?",
    "text": "А что если вообще не рисовать пределы погрешностей?\nЕсли число значений в выборке невелико (например меньше 10), то лучше нарисовать все числа как они есть, например с помощью диаграммы рассеяния (scatter plot) без редуцирования информации в боксплоты или барплоты с пределами погрешностей. Если значений больше, то возможно множество вариантов отрисовывания, часто исследователи используют просто барплоты с пределами погрешностей или боксплоты, однако здесь я предлагаю два возможных варианта более репрезентативного отображения данных.\nПервый - это отрисовать violin plot (скрипичная диаграмма), но не просто, а с небольшим боксплотом внутри. Я эту идею подчерпнула на курсе бластима по R, мне показалось очень забавно, прикрепляю небольшой пример как это выглядит на примере данных iris.\n\nlibrary(tidyverse)\nviolin_box &lt;- iris %&gt;% \n  ggplot(aes(x = Species, y = Sepal.Width))+\n  geom_violin(aes(fill = Species))+\n  geom_boxplot(width = 0.15, alpha = 0.8)+\n  theme_bw()\nviolin_box\n\n\n\n\nВторой вариант больше подойдет для относительно небольшого количества наблюдений, когда счет идет на десятки, но не тысячи точек. Это комбинация боксплота и отображения точек как они есть с помощью geom_jitter() в пакете ggplot2.\n\nbox_point &lt;- iris %&gt;% \n  ggplot(aes(Species, Sepal.Width))+\n  geom_boxplot()+\n  geom_jitter(aes(colour = Species), \n              position = position_jitter(width = 0.3, height = 0),\n              alpha = 0.6, size = 1.5)+\n  theme_bw()\nbox_point\n\n\n\n\nПо моему прикольно получилось! Эти варианты визуализации содержат гораздо больше информации, сравните например с обычными боксплотами и барплотами (здесь как предел погрешности использовала стандартное отклонение).\n\n📝 UPD: в комментариях посоветовали напомнить, что перекрывание или не-перекрывание усов в боксплотах и вайлин плотах не имеет отношения к статистике вывода, то есть не позволяет делать выводы о значимости различий\n\n\nbox &lt;- iris %&gt;% \n  ggplot(aes(Species, Sepal.Width, fill = Species))+\n  geom_boxplot()+\n  theme_bw()\nbar &lt;- iris %&gt;% \n  group_by(Species) %&gt;% \n  summarise(mean_PW = mean(Sepal.Width), sd_PW = sd(Sepal.Width)) %&gt;% \n  ggplot(aes(Species, mean_PW, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean_PW - sd_PW, ymax = mean_PW + sd_PW), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are standard deviation')+\n  theme_bw()\nbox\n\n\n\nbar\n\n\n\n\nА теперь все вместе на одном графике (обратите внимание на пакет patchwork для красивого объединения плотов на одном рисунке):\n\nlibrary(patchwork)\np &lt;- (violin_box + box_point) / (box + bar)\np + plot_annotation(tag_levels = 'A')\n\n\n\n\nГолосуйте, какой плот больше нравится и является более информативным. Мне лично здесь нравится вариант B - box+точки, кажется наиболее информативным и красивым. Возможно, если наблюдений будет больше, то лучше окажется первый вариант с вайлином плотом и боксом.\n\n📝 В violin plot-е (скрипичная диаграмма) форма отражает плотность распределения значений. Грубо говоря, чем больше значений в диапазоне, тем толще соответствующий диапазон на графике. В случае geom_jitter по оси X важна только принадлежность точек к группе, внутри одной группы точки по оси X распределяются так, чтобы не перекрывать друг друга.\n\nА теперь визуализация трех основных пределов погрешностей: стандартного отклонения, стандартной ошибки и доверительных интервалов на данных iris.\n\nlibrary(data.table)\nbar_se &lt;- iris %&gt;% \n  group_by(Species) %&gt;% \n  summarise(mean_PW = mean(Sepal.Width), se_PW = sd(Sepal.Width)/sqrt(length(Sepal.Width))) %&gt;% \n  ggplot(aes(Species, mean_PW, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean_PW - se_PW, ymax = mean_PW + se_PW), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are standard error')+\n  theme_bw()\n# bar_se\n\nbar_CI &lt;- iris %&gt;% \n  group_by(Species) %&gt;%\n  summarise(n=n(), mean=mean(Sepal.Length), sd=sd(Sepal.Length)) %&gt;%\n  mutate(se = sd/sqrt(n))  %&gt;%\n  mutate(ic = se * qt((1-0.05)/2 + .5, n-1)) %&gt;% \n  ggplot(aes(Species, mean, fill = Species))+\n  geom_bar(stat = 'identity')+\n  geom_errorbar(aes(ymin = mean - ic, ymax = mean + ic), width = 0.2)+\n  labs(y = 'Mean Sepal Width')+\n  ggtitle('Error bars are confidence intervals')+\n  theme_bw()\n# bar_CI\nbar + bar_se + bar_CI+  plot_layout(ncol = 2)\n\n\n\n\nТеперь я сделаю одну плохую вещь, а именно просто сравню тестом Стьюдента Sepal.Width для разных видов ириса. Как думаете, почему это плохо?\nЯ в этом примере не делаю поправку на множественное тестирование\n\niris %&gt;% \n  setDT() \ncat('versicolor vs setosa: \\np-value of the test', t.test(iris[Species == 'setosa', Sepal.Width], iris[Species == 'versicolor', Sepal.Width])$p.value)\n\nversicolor vs setosa: \np-value of the test 2.484228e-15\n\ncat('setosa vs virginica: \\np-value of the test', t.test(iris[Species == 'setosa', Sepal.Width], iris[Species == 'virginica', Sepal.Width])$p.value)\n\nsetosa vs virginica: \np-value of the test 4.570771e-09\n\ncat('virginica vs versicolor: \\np-value of the test', t.test(iris[Species == 'virginica', Sepal.Width], iris[Species == 'versicolor', Sepal.Width])$p.value)\n\nvirginica vs versicolor: \np-value of the test 0.001819483\n\n\nНо один раз в жизни можно, только для демонстрации того, что все выборки значимо отличаются друг от друга (без поправки), и на графиках можно увидеть что доверительные интервалы не перекрываются.\nУра! Я дописала, а вы дочитали, с чем я всех и поздравляю) Теперь перейдем к выводам."
  },
  {
    "objectID": "posts/types_of_error_bars.html#выводы",
    "href": "posts/types_of_error_bars.html#выводы",
    "title": "Виды пределов погрешностей",
    "section": "Выводы",
    "text": "Выводы\n\nСуществует два типа отображения пределов погрешностей на графике: описательные, которые описывают значения в конкретно нашей выборке и inferential (так и не придумала как переводить), которые пытаются отразить что-то о генеральной совокупности с заданной долей уверенности.\nДля отображения сравнений между группами рекомендуют использовать вторые, поскольку они позволяют делать выводы из перекрывания или не-перекрывания усов.\nОднако, есть способы рисовать распределение наших значений без использования мисинтерпретируемых пределов погрешностей, например violin+boxplot и boxplot+точки\n\nПодписывайтесь на телеграм канал: https://t.me/stats_for_science, будет много интересного. Обсудить пост можно здесь в комментариях."
  }
]